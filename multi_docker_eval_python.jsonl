{"repo": "getlogbook/logbook", "pull_number": 183, "instance_id": "getlogbook__logbook-183", "issue_numbers": ["94"], "base_commit": "1d999a784d0d8f5f7423f25c684cc1100843ccc5", "patch": "diff --git a/logbook/handlers.py b/logbook/handlers.py\n--- a/logbook/handlers.py\n+++ b/logbook/handlers.py\n@@ -20,6 +20,7 @@\n except ImportError:\n     from sha import new as sha1\n import traceback\n+import collections\n from datetime import datetime, timedelta\n from collections import deque\n from textwrap import dedent\n@@ -1014,14 +1015,42 @@ class MailHandler(Handler, StringFormatterHandlerMixin,\n \n     The default timedelta is 60 seconds (one minute).\n \n-    The mail handler is sending mails in a blocking manner.  If you are not\n+    The mail handler sends mails in a blocking manner.  If you are not\n     using some centralized system for logging these messages (with the help\n     of ZeroMQ or others) and the logging system slows you down you can\n     wrap the handler in a :class:`logbook.queues.ThreadedWrapperHandler`\n     that will then send the mails in a background thread.\n \n+    `server_addr` can be a tuple of host and port, or just a string containing\n+    the host to use the default port (25, or 465 if connecting securely.)\n+\n+    `credentials` can be a tuple or dictionary of arguments that will be passed\n+    to :py:meth:`smtplib.SMTP.login`.\n+\n+    `secure` can be a tuple, dictionary, or boolean. As a boolean, this will\n+    simply enable or disable a secure connection. The tuple is unpacked as\n+    parameters `keyfile`, `certfile`. As a dictionary, `secure` should contain\n+    those keys. For backwards compatibility, ``secure=()`` will enable a secure\n+    connection. If `starttls` is enabled (default), these parameters will be\n+    passed to :py:meth:`smtplib.SMTP.starttls`, otherwise\n+    :py:class:`smtplib.SMTP_SSL`.\n+\n+\n     .. versionchanged:: 0.3\n        The handler supports the batching system now.\n+\n+    .. versionadded:: 1.0\n+       `starttls` parameter added to allow disabling STARTTLS for SSL\n+       connections.\n+\n+    .. versionchanged:: 1.0\n+       If `server_addr` is a string, the default port will be used.\n+\n+    .. versionchanged:: 1.0\n+       `credentials` parameter can now be a dictionary of keyword arguments.\n+\n+    .. versionchanged:: 1.0\n+       `secure` can now be a dictionary or boolean in addition to to a tuple.\n     \"\"\"\n     default_format_string = MAIL_FORMAT_STRING\n     default_related_format_string = MAIL_RELATED_FORMAT_STRING\n@@ -1039,7 +1068,7 @@ def __init__(self, from_addr, recipients, subject=None,\n                  server_addr=None, credentials=None, secure=None,\n                  record_limit=None, record_delta=None, level=NOTSET,\n                  format_string=None, related_format_string=None,\n-                 filter=None, bubble=False):\n+                 filter=None, bubble=False, starttls=True):\n         Handler.__init__(self, level, filter, bubble)\n         StringFormatterHandlerMixin.__init__(self, format_string)\n         LimitingHandlerMixin.__init__(self, record_limit, record_delta)\n@@ -1054,6 +1083,7 @@ def __init__(self, from_addr, recipients, subject=None,\n         if related_format_string is None:\n             related_format_string = self.default_related_format_string\n         self.related_format_string = related_format_string\n+        self.starttls = starttls\n \n     def _get_related_format_string(self):\n         if isinstance(self.related_formatter, StringFormatter):\n@@ -1148,20 +1178,63 @@ def get_connection(self):\n         \"\"\"Returns an SMTP connection.  By default it reconnects for\n         each sent mail.\n         \"\"\"\n-        from smtplib import SMTP, SMTP_PORT, SMTP_SSL_PORT\n+        from smtplib import SMTP, SMTP_SSL, SMTP_PORT, SMTP_SSL_PORT\n         if self.server_addr is None:\n             host = '127.0.0.1'\n             port = self.secure and SMTP_SSL_PORT or SMTP_PORT\n         else:\n-            host, port = self.server_addr\n-        con = SMTP()\n-        con.connect(host, port)\n+            try:\n+                host, port = self.server_addr\n+            except ValueError:\n+                # If server_addr is a string, the tuple unpacking will raise\n+                # ValueError, and we can use the default port.\n+                host = self.server_addr\n+                port = self.secure and SMTP_SSL_PORT or SMTP_PORT\n+\n+        # Previously, self.secure was passed as con.starttls(*self.secure). This\n+        # meant that starttls couldn't be used without a keyfile and certfile\n+        # unless an empty tuple was passed. See issue #94.\n+        #\n+        # The changes below allow passing:\n+        # - secure=True for secure connection without checking identity.\n+        # - dictionary with keys 'keyfile' and 'certfile'.\n+        # - tuple to be unpacked to variables keyfile and certfile.\n+        # - secure=() equivalent to secure=True for backwards compatibility.\n+        # - secure=False equivalent to secure=None to disable.\n+        if isinstance(self.secure, collections.Mapping):\n+            keyfile = self.secure.get('keyfile', None)\n+            certfile = self.secure.get('certfile', None)\n+        elif isinstance(self.secure, collections.Iterable):\n+            # Allow empty tuple for backwards compatibility\n+            if len(self.secure) == 0:\n+                keyfile = certfile = None\n+            else:\n+                keyfile, certfile = self.secure\n+        else:\n+            keyfile = certfile = None\n+\n+        # Allow starttls to be disabled by passing starttls=False.\n+        if not self.starttls and self.secure:\n+            con = SMTP_SSL(host, port, keyfile=keyfile, certfile=certfile)\n+        else:\n+            con = SMTP(host, port)\n+\n         if self.credentials is not None:\n-            if self.secure is not None:\n+            secure = self.secure\n+            if self.starttls and secure is not None and secure is not False:\n                 con.ehlo()\n-                con.starttls(*self.secure)\n+                con.starttls(keyfile=keyfile, certfile=certfile)\n                 con.ehlo()\n-            con.login(*self.credentials)\n+\n+            # Allow credentials to be a tuple or dict.\n+            if isinstance(self.credentials, collections.Mapping):\n+                credentials_args = ()\n+                credentials_kwargs = self.credentials\n+            else:\n+                credentials_args = self.credentials\n+                credentials_kwargs = dict()\n+\n+            con.login(*credentials_args, **credentials_kwargs)\n         return con\n \n     def close_connection(self, con):\n@@ -1175,7 +1248,7 @@ def close_connection(self, con):\n             pass\n \n     def deliver(self, msg, recipients):\n-        \"\"\"Delivers the given message to a list of recpients.\"\"\"\n+        \"\"\"Delivers the given message to a list of recipients.\"\"\"\n         con = self.get_connection()\n         try:\n             con.sendmail(self.from_addr, recipients, msg.as_string())\n@@ -1227,7 +1300,7 @@ class GMailHandler(MailHandler):\n \n     def __init__(self, account_id, password, recipients, **kw):\n         super(GMailHandler, self).__init__(\n-            account_id, recipients, secure=(),\n+            account_id, recipients, secure=True,\n             server_addr=(\"smtp.gmail.com\", 587),\n             credentials=(account_id, password), **kw)\n \ndiff --git a/setup.py b/setup.py\n--- a/setup.py\n+++ b/setup.py\n@@ -158,6 +158,10 @@ def status_msgs(*msgs):\n \n extras_require = dict()\n extras_require['test'] = set(['pytest', 'pytest-cov'])\n+\n+if sys.version_info[:2] < (3, 3):\n+    extras_require['test'] |= set(['mock'])\n+\n extras_require['dev'] = set(['cython']) | extras_require['test']\n \n extras_require['execnet'] = set(['execnet>=1.0.9'])\n", "test_patch": "diff --git a/tests/test_mail_handler.py b/tests/test_mail_handler.py\n--- a/tests/test_mail_handler.py\n+++ b/tests/test_mail_handler.py\n@@ -7,6 +7,11 @@\n \n from .utils import capturing_stderr_context, make_fake_mail_handler\n \n+try:\n+    from unittest.mock import Mock, call, patch\n+except ImportError:\n+    from mock import Mock, call, patch\n+\n __file_without_pyc__ = __file__\n if __file_without_pyc__.endswith('.pyc'):\n     __file_without_pyc__ = __file_without_pyc__[:-1]\n@@ -104,3 +109,126 @@ def test_group_handler_mail_combo(activation_strategy, logger):\n     assert len(related) == 2\n     assert re.search('Message type:\\s+WARNING', related[0])\n     assert re.search('Message type:\\s+DEBUG', related[1])\n+\n+\n+def test_mail_handler_arguments():\n+    with patch('smtplib.SMTP', autospec=True) as mock_smtp:\n+\n+        # Test the mail handler with supported arguments before changes to\n+        # secure, credentials, and starttls\n+        mail_handler = logbook.MailHandler(\n+            from_addr='from@example.com',\n+            recipients='to@example.com',\n+            server_addr=('server.example.com', 465),\n+            credentials=('username', 'password'),\n+            secure=('keyfile', 'certfile'))\n+\n+        mail_handler.get_connection()\n+\n+        assert mock_smtp.call_args == call('server.example.com', 465)\n+        assert mock_smtp.method_calls[1] == call().starttls(\n+            keyfile='keyfile', certfile='certfile')\n+        assert mock_smtp.method_calls[3] == call().login('username', 'password')\n+\n+        # Test secure=()\n+        mail_handler = logbook.MailHandler(\n+            from_addr='from@example.com',\n+            recipients='to@example.com',\n+            server_addr=('server.example.com', 465),\n+            credentials=('username', 'password'),\n+            secure=())\n+\n+        mail_handler.get_connection()\n+\n+        assert mock_smtp.call_args == call('server.example.com', 465)\n+        assert mock_smtp.method_calls[5] == call().starttls(\n+            certfile=None, keyfile=None)\n+        assert mock_smtp.method_calls[7] == call().login('username', 'password')\n+\n+        # Test implicit port with string server_addr, dictionary credentials,\n+        # dictionary secure.\n+        mail_handler = logbook.MailHandler(\n+            from_addr='from@example.com',\n+            recipients='to@example.com',\n+            server_addr='server.example.com',\n+            credentials={'user': 'username', 'password': 'password'},\n+            secure={'certfile': 'certfile2', 'keyfile': 'keyfile2'})\n+\n+        mail_handler.get_connection()\n+\n+        assert mock_smtp.call_args == call('server.example.com', 465)\n+        assert mock_smtp.method_calls[9] == call().starttls(\n+            certfile='certfile2', keyfile='keyfile2')\n+        assert mock_smtp.method_calls[11] == call().login(\n+            user='username', password='password')\n+\n+        # Test secure=True\n+        mail_handler = logbook.MailHandler(\n+            from_addr='from@example.com',\n+            recipients='to@example.com',\n+            server_addr=('server.example.com', 465),\n+            credentials=('username', 'password'),\n+            secure=True)\n+\n+        mail_handler.get_connection()\n+\n+        assert mock_smtp.call_args == call('server.example.com', 465)\n+        assert mock_smtp.method_calls[13] == call().starttls(\n+            certfile=None, keyfile=None)\n+        assert mock_smtp.method_calls[15] == call().login('username', 'password')\n+        assert len(mock_smtp.method_calls) == 16\n+\n+        # Test secure=False\n+        mail_handler = logbook.MailHandler(\n+            from_addr='from@example.com',\n+            recipients='to@example.com',\n+            server_addr=('server.example.com', 465),\n+            credentials=('username', 'password'),\n+            secure=False)\n+\n+        mail_handler.get_connection()\n+\n+        # starttls not called because we check len of method_calls before and\n+        # after this test.\n+        assert mock_smtp.call_args == call('server.example.com', 465)\n+        assert mock_smtp.method_calls[16] == call().login('username', 'password')\n+        assert len(mock_smtp.method_calls) == 17\n+\n+    with patch('smtplib.SMTP_SSL', autospec=True) as mock_smtp_ssl:\n+        # Test starttls=False\n+        mail_handler = logbook.MailHandler(\n+            from_addr='from@example.com',\n+            recipients='to@example.com',\n+            server_addr='server.example.com',\n+            credentials={'user': 'username', 'password': 'password'},\n+            secure={'certfile': 'certfile', 'keyfile': 'keyfile'},\n+            starttls=False)\n+\n+        mail_handler.get_connection()\n+\n+        assert mock_smtp_ssl.call_args == call(\n+            'server.example.com', 465, keyfile='keyfile', certfile='certfile')\n+        assert mock_smtp_ssl.method_calls[0] == call().login(\n+            user='username', password='password')\n+\n+        # Test starttls=False with secure=True\n+        mail_handler = logbook.MailHandler(\n+            from_addr='from@example.com',\n+            recipients='to@example.com',\n+            server_addr='server.example.com',\n+            credentials={'user': 'username', 'password': 'password'},\n+            secure=True,\n+            starttls=False)\n+\n+        mail_handler.get_connection()\n+\n+        assert mock_smtp_ssl.call_args == call(\n+            'server.example.com', 465, keyfile=None, certfile=None)\n+        assert mock_smtp_ssl.method_calls[1] == call().login(\n+            user='username', password='password')\n+\n+\n+\n+\n+\n+\n", "problem_statement": "SMTP Handler STARTTLS\nDue to the lack of documentation on this handler it took a little digging to work out how to get it to work...\n\nOne thing that confused me was the \"secure\" argument. Python SMTPLib starttls() accepts two optional values: a keyfile and certfile - but these are only required for _checking_ the identity. If neither are specified then SMTPLib will still try establish an encrypted connection but without checking the identity. If you do not specify an argument to Logbook, it will not attempt to establish an encrypted connection at all.\n\nSo, if you want a tls connection to the SMTP server but don't care about checking the identity you can do `secure = []` which will pass the `if self.secure is not None`, however if you do `secure = True` you will get an error because you cannot unpack a boolean! (as logbook populates the arguments using: `conn.starttls(*self.secure)`).\n\nIt'd help if the documentation explained the arguments for the mail handlers.\n\n", "hints_text": "You're right. A simple solution is to use `secure = ()`, but I agree it has to be better documented.\n", "created_at": 1449, "language": "python", "label": "Easy"}
{"repo": "rigetti/pyquil", "pull_number": 399, "instance_id": "rigetti__pyquil-399", "issue_numbers": ["398", "398"], "base_commit": "d6a0e29b2b1a506a48977a9d8432e70ec699af34", "patch": "diff --git a/pyquil/parameters.py b/pyquil/parameters.py\n--- a/pyquil/parameters.py\n+++ b/pyquil/parameters.py\n@@ -31,9 +31,11 @@ def format_parameter(element):\n             out += repr(r)\n \n         if i == 1:\n-            out += 'i'\n+            assert np.isclose(r, 0, atol=1e-14)\n+            out = 'i'\n         elif i == -1:\n-            out += '-i'\n+            assert np.isclose(r, 0, atol=1e-14)\n+            out = '-i'\n         elif i < 0:\n             out += repr(i) + 'i'\n         else:\n", "test_patch": "diff --git a/pyquil/tests/test_parameters.py b/pyquil/tests/test_parameters.py\n--- a/pyquil/tests/test_parameters.py\n+++ b/pyquil/tests/test_parameters.py\n@@ -14,6 +14,8 @@ def test_format_parameter():\n         (1j, 'i'),\n         (0 + 1j, 'i'),\n         (-1j, '-i'),\n+        (1e-15 + 1j, 'i'),\n+        (1e-15 - 1j, '-i')\n     ]\n \n     for test_case in test_cases:\n", "problem_statement": "DEFGATEs are not correct\nThere is a problem with DEFGATEs that has manifested itself in the `phase_estimation` module of Grove (brought to our attention here: https://github.com/rigetticomputing/grove/issues/145). \r\n\r\nI have traced the problem to commit d309ac11dabd9ea9c7ffa57dd26e68b5e7129aa9 \r\n\r\nEach of the below test cases should deterministically return the input phase, for both `phase_estimation` and `estimate_gradient`. With this commit, result is not correct and nondeterministic for phase=3/4.\r\n\r\n```\r\nimport numpy as np\r\nimport scipy.linalg\r\nimport pyquil.api as api\r\nfrom grove.alpha.phaseestimation.phase_estimation import phase_estimation\r\nfrom grove.alpha.jordan_gradient.gradient_utils import *\r\nfrom grove.alpha.jordan_gradient.jordan_gradient import estimate_gradient\r\n\r\nqvm = api.QVMConnection()\r\ntrials = 1\r\nprecision = 8\r\nfor phase in [1/2, 1/4, 3/4, 1/8, 1/16, 1/32]:\r\n\r\n    Z = np.asarray([[1.0, 0.0], [0.0, -1.0]])\r\n    Rz = scipy.linalg.expm(-1j*Z*np.pi*phase)\r\n\r\n    p = phase_estimation(Rz, precision)\r\n    out = qvm.run(p, list(range(precision)), trials)\r\n    wf = qvm.wavefunction(p)\r\n\r\n    bf_estimate = measurements_to_bf(out)\r\n    bf_explicit = '{0:.16f}'.format(bf_estimate)\r\n    deci_estimate = binary_to_real(bf_explicit)\r\n\r\n    print('phase: ', phase)\r\n    print('pe', deci_estimate)\r\n    print('jg', estimate_gradient(phase, precision, n_measurements=trials, cxn=qvm))\r\n    print('\\n')\r\n```\r\n\nDEFGATEs are not correct\nThere is a problem with DEFGATEs that has manifested itself in the `phase_estimation` module of Grove (brought to our attention here: https://github.com/rigetticomputing/grove/issues/145). \r\n\r\nI have traced the problem to commit d309ac11dabd9ea9c7ffa57dd26e68b5e7129aa9 \r\n\r\nEach of the below test cases should deterministically return the input phase, for both `phase_estimation` and `estimate_gradient`. With this commit, result is not correct and nondeterministic for phase=3/4.\r\n\r\n```\r\nimport numpy as np\r\nimport scipy.linalg\r\nimport pyquil.api as api\r\nfrom grove.alpha.phaseestimation.phase_estimation import phase_estimation\r\nfrom grove.alpha.jordan_gradient.gradient_utils import *\r\nfrom grove.alpha.jordan_gradient.jordan_gradient import estimate_gradient\r\n\r\nqvm = api.QVMConnection()\r\ntrials = 1\r\nprecision = 8\r\nfor phase in [1/2, 1/4, 3/4, 1/8, 1/16, 1/32]:\r\n\r\n    Z = np.asarray([[1.0, 0.0], [0.0, -1.0]])\r\n    Rz = scipy.linalg.expm(-1j*Z*np.pi*phase)\r\n\r\n    p = phase_estimation(Rz, precision)\r\n    out = qvm.run(p, list(range(precision)), trials)\r\n    wf = qvm.wavefunction(p)\r\n\r\n    bf_estimate = measurements_to_bf(out)\r\n    bf_explicit = '{0:.16f}'.format(bf_estimate)\r\n    deci_estimate = binary_to_real(bf_explicit)\r\n\r\n    print('phase: ', phase)\r\n    print('pe', deci_estimate)\r\n    print('jg', estimate_gradient(phase, precision, n_measurements=trials, cxn=qvm))\r\n    print('\\n')\r\n```\r\n\n", "hints_text": "\n", "created_at": 1524, "language": "python", "label": "Hard"}
{"repo": "marcelotduarte/cx_Freeze", "pull_number": 2220, "instance_id": "marcelotduarte__cx_Freeze-2220", "issue_numbers": ["2210"], "base_commit": "639141207611f0edca554978f66b1ed7df3d8cdf", "patch": "diff --git a/cx_Freeze/winversioninfo.py b/cx_Freeze/winversioninfo.py\n--- a/cx_Freeze/winversioninfo.py\n+++ b/cx_Freeze/winversioninfo.py\n@@ -12,16 +12,16 @@\n \n __all__ = [\"Version\", \"VersionInfo\"]\n \n+# types\n+CHAR = \"c\"\n+WCHAR = \"ss\"\n+WORD = \"=H\"\n+DWORD = \"=L\"\n+\n # constants\n RT_VERSION = 16\n ID_VERSION = 1\n \n-# types\n-CHAR = \"c\"\n-DWORD = \"L\"\n-WCHAR = \"H\"\n-WORD = \"H\"\n-\n VS_FFI_SIGNATURE = 0xFEEF04BD\n VS_FFI_STRUCVERSION = 0x00010000\n VS_FFI_FILEFLAGSMASK = 0x0000003F\n@@ -32,6 +32,8 @@\n KEY_STRING_TABLE = \"040904E4\"\n KEY_VAR_FILE_INFO = \"VarFileInfo\"\n \n+COMMENTS_MAX_LEN = (64 - 2) * 1024 // calcsize(WCHAR)\n+\n # To disable the experimental feature in Windows:\n # set CX_FREEZE_STAMP=pywin32\n # pip install -U pywin32\n@@ -82,7 +84,7 @@ def to_buffer(self):\n                 data = data.to_buffer()\n             elif isinstance(data, str):\n                 data = data.encode(\"utf-16le\")\n-            elif isinstance(fmt, str):\n+            elif isinstance(data, int):\n                 data = pack(fmt, data)\n             buffer += data\n         return buffer\n@@ -142,7 +144,9 @@ def __init__(\n             value_len = value.wLength\n             fields.append((\"Value\", type(value)))\n         elif isinstance(value, Structure):\n-            value_len = calcsize(\"\".join([f[1] for f in value._fields]))\n+            value_len = 0\n+            for field in value._fields:\n+                value_len += calcsize(field[1])\n             value_type = 0\n             fields.append((\"Value\", type(value)))\n \n@@ -199,7 +203,8 @@ def __init__(\n         self.valid_version: Version = valid_version\n         self.internal_name: str | None = internal_name\n         self.original_filename: str | None = original_filename\n-        self.comments: str | None = comments\n+        # comments length must be limited to 31kb\n+        self.comments: str = comments[:COMMENTS_MAX_LEN] if comments else None\n         self.company: str | None = company\n         self.description: str | None = description\n         self.copyright: str | None = copyright\n@@ -221,6 +226,8 @@ def stamp(self, path: str | Path) -> None:\n                 version_stamp = import_module(\"win32verstamp\").stamp\n             except ImportError as exc:\n                 raise RuntimeError(\"install pywin32 extension first\") from exc\n+            # comments length must be limited to 15kb (uses WORD='h')\n+            self.comments = (self.comments or \"\")[: COMMENTS_MAX_LEN // 2]\n             version_stamp(os.fspath(path), self)\n             return\n \n@@ -263,17 +270,18 @@ def version_info(self, path: Path) -> String:\n         elif len(self.valid_version.release) >= 4:\n             build = self.valid_version.release[3]\n \n+        # use the data in the order shown in 'pepper'\n         data = {\n-            \"Comments\": self.comments or \"\",\n-            \"CompanyName\": self.company or \"\",\n             \"FileDescription\": self.description or \"\",\n             \"FileVersion\": self.version,\n             \"InternalName\": self.internal_name or path.name,\n+            \"CompanyName\": self.company or \"\",\n             \"LegalCopyright\": self.copyright or \"\",\n             \"LegalTrademarks\": self.trademarks or \"\",\n             \"OriginalFilename\": self.original_filename or path.name,\n             \"ProductName\": self.product or \"\",\n             \"ProductVersion\": str(self.valid_version),\n+            \"Comments\": self.comments or \"\",\n         }\n         is_dll = self.dll\n         if is_dll is None:\n@@ -311,6 +319,7 @@ def version_info(self, path: Path) -> String:\n         string_version_info = String(KEY_VERSION_INFO, fixed_file_info)\n         string_version_info.children(string_file_info)\n         string_version_info.children(var_file_info)\n+\n         return string_version_info\n \n \n", "test_patch": "diff --git a/tests/test_winversioninfo.py b/tests/test_winversioninfo.py\n--- a/tests/test_winversioninfo.py\n+++ b/tests/test_winversioninfo.py\n@@ -9,7 +9,12 @@\n import pytest\n from generate_samples import create_package, run_command\n \n-from cx_Freeze.winversioninfo import Version, VersionInfo, main_test\n+from cx_Freeze.winversioninfo import (\n+    COMMENTS_MAX_LEN,\n+    Version,\n+    VersionInfo,\n+    main_test,\n+)\n \n PLATFORM = get_platform()\n PYTHON_VERSION = get_python_version()\n@@ -97,6 +102,14 @@ def test___init__with_kwargs(self):\n         assert version_instance.debug is input_debug\n         assert version_instance.verbose is input_verbose\n \n+    def test_big_comment(self):\n+        \"\"\"Tests a big comment value for the VersionInfo class.\"\"\"\n+        input_version = \"9.9.9.9\"\n+        input_comments = \"TestComment\" + \"=\" * COMMENTS_MAX_LEN\n+        version_instance = VersionInfo(input_version, comments=input_comments)\n+        assert version_instance.version == \"9.9.9.9\"\n+        assert version_instance.comments == input_comments[:COMMENTS_MAX_LEN]\n+\n     @pytest.mark.parametrize(\n         (\"input_version\", \"version\"),\n         [\n", "problem_statement": "Cannot freeze python-3.12 code on Windows 11\n**Describe the bug**\r\nCannot freeze python 3.12 code on Windows 11 Pro amd64 using cx_Freeze 6.16.aplha versions, last I tried is 20.\r\nThis was working fine three weeks ago, but suddenly it started to fail like this:\r\n```\r\ncopying C:\\Users\\jmarcet\\scoop\\apps\\openjdk17\\17.0.2-8\\bin\\api-ms-win-core-console-l1-2-0.dll -> C:\\Users\\jmarcet\\src\\movistar-u7d\\build\\exe.win-amd64-3.12\\api-ms-win-core-console-l1-2-0.dll\r\ncopying C:\\Users\\jmarcet\\scoop\\apps\\python312\\3.12.1\\python312.dll -> C:\\Users\\jmarcet\\src\\movistar-u7d\\build\\exe.win-amd64-3.12\\python312.dll\r\nWARNING: cannot find 'api-ms-win-core-path-l1-1-0.dll'\r\ncopying C:\\Users\\jmarcet\\scoop\\persist\\python312\\Lib\\site-packages\\cx_Freeze\\bases\\console-cpython-312-win_amd64.exe -> C:\\Users\\jmarcet\\src\\movistar-u7d\\build\\exe.win-amd64-3.12\\movistar_epg.exe\r\ncopying C:\\Users\\jmarcet\\scoop\\persist\\python312\\Lib\\site-packages\\cx_Freeze\\initscripts\\frozen_application_license.txt -> C:\\Users\\jmarcet\\src\\movistar-u7d\\build\\exe.win-amd64-3.12\\frozen_application_license.txt\r\ndata=72092\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\jmarcet\\src\\movistar-u7d\\setup.py\", line 25, in <module>\r\n    setup(\r\n  File \"C:\\Users\\jmarcet\\scoop\\apps\\python312\\current\\Lib\\site-packages\\cx_Freeze\\__init__.py\", line 68, in setup\r\n    setuptools.setup(**attrs)\r\n  File \"C:\\Users\\jmarcet\\scoop\\apps\\python312\\current\\Lib\\site-packages\\setuptools\\__init__.py\", line 103, in setup\r\n    return distutils.core.setup(**attrs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\jmarcet\\scoop\\apps\\python312\\current\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 185, in setup\r\n    return run_commands(dist)\r\n           ^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\jmarcet\\scoop\\apps\\python312\\current\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 201, in run_commands\r\n    dist.run_commands()\r\n  File \"C:\\Users\\jmarcet\\scoop\\apps\\python312\\current\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 969, in run_commands\r\n    self.run_command(cmd)\r\n  File \"C:\\Users\\jmarcet\\scoop\\apps\\python312\\current\\Lib\\site-packages\\setuptools\\dist.py\", line 963, in run_command\r\n    super().run_command(command)\r\n  File \"C:\\Users\\jmarcet\\scoop\\apps\\python312\\current\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\r\n    cmd_obj.run()\r\n  File \"C:\\Users\\jmarcet\\scoop\\apps\\python312\\current\\Lib\\site-packages\\setuptools\\_distutils\\command\\build.py\", line 131, in run\r\n    self.run_command(cmd_name)\r\n  File \"C:\\Users\\jmarcet\\scoop\\apps\\python312\\current\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 318, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"C:\\Users\\jmarcet\\scoop\\apps\\python312\\current\\Lib\\site-packages\\setuptools\\dist.py\", line 963, in run_command\r\n    super().run_command(command)\r\n  File \"C:\\Users\\jmarcet\\scoop\\apps\\python312\\current\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\r\n    cmd_obj.run()\r\n  File \"C:\\Users\\jmarcet\\scoop\\apps\\python312\\current\\Lib\\site-packages\\cx_Freeze\\command\\build_exe.py\", line 284, in run\r\n    freezer.freeze()\r\n  File \"C:\\Users\\jmarcet\\scoop\\apps\\python312\\current\\Lib\\site-packages\\cx_Freeze\\freezer.py\", line 731, in freeze\r\n    self._freeze_executable(executable)\r\n  File \"C:\\Users\\jmarcet\\scoop\\apps\\python312\\current\\Lib\\site-packages\\cx_Freeze\\freezer.py\", line 323, in _freeze_executable\r\n    self._add_resources(exe)\r\n  File \"C:\\Users\\jmarcet\\scoop\\apps\\python312\\current\\Lib\\site-packages\\cx_Freeze\\freezer.py\", line 794, in _add_resources\r\n    version.stamp(target_path)\r\n  File \"C:\\Users\\jmarcet\\scoop\\apps\\python312\\current\\Lib\\site-packages\\cx_Freeze\\winversioninfo.py\", line 240, in stamp\r\n    handle, RT_VERSION, ID_VERSION, string_version_info.to_buffer()\r\n                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\jmarcet\\scoop\\apps\\python312\\current\\Lib\\site-packages\\cx_Freeze\\winversioninfo.py\", line 96, in to_buffer\r\n    data = pack(fmt, data)\r\n           ^^^^^^^^^^^^^^^\r\nstruct.error: 'H' format requires 0 <= number <= 65535\r\n```\r\n\r\n**To Reproduce**\r\n```\r\ngit clone -b next https://github.com/jmarcet/movistar-u7d\r\ncd movistar-u7d\r\npip install --force --no-cache --pre --upgrade --extra-index-url https://marcelotduarte.github.io/packages/cx_Freeze\r\npip install -r requirements-win.txt\r\npython .\\setup.py build\r\n```\r\n\r\n**Expected behavior**\r\nFrozen artifacts saved under `build` dir\r\n\r\n**Desktop (please complete the following information):**\r\n - Platform information: Windows 11 Pro\r\n - OS architecture: amd64\r\n - cx_Freeze version: [cx_Freeze-6.16.0.dev20-cp312-cp312-win_amd64.whl](https://marcelotduarte.github.io/packages/cx-freeze/cx_Freeze-6.16.0.dev20-cp312-cp312-win_amd64.whl)\r\n - Python version: 3.12.1\r\n\r\n**Additional context**\r\nI had initially reported it on #2153\n", "hints_text": "Please check the version installed of cx_Freeze and setuptools with `pip list`.\r\nSuccessfully installed aiofiles-23.2.1 aiohttp-3.9.1 aiosignal-1.3.1 asyncio-3.4.3 asyncio_dgram-2.1.2 attrs-23.2.0 cx-Logging-3.1.0 **cx_Freeze-6.16.0.dev9** defusedxml-0.8.0rc2 filelock-3.13.1 frozenlist-1.4.1 httptools-0.6.1 idna-3.6 lief-0.14.0 multidict-6.0.4 prometheus-client-0.7.1 psutil-5.9.8 pywin32-306 sanic-22.6.2 sanic-prometheus-0.2.1 sanic-routing-22.3.0 **setuptools-68.2.2** tomli-2.0.1 ujson-5.9.0 websockets-10.4 wheel-0.41.2 wmi-1.5.1 xmltodict-0.13.0 yarl-1.9.4\r\n\r\nYou should update your requirements-win.txt, insert the first line:\r\n--extra-index-url https://marcelotduarte.github.io/packages/\r\n\r\nOR install the new development release after the requirements. Also, update setuptools.\r\n\r\n\n@marcelotduarte I still have the same issue\r\n\r\n```\r\n> pip list\r\nPackage            Version\r\n------------------ ------------\r\naiofiles           23.2.1\r\naiohttp            3.9.1\r\naiosignal          1.3.1\r\nastroid            3.0.2\r\nasttokens          2.4.1\r\nasyncio            3.4.3\r\nasyncio-dgram      2.1.2\r\nattrs              23.2.0\r\nbandit             1.7.6\r\ncertifi            2023.11.17\r\ncharset-normalizer 3.3.2\r\ncolorama           0.4.6\r\ncx-Freeze          6.16.0.dev23\r\ncx_Logging         3.1.0\r\ndecorator          5.1.1\r\ndefusedxml         0.7.1\r\ndill               0.3.7\r\nexecuting          2.0.1\r\nfilelock           3.13.1\r\nfrozenlist         1.4.1\r\ngitdb              4.0.11\r\nGitPython          3.1.41\r\nhttpie             3.2.2\r\nhttptools          0.6.1\r\nidna               3.6\r\nipython            8.20.0\r\nisort              5.13.2\r\njedi               0.19.1\r\nlief               0.15.0\r\nmarkdown-it-py     3.0.0\r\nmatplotlib-inline  0.1.6\r\nmccabe             0.7.0\r\nmdurl              0.1.2\r\nmultidict          6.0.4\r\nparso              0.8.3\r\npbr                6.0.0\r\npip                23.2.1\r\nplatformdirs       4.1.0\r\nprometheus-client  0.7.1\r\nprompt-toolkit     3.0.43\r\npsutil             5.9.8\r\npure-eval          0.2.2\r\nPygments           2.17.2\r\npylint             3.0.3\r\npynvim             0.5.0\r\nPySocks            1.7.1\r\npywin32            306\r\nPyYAML             6.0.1\r\nrequests           2.31.0\r\nrequests-toolbelt  1.0.0\r\nrich               13.7.0\r\nruff               0.1.11\r\nsanic              22.6.2\r\nsanic-prometheus   0.2.1\r\nsanic-routing      22.3.0\r\nsetuptools         69.0.3\r\nsix                1.16.0\r\nsmmap              5.0.1\r\nstack-data         0.6.3\r\nstevedore          5.1.0\r\ntomli              2.0.1\r\ntomlkit            0.12.3\r\ntraitlets          5.14.1\r\nujson              5.9.0\r\nurllib3            2.1.0\r\nwcwidth            0.2.13\r\nwebsockets         10.4\r\nwheel              0.42.0\r\nWMI                1.5.1\r\nxmltodict          0.13.0\r\nyarl               1.9.4\r\n```", "created_at": 1706, "language": "python", "label": "Easy"}
{"repo": "pytest-dev/pytest-django", "pull_number": 1108, "instance_id": "pytest-dev__pytest-django-1108", "issue_numbers": ["1106"], "base_commit": "6cf63b65e86870abf68ae1f376398429e35864e7", "patch": "diff --git a/pytest_django/plugin.py b/pytest_django/plugin.py\n--- a/pytest_django/plugin.py\n+++ b/pytest_django/plugin.py\n@@ -362,8 +362,15 @@ def _get_option_with_source(\n \n @pytest.hookimpl(trylast=True)\n def pytest_configure(config: pytest.Config) -> None:\n-    # Allow Django settings to be configured in a user pytest_configure call,\n-    # but make sure we call django.setup()\n+    if config.getoption(\"version\", 0) > 0 or config.getoption(\"help\", False):\n+        return\n+\n+    # Normally Django is set up in `pytest_load_initial_conftests`, but we also\n+    # allow users to not set DJANGO_SETTINGS_MODULE/`--ds` and instead\n+    # configure the Django settings in a `pytest_configure` hookimpl using e.g.\n+    # `settings.configure(...)`. In this case, the `_setup_django` call in\n+    # `pytest_load_initial_conftests` only partially initializes Django, and\n+    # it's fully initialized here.\n     _setup_django(config)\n \n \n@@ -470,8 +477,7 @@ def get_order_number(test: pytest.Item) -> int:\n \n @pytest.fixture(autouse=True, scope=\"session\")\n def django_test_environment(request: pytest.FixtureRequest) -> Generator[None, None, None]:\n-    \"\"\"\n-    Ensure that Django is loaded and has its testing environment setup.\n+    \"\"\"Setup Django's test environment for the testing session.\n \n     XXX It is a little dodgy that this is an autouse fixture.  Perhaps\n         an email fixture should be requested in order to be able to\n@@ -481,7 +487,6 @@ def django_test_environment(request: pytest.FixtureRequest) -> Generator[None, N\n         we need to follow this model.\n     \"\"\"\n     if django_settings_is_configured():\n-        _setup_django(request.config)\n         from django.test.utils import setup_test_environment, teardown_test_environment\n \n         debug_ini = request.config.getini(\"django_debug_mode\")\n", "test_patch": "diff --git a/tests/test_manage_py_scan.py b/tests/test_manage_py_scan.py\n--- a/tests/test_manage_py_scan.py\n+++ b/tests/test_manage_py_scan.py\n@@ -144,6 +144,37 @@ def test_django_project_found_invalid_settings_version(\n     result.stdout.fnmatch_lines([\"*usage:*\"])\n \n \n+@pytest.mark.django_project(project_root=\"django_project_root\", create_manage_py=True)\n+def test_django_project_late_settings_version(\n+    django_pytester: DjangoPytester,\n+    monkeypatch: pytest.MonkeyPatch,\n+) -> None:\n+    \"\"\"Late configuration should not cause an error with --help or --version.\"\"\"\n+    monkeypatch.delenv(\"DJANGO_SETTINGS_MODULE\")\n+    django_pytester.makepyfile(\n+        t=\"WAT = 1\",\n+    )\n+    django_pytester.makeconftest(\n+        \"\"\"\n+        import os\n+\n+        def pytest_configure():\n+            os.environ.setdefault('DJANGO_SETTINGS_MODULE', 't')\n+            from django.conf import settings\n+            settings.WAT\n+        \"\"\"\n+    )\n+\n+    result = django_pytester.runpytest_subprocess(\"django_project_root\", \"--version\", \"--version\")\n+    assert result.ret == 0\n+\n+    result.stdout.fnmatch_lines([\"*This is pytest version*\"])\n+\n+    result = django_pytester.runpytest_subprocess(\"django_project_root\", \"--help\")\n+    assert result.ret == 0\n+    result.stdout.fnmatch_lines([\"*usage:*\"])\n+\n+\n @pytest.mark.django_project(project_root=\"django_project_root\", create_manage_py=True)\n def test_runs_without_error_on_long_args(django_pytester: DjangoPytester) -> None:\n     django_pytester.create_test_module(\n", "problem_statement": "`pytest --help` fails in a partially configured app\nhaving a difficult time narrowing down a minimal example -- the repo involved is https://github.com/getsentry/sentry\r\n\r\nI have figured out _why_ it is happening and the stacktrace for it:\r\n\r\n<summary>full stacktrace with error\r\n\r\n<details>\r\n\r\n```console\r\n$ pytest --help\r\n/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/trio/_core/_multierror.py:511: RuntimeWarning: You seem to already have a custom sys.excepthook handler installed. I'll skip installing Trio's custom handler, but this means MultiErrors will not show full tracebacks.\r\n  warnings.warn(\r\nTraceback (most recent call last):\r\n  File \"/Users/asottile/workspace/sentry/.venv/bin/pytest\", line 8, in <module>\r\n    sys.exit(console_main())\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/_pytest/config/__init__.py\", line 190, in console_main\r\n    code = main()\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/_pytest/config/__init__.py\", line 167, in main\r\n    ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/pluggy/hooks.py\", line 286, in __call__\r\n    return self._hookexec(self, self.get_hookimpls(), kwargs)\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/pluggy/manager.py\", line 93, in _hookexec\r\n    return self._inner_hookexec(hook, methods, kwargs)\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/pluggy/manager.py\", line 84, in <lambda>\r\n    self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/pluggy/callers.py\", line 208, in _multicall\r\n    return outcome.get_result()\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/pluggy/callers.py\", line 80, in get_result\r\n    raise ex[1].with_traceback(ex[2])\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/pluggy/callers.py\", line 187, in _multicall\r\n    res = hook_impl.function(*args)\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/_pytest/helpconfig.py\", line 152, in pytest_cmdline_main\r\n    config._do_configure()\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/_pytest/config/__init__.py\", line 1037, in _do_configure\r\n    self.hook.pytest_configure.call_historic(kwargs=dict(config=self))\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/pluggy/hooks.py\", line 308, in call_historic\r\n    res = self._hookexec(self, self.get_hookimpls(), kwargs)\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/pluggy/manager.py\", line 93, in _hookexec\r\n    return self._inner_hookexec(hook, methods, kwargs)\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/pluggy/manager.py\", line 84, in <lambda>\r\n    self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/pluggy/callers.py\", line 208, in _multicall\r\n    return outcome.get_result()\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/pluggy/callers.py\", line 80, in get_result\r\n    raise ex[1].with_traceback(ex[2])\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/pluggy/callers.py\", line 187, in _multicall\r\n    res = hook_impl.function(*args)\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/pytest_django/plugin.py\", line 367, in pytest_configure\r\n    _setup_django(config)\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/pytest_django/plugin.py\", line 238, in _setup_django\r\n    blocking_manager = config.stash[blocking_manager_key]\r\n  File \"/Users/asottile/workspace/sentry/.venv/lib/python3.10/site-packages/_pytest/stash.py\", line 80, in __getitem__\r\n    return cast(T, self._storage[key])\r\nKeyError: <_pytest.stash.StashKey object at 0x1066ab520>\r\n```\r\n\r\n</details>\r\n</summary>\r\n\r\nbasically what's happening is the setup is skipped here:  https://github.com/pytest-dev/pytest-django/blob/6cf63b65e86870abf68ae1f376398429e35864e7/pytest_django/plugin.py#L300-L301\r\n\r\nnormally it sets the thing that's being looked up here: https://github.com/pytest-dev/pytest-django/blob/6cf63b65e86870abf68ae1f376398429e35864e7/pytest_django/plugin.py#L358\r\n\r\nwhich then fails to lookup here: https://github.com/pytest-dev/pytest-django/blob/6cf63b65e86870abf68ae1f376398429e35864e7/pytest_django/plugin.py#L238\r\n\r\nsomething about sentry's `tests/conftest.py` initializes enough of django that `pytest-django` takes over.  but since the setup has been skipped it fails to set up properly.  I suspect that #238 is playing poorly with something.\r\n\r\nof note this worked before I upgraded `pytest-django` (I was previously on 4.4.0 and upgraded to 4.7.0 to get django 4.x support)\r\n\r\nwill try and narrow down a smaller reproduction...\n", "hints_text": "Thatâ€™s a fun one! Hopefully using `config.stash.get()` calls and acting only on non-`None` values will be enough to fix the issue...\nhere's a minimal case:\r\n\r\n```console\r\n==> t.py <==\r\nWAT = 1\r\n\r\n==> tests/__init__.py <==\r\n\r\n==> tests/conftest.py <==\r\nimport os\r\n\r\ndef pytest_configure():\r\n    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 't')\r\n    from django.conf import settings\r\n    settings.WAT\r\n```", "created_at": 1706, "language": "python", "label": "Hard"}
{"repo": "marcelotduarte/cx_Freeze", "pull_number": 2597, "instance_id": "marcelotduarte__cx_Freeze-2597", "issue_numbers": ["2596"], "base_commit": "df2c8aef8f92da535a1bb657706ca4496b1c3352", "patch": "diff --git a/cx_Freeze/finder.py b/cx_Freeze/finder.py\n--- a/cx_Freeze/finder.py\n+++ b/cx_Freeze/finder.py\n@@ -537,7 +537,10 @@ def _replace_package_in_code(module: Module) -> CodeType:\n             # Insert a bytecode to set __package__ as module.parent.name\n             codes = [LOAD_CONST, pkg_const_index, STORE_NAME, pkg_name_index]\n             codestring = bytes(codes) + code.co_code\n-            consts.append(module.parent.name)\n+            if module.file.stem == \"__init__\":\n+                consts.append(module.name)\n+            else:\n+                consts.append(module.parent.name)\n             code = code_object_replace(\n                 code, co_code=codestring, co_consts=consts\n             )\ndiff --git a/cx_Freeze/hooks/scipy.py b/cx_Freeze/hooks/scipy.py\n--- a/cx_Freeze/hooks/scipy.py\n+++ b/cx_Freeze/hooks/scipy.py\n@@ -18,12 +18,18 @@\n def load_scipy(finder: ModuleFinder, module: Module) -> None:\n     \"\"\"The scipy package.\n \n-    Supported pypi and conda-forge versions (lasted tested version is 1.11.2).\n+    Supported pypi and conda-forge versions (lasted tested version is 1.14.1).\n     \"\"\"\n     source_dir = module.file.parent.parent / f\"{module.name}.libs\"\n     if source_dir.exists():  # scipy >= 1.9.2 (windows)\n-        finder.include_files(source_dir, f\"lib/{source_dir.name}\")\n-        replace_delvewheel_patch(module)\n+        if IS_WINDOWS:\n+            finder.include_files(source_dir, f\"lib/{source_dir.name}\")\n+            replace_delvewheel_patch(module)\n+        else:\n+            target_dir = f\"lib/{source_dir.name}\"\n+            for source in source_dir.iterdir():\n+                finder.lib_files[source] = f\"{target_dir}/{source.name}\"\n+\n     finder.include_package(\"scipy.integrate\")\n     finder.include_package(\"scipy._lib\")\n     finder.include_package(\"scipy.misc\")\n", "test_patch": "diff --git a/samples/scipy/test_scipy.py b/samples/scipy/test_scipy.py\n--- a/samples/scipy/test_scipy.py\n+++ b/samples/scipy/test_scipy.py\n@@ -1,8 +1,6 @@\n \"\"\"A simple script to demonstrate scipy.\"\"\"\n \n-from scipy.stats import norm\n+from scipy.spatial.transform import Rotation\n \n if __name__ == \"__main__\":\n-    print(\n-        \"bounds of distribution lower: {}, upper: {}\".format(*norm.support())\n-    )\n+    print(Rotation.from_euler(\"XYZ\", [10, 10, 10], degrees=True).as_matrix())\n", "problem_statement": "cx-Freeze - No module named 'scipy._lib.array_api_compat._aliases'\n**Prerequisite**\r\nThis was previously reported in the closed issue #2544, where no action was taken. I include a minimal script that produces the problem for me.\r\n\r\n**Describe the bug**\r\nWhen running the compiled executable, i get the following error:\r\n```\r\nPS C:\\dat\\projects\\gazeMapper\\cxFreeze\\build\\exe.win-amd64-3.10> .\\test.exe\r\nTraceback (most recent call last):\r\n  File \"C:\\dat\\projects\\gazeMapper\\cxFreeze\\.venv\\Lib\\site-packages\\cx_Freeze\\initscripts\\__startup__.py\", line 141, in run\r\n    module_init.run(f\"__main__{name}\")\r\n  File \"C:\\dat\\projects\\gazeMapper\\cxFreeze\\.venv\\Lib\\site-packages\\cx_Freeze\\initscripts\\console.py\", line 25, in run\r\n    exec(code, main_globals)\r\n  File \"C:\\dat\\projects\\gazeMapper\\cxFreeze\\test.py\", line 1, in <module>\r\n    from scipy.spatial.transform import Rotation\r\n  File \"C:\\dat\\projects\\gazeMapper\\cxFreeze\\.venv\\lib\\site-packages\\scipy\\spatial\\__init__.py\", line 110, in <module>\r\n    from ._kdtree import *\r\n  File \"C:\\dat\\projects\\gazeMapper\\cxFreeze\\.venv\\lib\\site-packages\\scipy\\spatial\\_kdtree.py\", line 4, in <module>\r\n    from ._ckdtree import cKDTree, cKDTreeNode\r\n  File \"_ckdtree.pyx\", line 11, in init scipy.spatial._ckdtree\r\n  File \"C:\\dat\\projects\\gazeMapper\\cxFreeze\\.venv\\lib\\site-packages\\scipy\\sparse\\__init__.py\", line 293, in <module>\r\n    from ._base import *\r\n  File \"C:\\dat\\projects\\gazeMapper\\cxFreeze\\.venv\\lib\\site-packages\\scipy\\sparse\\_base.py\", line 5, in <module>\r\n    from ._sputils import (asmatrix, check_reshape_kwargs, check_shape,\r\n  File \"C:\\dat\\projects\\gazeMapper\\cxFreeze\\.venv\\lib\\site-packages\\scipy\\sparse\\_sputils.py\", line 10, in <module>\r\n    from scipy._lib._util import np_long, np_ulong\r\n  File \"C:\\dat\\projects\\gazeMapper\\cxFreeze\\.venv\\lib\\site-packages\\scipy\\_lib\\_util.py\", line 18, in <module>\r\n    from scipy._lib._array_api import array_namespace, is_numpy, size as xp_size\r\n  File \"C:\\dat\\projects\\gazeMapper\\cxFreeze\\.venv\\lib\\site-packages\\scipy\\_lib\\_array_api.py\", line 21, in <module>\r\n    from scipy._lib.array_api_compat import (\r\n  File \"C:\\dat\\projects\\gazeMapper\\cxFreeze\\.venv\\lib\\site-packages\\scipy\\_lib\\array_api_compat\\numpy\\__init__.py\", line 16, in <module>\r\n    __import__(__package__ + '.linalg')\r\nModuleNotFoundError: No module named 'scipy._lib.array_api_compat._aliases'\r\n```\r\n\r\n**To Reproduce**\r\nTwo files:\r\ntest.py\r\n```python\r\nfrom scipy.spatial.transform import Rotation\r\nprint(Rotation.from_euler('XYZ', [10, 10, 10], degrees=True).as_matrix())\r\n```\r\nsetup.py:\r\n```python\r\nimport cx_Freeze\r\nimport pathlib\r\nimport sys\r\nimport site\r\n\r\npath = pathlib.Path(__file__).absolute().parent\r\n\r\ndef get_include_files():\r\n    # don't know if this is a bad idea, it certainly didn't help\r\n    files = []\r\n\r\n    # scipy dlls\r\n    for d in site.getsitepackages():\r\n        d=pathlib.Path(d)/'scipy'/'.libs'\r\n        if d.is_dir():\r\n            for f in d.iterdir():\r\n                if f.is_file() and f.suffix=='' or f.suffix in ['.dll']:\r\n                    files.append((f,pathlib.Path('lib')/f.name))\r\n    return files\r\n\r\nbuild_options = {\r\n    \"build_exe\": {\r\n        \"optimize\": 1,\r\n        \"packages\": [\r\n            'numpy','scipy'\r\n        ],\r\n        \"excludes\":[\"tkinter\"],\r\n        \"zip_include_packages\": \"*\",\r\n        \"zip_exclude_packages\": [],\r\n        \"silent_level\": 1,\r\n        \"include_msvcr\": True\r\n    }\r\n}\r\nif sys.platform.startswith(\"win\"):\r\n    build_options[\"build_exe\"][\"include_files\"] = get_include_files()\r\n\r\ncx_Freeze.setup(\r\n    name=\"test\",\r\n    version=\"0.0.1\",\r\n    description=\"test\",\r\n    executables=[\r\n        cx_Freeze.Executable(\r\n            script=path / \"test.py\",\r\n            target_name=\"test\"\r\n        )\r\n    ],\r\n    options=build_options,\r\n    py_modules=[]\r\n)\r\n```\r\n\r\n**Expected behavior**\r\nexe runs\r\n\r\n**Desktop (please complete the following information):**\r\n - Windows 11 Enterprise\r\n - amd64\r\n - cx_Freeze version 7.2.2\r\n - Python version 3.10\r\n - Numpy 2.1.1\r\n - Scipy 1.14.1\r\n\r\n**Additional context**\r\nat `\\.venv\\Lib\\site-packages\\scipy\\_lib\\array_api_compat` there is no `_aliases.py`, only `__init__.py` with the following content:\r\n```python\r\n__version__ = '1.5.1'\r\nfrom .common import *  # noqa: F401, F403\r\n```\r\n`_aliases.py` does exist at `\\.venv\\Lib\\site-packages\\scipy\\_lib\\array_api_compat\\common`\r\n\r\nBoth files are packed into library.zip (whole scipy tree is)\n", "hints_text": "Changing the config to `\"zip_exclude_packages\": ['scipy']`, things work. I assume it should work just fine/the same from the zip file. This will be my workaround for now", "created_at": 1727, "language": "python", "label": "Easy"}
{"repo": "rigetti/pyquil", "pull_number": 1149, "instance_id": "rigetti__pyquil-1149", "issue_numbers": ["980"], "base_commit": "07db509c5293df2b4624ca6ac409e4fce2666ea1", "patch": "diff --git a/pyquil/device/_isa.py b/pyquil/device/_isa.py\n--- a/pyquil/device/_isa.py\n+++ b/pyquil/device/_isa.py\n@@ -13,8 +13,8 @@\n #    See the License for the specific language governing permissions and\n #    limitations under the License.\n ##############################################################################\n-from collections import namedtuple\n-from typing import Union\n+import sys\n+from typing import Any, Dict, List, Optional, Sequence, Tuple, Union\n \n import networkx as nx\n import numpy as np\n@@ -22,35 +22,64 @@\n from pyquil.quilatom import Parameter, unpack_qubit\n from pyquil.quilbase import Gate\n \n-THETA = Parameter(\"theta\")\n-\"Used as the symbolic parameter in RZ, CPHASE gates.\"\n+if sys.version_info < (3, 7):\n+    from pyquil.external.dataclasses import dataclass\n+else:\n+    from dataclasses import dataclass\n \n DEFAULT_QUBIT_TYPE = \"Xhalves\"\n DEFAULT_EDGE_TYPE = \"CZ\"\n+THETA = Parameter(\"theta\")\n+\"Used as the symbolic parameter in RZ, CPHASE gates.\"\n+\n \n-Qubit = namedtuple(\"Qubit\", [\"id\", \"type\", \"dead\", \"gates\"])\n-Edge = namedtuple(\"Edge\", [\"targets\", \"type\", \"dead\", \"gates\"])\n-_ISA = namedtuple(\"_ISA\", [\"qubits\", \"edges\"])\n+@dataclass\n+class MeasureInfo:\n+    operator: Optional[str] = None\n+    qubit: Optional[int] = None\n+    target: Optional[Union[int, str]] = None\n+    duration: Optional[float] = None\n+    fidelity: Optional[float] = None\n \n-MeasureInfo = namedtuple(\"MeasureInfo\", [\"operator\", \"qubit\", \"target\", \"duration\", \"fidelity\"])\n-GateInfo = namedtuple(\"GateInfo\", [\"operator\", \"parameters\", \"arguments\", \"duration\", \"fidelity\"])\n \n-# make Qubit and Edge arguments optional\n-Qubit.__new__.__defaults__ = (None,) * len(Qubit._fields)\n-Edge.__new__.__defaults__ = (None,) * len(Edge._fields)\n-MeasureInfo.__new__.__defaults__ = (None,) * len(MeasureInfo._fields)\n-GateInfo.__new__.__defaults__ = (None,) * len(GateInfo._fields)\n+@dataclass\n+class GateInfo:\n+    operator: Optional[str] = None\n+    parameters: Optional[Sequence[Union[str, float]]] = None\n+    arguments: Optional[Sequence[Union[str, float]]] = None\n+    duration: Optional[float] = None\n+    fidelity: Optional[float] = None\n \n \n-class ISA(_ISA):\n+@dataclass\n+class Qubit:\n+    id: int\n+    type: Optional[str] = None\n+    dead: Optional[bool] = None\n+    gates: Optional[Sequence[Union[GateInfo, MeasureInfo]]] = None\n+\n+\n+@dataclass\n+class Edge:\n+    targets: Tuple[int, ...]\n+    type: Optional[str] = None\n+    dead: Optional[bool] = None\n+    gates: Optional[Sequence[GateInfo]] = None\n+\n+\n+@dataclass\n+class ISA:\n     \"\"\"\n     Basic Instruction Set Architecture specification.\n \n-    :ivar Sequence[Qubit] qubits: The qubits associated with the ISA.\n-    :ivar Sequence[Edge] edges: The multi-qubit gates.\n+    :ivar qubits: The qubits associated with the ISA.\n+    :ivar edges: The multi-qubit gates.\n     \"\"\"\n \n-    def to_dict(self):\n+    qubits: Sequence[Qubit]\n+    edges: Sequence[Edge]\n+\n+    def to_dict(self) -> Dict[str, Any]:\n         \"\"\"\n         Create a JSON-serializable representation of the ISA.\n \n@@ -80,19 +109,17 @@ def to_dict(self):\n             }\n \n         :return: A dictionary representation of self.\n-        :rtype: Dict[str, Any]\n         \"\"\"\n \n-        def _maybe_configure(o, t):\n-            # type: (Union[Qubit,Edge], str) -> dict\n+        def _maybe_configure(o: Union[Qubit, Edge], t: str) -> Dict[str, Any]:\n             \"\"\"\n             Exclude default values from generated dictionary.\n \n-            :param Union[Qubit,Edge] o: The object to serialize\n-            :param str t: The default value for ``o.type``.\n+            :param o: The object to serialize\n+            :param t: The default value for ``o.type``.\n             :return: d\n             \"\"\"\n-            d = {}\n+            d: Dict[str, Any] = {}\n             if o.gates is not None:\n                 d[\"gates\"] = [\n                     {\n@@ -127,13 +154,12 @@ def _maybe_configure(o, t):\n         }\n \n     @staticmethod\n-    def from_dict(d):\n+    def from_dict(d: Dict[str, Any]) -> \"ISA\":\n         \"\"\"\n         Re-create the ISA from a dictionary representation.\n \n-        :param Dict[str,Any] d: The dictionary representation.\n+        :param d: The dictionary representation.\n         :return: The restored ISA.\n-        :rtype: ISA\n         \"\"\"\n         return ISA(\n             qubits=sorted(\n@@ -150,7 +176,7 @@ def from_dict(d):\n             edges=sorted(\n                 [\n                     Edge(\n-                        targets=[int(q) for q in eid.split(\"-\")],\n+                        targets=tuple(int(q) for q in eid.split(\"-\")),\n                         type=e.get(\"type\", DEFAULT_EDGE_TYPE),\n                         dead=e.get(\"dead\", False),\n                     )\n@@ -161,13 +187,12 @@ def from_dict(d):\n         )\n \n \n-def gates_in_isa(isa):\n+def gates_in_isa(isa: ISA) -> List[Gate]:\n     \"\"\"\n     Generate the full gateset associated with an ISA.\n \n-    :param ISA isa: The instruction set architecture for a QPU.\n+    :param isa: The instruction set architecture for a QPU.\n     :return: A sequence of Gate objects encapsulating all gates compatible with the ISA.\n-    :rtype: Sequence[Gate]\n     \"\"\"\n     gates = []\n     for q in isa.qubits:\n@@ -211,6 +236,7 @@ def gates_in_isa(isa):\n             gates.append(Gate(\"XY\", [THETA], targets))\n             gates.append(Gate(\"XY\", [THETA], targets[::-1]))\n             continue\n+        assert e.type is not None\n         if \"WILDCARD\" in e.type:\n             gates.append(Gate(\"_\", \"_\", targets))\n             gates.append(Gate(\"_\", \"_\", targets[::-1]))\n@@ -220,7 +246,7 @@ def gates_in_isa(isa):\n     return gates\n \n \n-def isa_from_graph(graph: nx.Graph, oneq_type=\"Xhalves\", twoq_type=\"CZ\") -> ISA:\n+def isa_from_graph(graph: nx.Graph, oneq_type: str = \"Xhalves\", twoq_type: str = \"CZ\") -> ISA:\n     \"\"\"\n     Generate an ISA object from a NetworkX graph.\n \n@@ -230,7 +256,7 @@ def isa_from_graph(graph: nx.Graph, oneq_type=\"Xhalves\", twoq_type=\"CZ\") -> ISA:\n     \"\"\"\n     all_qubits = list(range(max(graph.nodes) + 1))\n     qubits = [Qubit(i, type=oneq_type, dead=i not in graph.nodes) for i in all_qubits]\n-    edges = [Edge(sorted((a, b)), type=twoq_type, dead=False) for a, b in graph.edges]\n+    edges = [Edge(tuple(sorted((a, b))), type=twoq_type, dead=False) for a, b in graph.edges]\n     return ISA(qubits, edges)\n \n \ndiff --git a/pyquil/device/_main.py b/pyquil/device/_main.py\n--- a/pyquil/device/_main.py\n+++ b/pyquil/device/_main.py\n@@ -15,7 +15,7 @@\n ##############################################################################\n import warnings\n from abc import ABC, abstractmethod\n-from typing import List, Tuple\n+from typing import Any, Dict, List, Optional, Tuple, Union\n \n import networkx as nx\n import numpy as np\n@@ -42,7 +42,7 @@\n \n class AbstractDevice(ABC):\n     @abstractmethod\n-    def qubits(self):\n+    def qubits(self) -> List[int]:\n         \"\"\"\n         A sorted list of qubits in the device topology.\n         \"\"\"\n@@ -54,7 +54,7 @@ def qubit_topology(self) -> nx.Graph:\n         \"\"\"\n \n     @abstractmethod\n-    def get_isa(self, oneq_type=\"Xhalves\", twoq_type=\"CZ\") -> ISA:\n+    def get_isa(self, oneq_type: str = \"Xhalves\", twoq_type: str = \"CZ\") -> ISA:\n         \"\"\"\n         Construct an ISA suitable for targeting by compilation.\n \n@@ -65,7 +65,7 @@ def get_isa(self, oneq_type=\"Xhalves\", twoq_type=\"CZ\") -> ISA:\n         \"\"\"\n \n     @abstractmethod\n-    def get_specs(self) -> Specs:\n+    def get_specs(self) -> Optional[Specs]:\n         \"\"\"\n         Construct a Specs object required by compilation\n         \"\"\"\n@@ -86,7 +86,7 @@ class Device(AbstractDevice):\n     :ivar NoiseModel noise_model: The noise model for the device.\n     \"\"\"\n \n-    def __init__(self, name, raw):\n+    def __init__(self, name: str, raw: Dict[str, Any]):\n         \"\"\"\n         :param name: name of the device\n         :param raw: raw JSON response from the server with additional information about this device.\n@@ -102,23 +102,25 @@ def __init__(self, name, raw):\n         )\n \n     @property\n-    def isa(self):\n+    def isa(self) -> Optional[ISA]:\n         warnings.warn(\"Accessing the static ISA is deprecated. Use `get_isa`\", DeprecationWarning)\n         return self._isa\n \n-    def qubits(self):\n+    def qubits(self) -> List[int]:\n+        assert self._isa is not None\n         return sorted(q.id for q in self._isa.qubits if not q.dead)\n \n     def qubit_topology(self) -> nx.Graph:\n         \"\"\"\n         The connectivity of qubits in this device given as a NetworkX graph.\n         \"\"\"\n+        assert self._isa is not None\n         return isa_to_graph(self._isa)\n \n-    def get_specs(self):\n+    def get_specs(self) -> Optional[Specs]:\n         return self.specs\n \n-    def get_isa(self, oneq_type=None, twoq_type=None) -> ISA:\n+    def get_isa(self, oneq_type: Optional[str] = None, twoq_type: Optional[str] = None) -> ISA:\n         \"\"\"\n         Construct an ISA suitable for targeting by compilation.\n \n@@ -130,7 +132,7 @@ def get_isa(self, oneq_type=None, twoq_type=None) -> ISA:\n                 \"make an ISA with custom gate types, you'll have to do it by hand.\"\n             )\n \n-        def safely_get(attr, index, default):\n+        def safely_get(attr: str, index: Union[int, Tuple[int, ...]], default: Any) -> Any:\n             if self.specs is None:\n                 return default\n \n@@ -144,8 +146,8 @@ def safely_get(attr, index, default):\n             else:\n                 return default\n \n-        def qubit_type_to_gates(q):\n-            gates = [\n+        def qubit_type_to_gates(q: Qubit) -> List[Union[GateInfo, MeasureInfo]]:\n+            gates: List[Union[GateInfo, MeasureInfo]] = [\n                 MeasureInfo(\n                     operator=\"MEASURE\",\n                     qubit=q.id,\n@@ -200,9 +202,9 @@ def qubit_type_to_gates(q):\n                 ]\n             return gates\n \n-        def edge_type_to_gates(e):\n-            gates = []\n-            if e is None or \"CZ\" in e.type:\n+        def edge_type_to_gates(e: Edge) -> List[GateInfo]:\n+            gates: List[GateInfo] = []\n+            if e is None or isinstance(e.type, str) and \"CZ\" in e.type:\n                 gates += [\n                     GateInfo(\n                         operator=\"CZ\",\n@@ -212,7 +214,7 @@ def edge_type_to_gates(e):\n                         fidelity=safely_get(\"fCZs\", tuple(e.targets), DEFAULT_CZ_FIDELITY),\n                     )\n                 ]\n-            if e is not None and \"ISWAP\" in e.type:\n+            if e is None or isinstance(e.type, str) and \"ISWAP\" in e.type:\n                 gates += [\n                     GateInfo(\n                         operator=\"ISWAP\",\n@@ -222,7 +224,7 @@ def edge_type_to_gates(e):\n                         fidelity=safely_get(\"fISWAPs\", tuple(e.targets), DEFAULT_ISWAP_FIDELITY),\n                     )\n                 ]\n-            if e is not None and \"CPHASE\" in e.type:\n+            if e is None or isinstance(e.type, str) and \"CPHASE\" in e.type:\n                 gates += [\n                     GateInfo(\n                         operator=\"CPHASE\",\n@@ -232,7 +234,7 @@ def edge_type_to_gates(e):\n                         fidelity=safely_get(\"fCPHASEs\", tuple(e.targets), DEFAULT_CPHASE_FIDELITY),\n                     )\n                 ]\n-            if e is not None and \"XY\" in e.type:\n+            if e is None or isinstance(e.type, str) and \"XY\" in e.type:\n                 gates += [\n                     GateInfo(\n                         operator=\"XY\",\n@@ -242,7 +244,7 @@ def edge_type_to_gates(e):\n                         fidelity=safely_get(\"fXYs\", tuple(e.targets), DEFAULT_XY_FIDELITY),\n                     )\n                 ]\n-            if e is not None and \"WILDCARD\" in e.type:\n+            if e is None or isinstance(e.type, str) and \"WILDCARD\" in e.type:\n                 gates += [\n                     GateInfo(\n                         operator=\"_\",\n@@ -254,6 +256,7 @@ def edge_type_to_gates(e):\n                 ]\n             return gates\n \n+        assert self._isa is not None\n         qubits = [\n             Qubit(id=q.id, type=None, dead=q.dead, gates=qubit_type_to_gates(q))\n             for q in self._isa.qubits\n@@ -264,10 +267,10 @@ def edge_type_to_gates(e):\n         ]\n         return ISA(qubits, edges)\n \n-    def __str__(self):\n+    def __str__(self) -> str:\n         return \"<Device {}>\".format(self.name)\n \n-    def __repr__(self):\n+    def __repr__(self) -> str:\n         return str(self)\n \n \n@@ -284,17 +287,17 @@ class NxDevice(AbstractDevice):\n     def __init__(self, topology: nx.Graph) -> None:\n         self.topology = topology\n \n-    def qubit_topology(self):\n+    def qubit_topology(self) -> nx.Graph:\n         return self.topology\n \n-    def get_isa(self, oneq_type=\"Xhalves\", twoq_type=\"CZ\"):\n+    def get_isa(self, oneq_type: str = \"Xhalves\", twoq_type: str = \"CZ\") -> ISA:\n         return isa_from_graph(self.topology, oneq_type=oneq_type, twoq_type=twoq_type)\n \n-    def get_specs(self):\n+    def get_specs(self) -> Specs:\n         return specs_from_graph(self.topology)\n \n     def qubits(self) -> List[int]:\n         return sorted(self.topology.nodes)\n \n-    def edges(self) -> List[Tuple[int, int]]:\n-        return sorted(tuple(sorted(pair)) for pair in self.topology.edges)  # type: ignore\n+    def edges(self) -> List[Tuple[Any, ...]]:\n+        return sorted(tuple(sorted(pair)) for pair in self.topology.edges)\ndiff --git a/pyquil/device/_specs.py b/pyquil/device/_specs.py\n--- a/pyquil/device/_specs.py\n+++ b/pyquil/device/_specs.py\n@@ -13,104 +13,105 @@\n #    See the License for the specific language governing permissions and\n #    limitations under the License.\n ##############################################################################\n+import sys\n import warnings\n-from collections import namedtuple\n+from typing import Any, Dict, Optional, Sequence, Tuple\n \n import networkx as nx\n \n-QubitSpecs = namedtuple(\n-    \"_QubitSpecs\",\n-    [\n-        \"id\",\n-        \"fRO\",\n-        \"f1QRB\",\n-        \"f1QRB_std_err\",\n-        \"f1Q_simultaneous_RB\",\n-        \"f1Q_simultaneous_RB_std_err\",\n-        \"T1\",\n-        \"T2\",\n-        \"fActiveReset\",\n-    ],\n-)\n-EdgeSpecs = namedtuple(\n-    \"_QubitQubitSpecs\",\n-    [\n-        \"targets\",\n-        \"fBellState\",\n-        \"fCZ\",\n-        \"fCZ_std_err\",\n-        \"fCPHASE\",\n-        \"fCPHASE_std_err\",\n-        \"fXY\",\n-        \"fXY_std_err\",\n-        \"fISWAP\",\n-        \"fISWAP_std_err\",\n-    ],\n-)\n-_Specs = namedtuple(\"_Specs\", [\"qubits_specs\", \"edges_specs\"])\n-\n-\n-class Specs(_Specs):\n+if sys.version_info < (3, 7):\n+    from pyquil.external.dataclasses import dataclass\n+else:\n+    from dataclasses import dataclass\n+\n+\n+@dataclass\n+class QubitSpecs:\n+    id: int\n+    fRO: Optional[float]\n+    f1QRB: Optional[float]\n+    f1QRB_std_err: Optional[float]\n+    f1Q_simultaneous_RB: Optional[float]\n+    f1Q_simultaneous_RB_std_err: Optional[float]\n+    T1: Optional[float]\n+    T2: Optional[float]\n+    fActiveReset: Optional[float]\n+\n+\n+@dataclass\n+class EdgeSpecs:\n+    targets: Tuple[int, ...]\n+    fBellState: Optional[float]\n+    fCZ: Optional[float]\n+    fCZ_std_err: Optional[float]\n+    fCPHASE: Optional[float]\n+    fCPHASE_std_err: Optional[float]\n+    fXY: Optional[float]\n+    fXY_std_err: Optional[float]\n+    fISWAP: Optional[float]\n+    fISWAP_std_err: Optional[float]\n+\n+\n+@dataclass\n+class Specs:\n     \"\"\"\n     Basic specifications for the device, such as gate fidelities and coherence times.\n \n-    :ivar List[QubitSpecs] qubits_specs: The specs associated with individual qubits.\n-    :ivar List[EdgesSpecs] edges_specs: The specs associated with edges, or qubit-qubit pairs.\n+    :ivar qubits_specs: The specs associated with individual qubits.\n+    :ivar edges_specs: The specs associated with edges, or qubit-qubit pairs.\n     \"\"\"\n \n-    def f1QRBs(self):\n+    qubits_specs: Sequence[QubitSpecs]\n+    edges_specs: Sequence[EdgeSpecs]\n+\n+    def f1QRBs(self) -> Dict[int, Optional[float]]:\n         \"\"\"\n         Get a dictionary of single-qubit randomized benchmarking fidelities (for individual gate\n         operation, normalized to unity) from the specs, keyed by qubit index.\n \n         :return: A dictionary of 1Q RB fidelities, normalized to unity.\n-        :rtype: Dict[int, float]\n         \"\"\"\n         return {qs.id: qs.f1QRB for qs in self.qubits_specs}\n \n-    def f1QRB_std_errs(self):\n+    def f1QRB_std_errs(self) -> Dict[int, Optional[float]]:\n         \"\"\"\n         Get a dictionary of the standard errors of single-qubit randomized\n         benchmarking fidelities (for individual gate operation, normalized to unity)\n         from the specs, keyed by qubit index.\n \n         :return: A dictionary of 1Q RB fidelity standard errors, normalized to unity.\n-        :rtype: Dict[int, float]\n         \"\"\"\n         return {qs.id: qs.f1QRB_std_err for qs in self.qubits_specs}\n \n-    def f1Q_simultaneous_RBs(self):\n+    def f1Q_simultaneous_RBs(self) -> Dict[int, Optional[float]]:\n         \"\"\"\n         Get a dictionary of single-qubit randomized benchmarking fidelities (for simultaneous gate\n         operation across the chip, normalized to unity) from the specs, keyed by qubit index.\n \n         :return: A dictionary of simultaneous 1Q RB fidelities, normalized to unity.\n-        :rtype: Dict[int, float]\n         \"\"\"\n         return {qs.id: qs.f1Q_simultaneous_RB for qs in self.qubits_specs}\n \n-    def f1Q_simultaneous_RB_std_errs(self):\n+    def f1Q_simultaneous_RB_std_errs(self) -> Dict[int, Optional[float]]:\n         \"\"\"\n         Get a dictionary of the standard errors of single-qubit randomized\n         benchmarking fidelities (for simultaneous gate operation across the chip, normalized to\n         unity) from the specs, keyed by qubit index.\n \n         :return: A dictionary of simultaneous 1Q RB fidelity standard errors, normalized to unity.\n-        :rtype: Dict[int, float]\n         \"\"\"\n         return {qs.id: qs.f1Q_simultaneous_RB_std_err for qs in self.qubits_specs}\n \n-    def fROs(self):\n+    def fROs(self) -> Dict[int, Optional[float]]:\n         \"\"\"\n         Get a dictionary of single-qubit readout fidelities (normalized to unity)\n         from the specs, keyed by qubit index.\n \n         :return: A dictionary of RO fidelities, normalized to unity.\n-        :rtype: Dict[int, float]\n         \"\"\"\n         return {qs.id: qs.fRO for qs in self.qubits_specs}\n \n-    def fActiveResets(self):\n+    def fActiveResets(self) -> Dict[int, Optional[float]]:\n         \"\"\"\n         Get a dictionary of single-qubit active reset fidelities (normalized to unity) from the\n         specs, keyed by qubit index.\n@@ -119,31 +120,28 @@ def fActiveResets(self):\n         \"\"\"\n         return {qs.id: qs.fActiveReset for qs in self.qubits_specs}\n \n-    def T1s(self):\n+    def T1s(self) -> Dict[int, Optional[float]]:\n         \"\"\"\n         Get a dictionary of T1s (in seconds) from the specs, keyed by qubit index.\n \n         :return: A dictionary of T1s, in seconds.\n-        :rtype: Dict[int, float]\n         \"\"\"\n         return {qs.id: qs.T1 for qs in self.qubits_specs}\n \n-    def T2s(self):\n+    def T2s(self) -> Dict[int, Optional[float]]:\n         \"\"\"\n         Get a dictionary of T2s (in seconds) from the specs, keyed by qubit index.\n \n         :return: A dictionary of T2s, in seconds.\n-        :rtype: Dict[int, float]\n         \"\"\"\n         return {qs.id: qs.T2 for qs in self.qubits_specs}\n \n-    def fBellStates(self):\n+    def fBellStates(self) -> Dict[Tuple[int, ...], Optional[float]]:\n         \"\"\"\n         Get a dictionary of two-qubit Bell state fidelities (normalized to unity)\n         from the specs, keyed by targets (qubit-qubit pairs).\n \n         :return: A dictionary of Bell state fidelities, normalized to unity.\n-        :rtype: Dict[tuple(int, int), float]\n         \"\"\"\n         warnings.warn(\n             DeprecationWarning(\n@@ -153,73 +151,66 @@ def fBellStates(self):\n         )\n         return {tuple(es.targets): es.fBellState for es in self.edges_specs}\n \n-    def fCZs(self):\n+    def fCZs(self) -> Dict[Tuple[int, ...], Optional[float]]:\n         \"\"\"\n         Get a dictionary of CZ fidelities (normalized to unity) from the specs,\n         keyed by targets (qubit-qubit pairs).\n \n         :return: A dictionary of CZ fidelities, normalized to unity.\n-        :rtype: Dict[tuple(int, int), float]\n         \"\"\"\n         return {tuple(es.targets): es.fCZ for es in self.edges_specs}\n \n-    def fISWAPs(self):\n+    def fISWAPs(self) -> Dict[Tuple[int, ...], Optional[float]]:\n         \"\"\"\n         Get a dictionary of ISWAP fidelities (normalized to unity) from the specs,\n         keyed by targets (qubit-qubit pairs).\n \n         :return: A dictionary of ISWAP fidelities, normalized to unity.\n-        :rtype: Dict[tuple(int, int), float]\n         \"\"\"\n         return {tuple(es.targets): es.fISWAP for es in self.edges_specs}\n \n-    def fISWAP_std_errs(self):\n+    def fISWAP_std_errs(self) -> Dict[Tuple[int, ...], Optional[float]]:\n         \"\"\"\n         Get a dictionary of the standard errors of the ISWAP fidelities from the specs,\n         keyed by targets (qubit-qubit pairs).\n \n         :return: A dictionary of ISWAP fidelities, normalized to unity.\n-        :rtype: Dict[tuple(int, int), float]\n         \"\"\"\n         return {tuple(es.targets): es.fISWAP_std_err for es in self.edges_specs}\n \n-    def fXYs(self):\n+    def fXYs(self) -> Dict[Tuple[int, ...], Optional[float]]:\n         \"\"\"\n         Get a dictionary of XY(pi) fidelities (normalized to unity) from the specs,\n         keyed by targets (qubit-qubit pairs).\n \n         :return: A dictionary of XY/2 fidelities, normalized to unity.\n-        :rtype: Dict[tuple(int, int), float]\n         \"\"\"\n         return {tuple(es.targets): es.fXY for es in self.edges_specs}\n \n-    def fXY_std_errs(self):\n+    def fXY_std_errs(self) -> Dict[Tuple[int, ...], Optional[float]]:\n         \"\"\"\n         Get a dictionary of the standard errors of the XY fidelities from the specs,\n         keyed by targets (qubit-qubit pairs).\n \n         :return: A dictionary of XY fidelities, normalized to unity.\n-        :rtype: Dict[tuple(int, int), float]\n         \"\"\"\n         return {tuple(es.targets): es.fXY_std_err for es in self.edges_specs}\n \n-    def fCZ_std_errs(self):\n+    def fCZ_std_errs(self) -> Dict[Tuple[int, ...], Optional[float]]:\n         \"\"\"\n         Get a dictionary of the standard errors of the CZ fidelities from the specs,\n         keyed by targets (qubit-qubit pairs).\n \n         :return: A dictionary of CZ fidelities, normalized to unity.\n-        :rtype: Dict[tuple(int, int), float]\n         \"\"\"\n         return {tuple(es.targets): es.fCZ_std_err for es in self.edges_specs}\n \n-    def fCPHASEs(self):\n+    def fCPHASEs(self) -> Dict[Tuple[int, ...], Optional[float]]:\n         \"\"\"\n         Get a dictionary of CPHASE fidelities (normalized to unity) from the specs,\n         keyed by targets (qubit-qubit pairs).\n \n         :return: A dictionary of CPHASE fidelities, normalized to unity.\n-        :rtype: Dict[tuple(int, int), float]\n         \"\"\"\n         warnings.warn(\n             DeprecationWarning(\n@@ -229,7 +220,7 @@ def fCPHASEs(self):\n         )\n         return {tuple(es.targets): es.fCPHASE for es in self.edges_specs}\n \n-    def to_dict(self):\n+    def to_dict(self) -> Dict[str, Any]:\n         \"\"\"\n         Create a JSON-serializable representation of the device Specs.\n \n@@ -270,7 +261,6 @@ def to_dict(self):\n             }\n \n         :return: A dctionary representation of self.\n-        :rtype: Dict[str, Any]\n         \"\"\"\n         return {\n             \"1Q\": {\n@@ -303,13 +293,12 @@ def to_dict(self):\n         }\n \n     @staticmethod\n-    def from_dict(d):\n+    def from_dict(d: Dict[str, Any]) -> \"Specs\":\n         \"\"\"\n         Re-create the Specs from a dictionary representation.\n \n-        :param Dict[str, Any] d: The dictionary representation.\n+        :param d: The dictionary representation.\n         :return: The restored Specs.\n-        :rtype: Specs\n         \"\"\"\n         return Specs(\n             qubits_specs=sorted(\n@@ -332,7 +321,7 @@ def from_dict(d):\n             edges_specs=sorted(\n                 [\n                     EdgeSpecs(\n-                        targets=[int(q) for q in e.split(\"-\")],\n+                        targets=tuple(int(q) for q in e.split(\"-\")),\n                         fBellState=especs.get(\"fBellState\"),\n                         fCZ=especs.get(\"fCZ\"),\n                         fCZ_std_err=especs.get(\"fCZ_std_err\"),\n@@ -350,7 +339,7 @@ def from_dict(d):\n         )\n \n \n-def specs_from_graph(graph: nx.Graph):\n+def specs_from_graph(graph: nx.Graph) -> Specs:\n     \"\"\"\n     Generate a Specs object from a NetworkX graph with placeholder values for the actual specs.\n \n", "test_patch": "diff --git a/pyquil/device/tests/test_device.py b/pyquil/device/tests/test_device.py\n--- a/pyquil/device/tests/test_device.py\n+++ b/pyquil/device/tests/test_device.py\n@@ -55,10 +55,10 @@ def test_isa(isa_dict):\n             Qubit(id=3, type=\"Xhalves\", dead=True),\n         ],\n         edges=[\n-            Edge(targets=[0, 1], type=\"CZ\", dead=False),\n-            Edge(targets=[0, 2], type=\"CPHASE\", dead=False),\n-            Edge(targets=[0, 3], type=\"CZ\", dead=True),\n-            Edge(targets=[1, 2], type=\"ISWAP\", dead=False),\n+            Edge(targets=(0, 1), type=\"CZ\", dead=False),\n+            Edge(targets=(0, 2), type=\"CPHASE\", dead=False),\n+            Edge(targets=(0, 3), type=\"CZ\", dead=True),\n+            Edge(targets=(1, 2), type=\"ISWAP\", dead=False),\n         ],\n     )\n     assert isa == ISA.from_dict(isa.to_dict())\n@@ -115,7 +115,7 @@ def test_specs(specs_dict):\n         ],\n         edges_specs=[\n             EdgeSpecs(\n-                targets=[0, 1],\n+                targets=(0, 1),\n                 fBellState=0.90,\n                 fCZ=0.89,\n                 fCZ_std_err=0.01,\n@@ -127,7 +127,7 @@ def test_specs(specs_dict):\n                 fCPHASE_std_err=None,\n             ),\n             EdgeSpecs(\n-                targets=[0, 2],\n+                targets=(0, 2),\n                 fBellState=0.92,\n                 fCZ=0.91,\n                 fCZ_std_err=0.20,\n@@ -139,7 +139,7 @@ def test_specs(specs_dict):\n                 fCPHASE_std_err=None,\n             ),\n             EdgeSpecs(\n-                targets=[0, 3],\n+                targets=(0, 3),\n                 fBellState=0.89,\n                 fCZ=0.88,\n                 fCZ_std_err=0.03,\n@@ -151,7 +151,7 @@ def test_specs(specs_dict):\n                 fCPHASE_std_err=None,\n             ),\n             EdgeSpecs(\n-                targets=[1, 2],\n+                targets=(1, 2),\n                 fBellState=0.91,\n                 fCZ=0.90,\n                 fCZ_std_err=0.12,\ndiff --git a/pyquil/tests/test_quantum_computer.py b/pyquil/tests/test_quantum_computer.py\n--- a/pyquil/tests/test_quantum_computer.py\n+++ b/pyquil/tests/test_quantum_computer.py\n@@ -194,8 +194,8 @@ def test_device_stuff():\n     assert nx.is_isomorphic(qc.qubit_topology(), topo)\n \n     isa = qc.get_isa(twoq_type=\"CPHASE\")\n-    assert sorted(isa.edges)[0].type == \"CPHASE\"\n-    assert sorted(isa.edges)[0].targets == [0, 4]\n+    assert isa.edges[0].type == \"CPHASE\"\n+    assert isa.edges[0].targets == (0, 4)\n \n \n def test_run(forest):\n", "problem_statement": "Change the namedtuples in device.py to dataclasses\nAs discussed in #961, using `dataclasses` instead of `namedtuples` would greatly improve readability, understanding, and use of the structures in the `device` module.\n", "hints_text": "", "created_at": 1577, "language": "python", "label": "Hard"}
{"repo": "pallets-eco/flask-wtf", "pull_number": 512, "instance_id": "pallets-eco__flask-wtf-512", "issue_numbers": ["511"], "base_commit": "b86d5c6516344f85f930cdd710b14d54ac88415c", "patch": "diff --git a/src/flask_wtf/__init__.py b/src/flask_wtf/__init__.py\n--- a/src/flask_wtf/__init__.py\n+++ b/src/flask_wtf/__init__.py\n@@ -5,4 +5,4 @@\n from .recaptcha import RecaptchaField\n from .recaptcha import RecaptchaWidget\n \n-__version__ = \"1.0.0\"\n+__version__ = \"1.0.1.dev0\"\ndiff --git a/src/flask_wtf/form.py b/src/flask_wtf/form.py\n--- a/src/flask_wtf/form.py\n+++ b/src/flask_wtf/form.py\n@@ -56,7 +56,7 @@ def wrap_formdata(self, form, formdata):\n                         return CombinedMultiDict((request.files, request.form))\n                     elif request.form:\n                         return request.form\n-                    elif request.get_json():\n+                    elif request.is_json:\n                         return ImmutableMultiDict(request.get_json())\n \n                 return None\ndiff --git a/src/flask_wtf/recaptcha/validators.py b/src/flask_wtf/recaptcha/validators.py\n--- a/src/flask_wtf/recaptcha/validators.py\n+++ b/src/flask_wtf/recaptcha/validators.py\n@@ -30,7 +30,7 @@ def __call__(self, form, field):\n         if current_app.testing:\n             return True\n \n-        if request.json:\n+        if request.is_json:\n             response = request.json.get(\"g-recaptcha-response\", \"\")\n         else:\n             response = request.form.get(\"g-recaptcha-response\", \"\")\n", "test_patch": "diff --git a/tests/test_recaptcha.py b/tests/test_recaptcha.py\n--- a/tests/test_recaptcha.py\n+++ b/tests/test_recaptcha.py\n@@ -80,7 +80,8 @@ def test_render_custom_args(app):\n     app.config[\"RECAPTCHA_DATA_ATTRS\"] = {\"red\": \"blue\"}\n     f = RecaptchaForm()\n     render = f.recaptcha()\n-    assert \"?key=%28value%29\" in render\n+    # new versions of url_encode allow more characters\n+    assert \"?key=(value)\" in render or \"?key=%28value%29\" in render\n     assert 'data-red=\"blue\"' in render\n \n \n", "problem_statement": "Update to Request.get_json() in Werkzeug 2.1.0 breaks empty forms\nSimilar to #510 - the get_json() change in Werkzeug 2.1.0 https://github.com/pallets/werkzeug/issues/2339 breaks any empty submitted form (not json).\r\nFrom form.py:\r\n   \r\n```\r\n def wrap_formdata(self, form, formdata):\r\n            if formdata is _Auto:\r\n                if _is_submitted():\r\n                    if request.files:\r\n                        return CombinedMultiDict((request.files, request.form))\r\n                    elif request.form:\r\n                        return request.form\r\n                    elif request.get_json():\r\n                        return ImmutableMultiDict(request.get_json())\r\n```\r\n\r\n\r\nIf the form is an empty ImmutableMultiDict - it falls into the get_json() code which is then checking that the content-type header has been set to application/json.\r\n\r\nPossible solution would be to change elif request.get_json() to elif request.is_json()\r\n\r\n\r\nExpected Behavior:\r\n\r\nEmpty form submits should be allowed as they were. In the case of an empty form - None should be returned from the wrapper.\r\n\r\nEnvironment:\r\n\r\n- Python version: 3.8\r\n- Flask-WTF version: 1.0.0\r\n- Flask version: 2.1\r\n\n", "hints_text": "", "created_at": 1648, "language": "python", "label": "Easy"}
{"repo": "pytest-dev/pytest-django", "pull_number": 979, "instance_id": "pytest-dev__pytest-django-979", "issue_numbers": ["978"], "base_commit": "b3b679f2cab9dad70e318f252751ff7659b951d1", "patch": "diff --git a/pytest_django/fixtures.py b/pytest_django/fixtures.py\n--- a/pytest_django/fixtures.py\n+++ b/pytest_django/fixtures.py\n@@ -167,7 +167,7 @@ def _django_db_helper(\n             serialized_rollback,\n         ) = False, False, None, False\n \n-    transactional = transactional or (\n+    transactional = transactional or reset_sequences or (\n         \"transactional_db\" in request.fixturenames\n         or \"live_server\" in request.fixturenames\n     )\n", "test_patch": "diff --git a/tests/test_database.py b/tests/test_database.py\n--- a/tests/test_database.py\n+++ b/tests/test_database.py\n@@ -287,11 +287,16 @@ def test_reset_sequences_disabled(self, request) -> None:\n         marker = request.node.get_closest_marker(\"django_db\")\n         assert not marker.kwargs\n \n-    @pytest.mark.django_db(transaction=True, reset_sequences=True)\n+    @pytest.mark.django_db(reset_sequences=True)\n     def test_reset_sequences_enabled(self, request) -> None:\n         marker = request.node.get_closest_marker(\"django_db\")\n         assert marker.kwargs[\"reset_sequences\"]\n \n+    @pytest.mark.django_db(transaction=True, reset_sequences=True)\n+    def test_transaction_reset_sequences_enabled(self, request) -> None:\n+        marker = request.node.get_closest_marker(\"django_db\")\n+        assert marker.kwargs[\"reset_sequences\"]\n+\n     @pytest.mark.django_db(databases=['default', 'replica', 'second'])\n     def test_databases(self, request) -> None:\n         marker = request.node.get_closest_marker(\"django_db\")\n", "problem_statement": "4.5.1: reset_sequences=True fails on MariaDB/MySQL\nFirstly, thanks for maintaining such a powerful and useful testing library for Django.\r\n\r\nOn to the bug:\r\n\r\n- OS: Windows 10\r\n- Python: 3.9.1\r\n- pytest-6.2.5\r\n- py-1.11.0\r\n- pluggy-1.0.0\r\n- Django: 3.2.10\r\n\r\nExample:\r\n\r\n    @pytest.mark.django_db(reset_sequences=True)\r\n    def test_reset_sequences():\r\n        assert True\r\n\r\nOutput:\r\n\r\n    ERROR my_test.py::test_reset_sequences - AssertionError: reset_sequences cannot be used on TestCase instances\n", "hints_text": "It's missing `transaction=True`. Needs a better error message.\r\n\r\nDid it work on pytest-django 4.4.0? If yes, then I'll make it work again.\nThanks for the fast response! Yes it works on 4.5.0", "created_at": 1638, "language": "python", "label": "Easy"}
{"repo": "rigetti/pyquil", "pull_number": 177, "instance_id": "rigetti__pyquil-177", "issue_numbers": ["176"], "base_commit": "e10881922b799ab015f750d07156f03b2bca7046", "patch": "diff --git a/pyquil/kraus.py b/pyquil/kraus.py\n--- a/pyquil/kraus.py\n+++ b/pyquil/kraus.py\n@@ -50,9 +50,8 @@ def _create_kraus_pragmas(name, qubit_indices, kraus_ops):\n     :rtype: str\n     \"\"\"\n \n-    prefix = \"PRAGMA ADD-KRAUS {} {}\".format(name, \" \".join(map(str, qubit_indices)))\n     pragmas = [Pragma(\"ADD-KRAUS\",\n-                      qubit_indices,\n+                      [name] + list(qubit_indices),\n                       \"({})\".format(\" \".join(map(format_parameter, np.ravel(k)))))\n                for k in kraus_ops]\n     return pragmas\n", "test_patch": "diff --git a/pyquil/tests/test_quil.py b/pyquil/tests/test_quil.py\n--- a/pyquil/tests/test_quil.py\n+++ b/pyquil/tests/test_quil.py\n@@ -520,11 +520,11 @@ def test_kraus():\n \n     ret = pq.out()\n     assert ret == \"\"\"X 0\n-PRAGMA ADD-KRAUS 0 \"(0.0+0.0i 1.0+0.0i 1.0+0.0i 0.0+0.0i)\"\n-PRAGMA ADD-KRAUS 0 \"(0.0+0.0i 0.0+0.0i 0.0+0.0i 0.0+0.0i)\"\n+PRAGMA ADD-KRAUS X 0 \"(0.0+0.0i 1.0+0.0i 1.0+0.0i 0.0+0.0i)\"\n+PRAGMA ADD-KRAUS X 0 \"(0.0+0.0i 0.0+0.0i 0.0+0.0i 0.0+0.0i)\"\n X 1\n-PRAGMA ADD-KRAUS 1 \"(0.0+0.0i 1.0+0.0i 1.0+0.0i 0.0+0.0i)\"\n-PRAGMA ADD-KRAUS 1 \"(0.0+0.0i 0.0+0.0i 0.0+0.0i 0.0+0.0i)\"\n+PRAGMA ADD-KRAUS X 1 \"(0.0+0.0i 1.0+0.0i 1.0+0.0i 0.0+0.0i)\"\n+PRAGMA ADD-KRAUS X 1 \"(0.0+0.0i 0.0+0.0i 0.0+0.0i 0.0+0.0i)\"\n \"\"\"\n     # test error due to bad normalization\n     with pytest.raises(ValueError):\n", "problem_statement": "`ADD-KRAUS` does not pass the gate name to `Pragma` constructor\nAs is `ADD-KRAUS` is broken, but the fix is easy.\n", "hints_text": "", "created_at": 1510, "language": "python", "label": "Hard"}
{"repo": "pytest-dev/pytest-django", "pull_number": 323, "instance_id": "pytest-dev__pytest-django-323", "issue_numbers": ["322"], "base_commit": "274efdfd48e806830e08d003d93af1e6070eb2b3", "patch": "diff --git a/pytest_django/plugin.py b/pytest_django/plugin.py\n--- a/pytest_django/plugin.py\n+++ b/pytest_django/plugin.py\n@@ -539,6 +539,20 @@ def _template_string_if_invalid_marker(request):\n             else:\n                 dj_settings.TEMPLATE_STRING_IF_INVALID.fail = False\n \n+\n+@pytest.fixture(autouse=True, scope='function')\n+def _django_clear_site_cache():\n+    \"\"\"Clears ``django.contrib.sites.models.SITE_CACHE`` to avoid\n+    unexpected behavior with cached site objects.\n+    \"\"\"\n+\n+    if django_settings_is_configured():\n+        from django.conf import settings as dj_settings\n+\n+        if 'django.contrib.sites' in dj_settings.INSTALLED_APPS:\n+            from django.contrib.sites.models import Site\n+            Site.objects.clear_cache()\n+\n # ############### Helper Functions ################\n \n \n", "test_patch": "diff --git a/tests/test_environment.py b/tests/test_environment.py\n--- a/tests/test_environment.py\n+++ b/tests/test_environment.py\n@@ -3,9 +3,12 @@\n import os\n \n import pytest\n+from django.contrib.sites.models import Site\n+from django.contrib.sites import models as site_models\n from django.core import mail\n from django.db import connection\n from django.test import TestCase\n+from pytest_django.lazy_django import get_django_version\n \n from pytest_django_test.app.models import Item\n \n@@ -215,3 +218,26 @@ def test_more_verbose_with_vv_and_reusedb(self, testdir):\n             \"*PASSED*\"])\n         assert (\"*Destroying test database for alias 'default' ('*')...*\"\n                 not in result.stdout.str())\n+\n+\n+@pytest.mark.skipif(\n+    get_django_version() < (1, 8),\n+    reason='Django 1.7 requires settings.SITE_ID to be set, so this test is invalid'\n+)\n+@pytest.mark.django_db\n+@pytest.mark.parametrize('site_name', ['site1', 'site2'])\n+def test_clear_site_cache(site_name, rf, monkeypatch):\n+    request = rf.get('/')\n+    monkeypatch.setattr(request, 'get_host', lambda: 'foo.com')\n+    Site.objects.create(domain='foo.com', name=site_name)\n+    assert Site.objects.get_current(request=request).name == site_name\n+\n+\n+@pytest.mark.django_db\n+@pytest.mark.parametrize('site_name', ['site1', 'site2'])\n+def test_clear_site_cache_check_site_cache_size(site_name, settings):\n+    assert len(site_models.SITE_CACHE) == 0\n+    site = Site.objects.create(domain='foo.com', name=site_name)\n+    settings.SITE_ID = site.id\n+    assert Site.objects.get_current() == site\n+    assert len(site_models.SITE_CACHE) == 1\n", "problem_statement": "Tests with django sites framework onetoonefield causes unexpected behavior\nAssume you have a model:\n\n```\nclass Customer(models.Model):\n    site = models.OneToOneField('sites.Site')\n```\n\nAnd when using the sites middleware, without setting SITE_ID, the site is looked up and cached based on the requests host information: https://github.com/django/django/blob/master/django/contrib/sites/models.py#L12\n\nThis causes unexpected behavior if testing a multi tenant site, as the request.site object will be the one from the SITE_CACHE, that might have an already populated _request.site.customer_ from previous execution.\n\nI will submit a proposal for fixing this, as it can cause plenty of pain when debugging :)\n\n", "hints_text": "", "created_at": 1459, "language": "python", "label": "Easy"}
{"repo": "pytest-dev/pytest-django", "pull_number": 1189, "instance_id": "pytest-dev__pytest-django-1189", "issue_numbers": ["1188"], "base_commit": "6d5c272519037031f0b68d78dca44727b860d65e", "patch": "diff --git a/pytest_django/fixtures.py b/pytest_django/fixtures.py\n--- a/pytest_django/fixtures.py\n+++ b/pytest_django/fixtures.py\n@@ -129,8 +129,8 @@ def _get_databases_for_test(test: pytest.Item) -> tuple[Iterable[str], bool]:\n \n     test_cls = getattr(test, \"cls\", None)\n     if test_cls and issubclass(test_cls, TransactionTestCase):\n-        serialized_rollback = getattr(test, \"serialized_rollback\", False)\n-        databases = getattr(test, \"databases\", None)\n+        serialized_rollback = getattr(test_cls, \"serialized_rollback\", False)\n+        databases = getattr(test_cls, \"databases\", None)\n     else:\n         fixtures = getattr(test, \"fixturenames\", ())\n         marker_db = test.get_closest_marker(\"django_db\")\n", "test_patch": "diff --git a/tests/test_database.py b/tests/test_database.py\n--- a/tests/test_database.py\n+++ b/tests/test_database.py\n@@ -432,6 +432,28 @@ def test_db_access_3(self):\n     )\n \n \n+def test_django_testcase_multi_db(django_pytester: DjangoPytester) -> None:\n+    \"\"\"Test that Django TestCase multi-db support works.\"\"\"\n+\n+    django_pytester.create_test_module(\n+        \"\"\"\n+        import pytest\n+        from django.test import TestCase\n+        from .app.models import Item, SecondItem\n+\n+        class TestCase(TestCase):\n+            databases = [\"default\", \"second\"]\n+\n+            def test_db_access(self):\n+                Item.objects.count() == 0\n+                SecondItem.objects.count() == 0\n+        \"\"\"\n+    )\n+\n+    result = django_pytester.runpytest_subprocess(\"-v\", \"--reuse-db\")\n+    result.assert_outcomes(passed=1)\n+\n+\n class Test_database_blocking:\n     def test_db_access_in_conftest(self, django_pytester: DjangoPytester) -> None:\n         \"\"\"Make sure database access in conftest module is prohibited.\"\"\"\n", "problem_statement": "django.test.TestCase with multiples database doesn't create secondary db in 4.11.0\n\nWith the 4.11.0 version, if a Django TestCase is setup to use multiples database with the `databases` attribute, only the default database is created on runtime.\n\n```\nclass Test(TestCase):\n    databases = {\"default\", \"db2\"}\n```\n\nTrying to add the decorator `@pytest.mark.django_db(databases=['default', 'db2'])`  on the class doesn't work either.\n\nThe problem seems to come from the line [133 in pytest_django/fixtures.py](https://github.com/pytest-dev/pytest-django/blob/6d5c272519037031f0b68d78dca44727b860d65e/pytest_django/fixtures.py#L133)\n\nThe line tries to get an attribute from the test function and not from the test class.\n\n```\n        databases = getattr(test_cls, \"databases\", None)\n```\nThis fixes the problem with Django TestCase without altering pytest.mark.django_db\n\n\nPS : the line 132 (serialized_rollback) seems to be broken also. I have not tried using _serialized_rollback_, so I can't confirm.\n", "hints_text": "Ouch, silly mistake! I will fix and do a patch release. Thanks for the report.", "created_at": 1743, "language": "python", "label": "Hard"}
{"repo": "rigetti/pyquil", "pull_number": 1492, "instance_id": "rigetti__pyquil-1492", "issue_numbers": ["1486"], "base_commit": "76c95c2b5ccdca93cce6f2b972dafda5a680ee13", "patch": "diff --git a/pyquil/api/_abstract_compiler.py b/pyquil/api/_abstract_compiler.py\n--- a/pyquil/api/_abstract_compiler.py\n+++ b/pyquil/api/_abstract_compiler.py\n@@ -102,12 +102,15 @@ def __init__(\n         self._timeout = timeout\n \n         self._client_configuration = client_configuration or QCSClientConfiguration.load()\n-        self._compiler_client = CompilerClient(client_configuration=self._client_configuration, request_timeout=timeout)\n \n         if event_loop is None:\n             event_loop = asyncio.get_event_loop()\n         self._event_loop = event_loop\n \n+        self._compiler_client = CompilerClient(\n+            client_configuration=self._client_configuration, request_timeout=timeout, event_loop=self._event_loop\n+        )\n+\n         self._connect()\n \n     def get_version_info(self) -> Dict[str, Any]:\ndiff --git a/pyquil/api/_compiler_client.py b/pyquil/api/_compiler_client.py\n--- a/pyquil/api/_compiler_client.py\n+++ b/pyquil/api/_compiler_client.py\n@@ -13,10 +13,12 @@\n #    See the License for the specific language governing permissions and\n #    limitations under the License.\n ##############################################################################\n+import asyncio\n from contextlib import contextmanager\n from dataclasses import dataclass\n-from typing import Iterator, Optional, List\n+from typing import Iterator, List, Optional\n \n+import qcs_sdk\n import rpcq\n from qcs_api_client.client import QCSClientConfiguration\n from rpcq.messages import TargetDevice as TargetQuantumProcessor\n@@ -151,7 +153,13 @@ class CompilerClient:\n     Client for making requests to a Quil compiler.\n     \"\"\"\n \n-    def __init__(self, *, client_configuration: QCSClientConfiguration, request_timeout: float = 10.0) -> None:\n+    def __init__(\n+        self,\n+        *,\n+        client_configuration: QCSClientConfiguration,\n+        request_timeout: float = 10.0,\n+        event_loop: Optional[asyncio.AbstractEventLoop] = None,\n+    ) -> None:\n         \"\"\"\n         Instantiate a new compiler client.\n \n@@ -164,17 +172,19 @@ def __init__(self, *, client_configuration: QCSClientConfiguration, request_time\n \n         self.base_url = base_url\n         self.timeout = request_timeout\n+        if event_loop is None:\n+            event_loop = asyncio.get_event_loop()\n+        self._event_loop = event_loop\n \n     def get_version(self) -> str:\n         \"\"\"\n         Get version info for compiler server.\n         \"\"\"\n-        with self._rpcq_client() as rpcq_client:  # type: rpcq.Client\n-            version: Optional[str] = rpcq_client.call(\"get_version_info\").get(\"quilc\")\n-            if version is None:\n-                raise ValueError(\"Expected compiler version info to contain a 'quilc' field.\")\n \n-            return version\n+        async def _get_quilc_version() -> str:\n+            return await qcs_sdk.get_quilc_version()\n+\n+        return self._event_loop.run_until_complete(_get_quilc_version())\n \n     def compile_to_native_quil(self, request: CompileToNativeQuilRequest) -> CompileToNativeQuilResponse:\n         \"\"\"\n", "test_patch": "diff --git a/test/unit/conftest.py b/test/unit/conftest.py\n--- a/test/unit/conftest.py\n+++ b/test/unit/conftest.py\n@@ -1,6 +1,5 @@\n import json\n import os\n-from pathlib import Path\n from typing import Dict, Any\n \n import numpy as np\ndiff --git a/test/unit/test_compiler_client.py b/test/unit/test_compiler_client.py\n--- a/test/unit/test_compiler_client.py\n+++ b/test/unit/test_compiler_client.py\n@@ -14,6 +14,14 @@\n #    limitations under the License.\n ##############################################################################\n \n+from test.unit.utils import patch_rpcq_client\n+\n+try:\n+    from unittest.mock import AsyncMock\n+except ImportError:  # 3.7 requires this backport of AsyncMock\n+    from asyncmock import AsyncMock\n+\n+import qcs_sdk\n import rpcq\n from _pytest.monkeypatch import MonkeyPatch\n from pytest import raises\n@@ -22,16 +30,15 @@\n \n from pyquil.api._compiler_client import (\n     CompilerClient,\n-    GenerateRandomizedBenchmarkingSequenceResponse,\n-    GenerateRandomizedBenchmarkingSequenceRequest,\n-    ConjugatePauliByCliffordResponse,\n+    CompileToNativeQuilRequest,\n+    CompileToNativeQuilResponse,\n     ConjugatePauliByCliffordRequest,\n+    ConjugatePauliByCliffordResponse,\n+    GenerateRandomizedBenchmarkingSequenceRequest,\n+    GenerateRandomizedBenchmarkingSequenceResponse,\n     NativeQuilMetadataResponse,\n-    CompileToNativeQuilResponse,\n-    CompileToNativeQuilRequest,\n )\n from pyquil.external.rpcq import CompilerISA, compiler_isa_to_target_quantum_processor\n-from test.unit.utils import patch_rpcq_client\n \n \n def test_init__sets_base_url_and_timeout(monkeypatch: MonkeyPatch):\n@@ -70,12 +77,11 @@ def test_get_version__returns_version(mocker: MockerFixture):\n     client_configuration = QCSClientConfiguration.load()\n     compiler_client = CompilerClient(client_configuration=client_configuration)\n \n-    rpcq_client = patch_rpcq_client(mocker=mocker, return_value={\"quilc\": \"1.2.3\"})\n+    version_mock = AsyncMock(return_value=\"1.2.3\")\n+    get_quilc_version_mock = mocker.patch(\"qcs_sdk.get_quilc_version\", version_mock)\n \n     assert compiler_client.get_version() == \"1.2.3\"\n-    rpcq_client.call.assert_called_once_with(\n-        \"get_version_info\"\n-    )\n+    assert get_quilc_version_mock.call_count == 1\n \n \n def test_compile_to_native_quil__returns_native_quil(\n@@ -99,7 +105,7 @@ def test_compile_to_native_quil__returns_native_quil(\n                 topological_swaps=3,\n                 qpu_runtime_estimation=0.1618,\n             ),\n-        )\n+        ),\n     )\n     request = CompileToNativeQuilRequest(\n         program=\"some-program\",\n@@ -130,12 +136,12 @@ def test_compile_to_native_quil__returns_native_quil(\n     )\n \n \n-def test_conjugate_pauli_by_clifford__returns_conjugation_result(\n-    mocker: MockerFixture\n-):\n+def test_conjugate_pauli_by_clifford__returns_conjugation_result(mocker: MockerFixture):\n     client_configuration = QCSClientConfiguration.load()\n     compiler_client = CompilerClient(client_configuration=client_configuration)\n-    rpcq_client = patch_rpcq_client(mocker=mocker, return_value=rpcq.messages.ConjugateByCliffordResponse(phase=42, pauli=\"pauli\"))\n+    rpcq_client = patch_rpcq_client(\n+        mocker=mocker, return_value=rpcq.messages.ConjugateByCliffordResponse(phase=42, pauli=\"pauli\")\n+    )\n \n     request = ConjugatePauliByCliffordRequest(\n         pauli_indices=[0, 1, 2],\n@@ -151,7 +157,7 @@ def test_conjugate_pauli_by_clifford__returns_conjugation_result(\n         rpcq.messages.ConjugateByCliffordRequest(\n             pauli=rpcq.messages.PauliTerm(indices=[0, 1, 2], symbols=[\"x\", \"y\", \"z\"]),\n             clifford=\"cliff\",\n-        )\n+        ),\n     )\n \n \n@@ -161,7 +167,9 @@ def test_generate_randomized_benchmarking_sequence__returns_benchmarking_sequenc\n     client_configuration = QCSClientConfiguration.load()\n     compiler_client = CompilerClient(client_configuration=client_configuration)\n \n-    rpcq_client = patch_rpcq_client(mocker=mocker, return_value=rpcq.messages.RandomizedBenchmarkingResponse(sequence=[[3, 1, 4], [1, 6, 1]]))\n+    rpcq_client = patch_rpcq_client(\n+        mocker=mocker, return_value=rpcq.messages.RandomizedBenchmarkingResponse(sequence=[[3, 1, 4], [1, 6, 1]])\n+    )\n \n     request = GenerateRandomizedBenchmarkingSequenceRequest(\n         depth=42,\n@@ -181,5 +189,5 @@ def test_generate_randomized_benchmarking_sequence__returns_benchmarking_sequenc\n             gateset=[\"some\", \"gate\", \"set\"],\n             seed=314,\n             interleaver=\"some-interleaver\",\n-        )\n+        ),\n     )\n", "problem_statement": "Get version info requests to quilc should go through the QCS SDK\nCurrently, the qcs-sdk handles all external requests to `quilc` _except_ for getting version info. We need add a method for getting that data to QCS SDK Rust (see [this issue](https://github.com/rigetti/qcs-sdk-rust/issues/205)), then follow-up and use it here. \r\n\r\nThis supports #1485\n", "hints_text": "Good catch!", "created_at": 1667, "language": "python", "label": "Hard"}
{"repo": "pallets-eco/flask-wtf", "pull_number": 264, "instance_id": "pallets-eco__flask-wtf-264", "issue_numbers": ["227"], "base_commit": "f306c360f74362be3aac89c43cdc7c37008764fb", "patch": "diff --git a/flask_wtf/_compat.py b/flask_wtf/_compat.py\n--- a/flask_wtf/_compat.py\n+++ b/flask_wtf/_compat.py\n@@ -6,9 +6,11 @@\n if not PY2:\n     text_type = str\n     string_types = (str,)\n+    from urllib.parse import urlparse\n else:\n     text_type = unicode\n     string_types = (str, unicode)\n+    from urlparse import urlparse\n \n \n def to_bytes(text):\ndiff --git a/flask_wtf/csrf.py b/flask_wtf/csrf.py\n--- a/flask_wtf/csrf.py\n+++ b/flask_wtf/csrf.py\n@@ -8,128 +8,94 @@\n     :copyright: (c) 2013 by Hsiaoming Yang.\n \"\"\"\n \n-import os\n-import hmac\n import hashlib\n-import time\n-from flask import Blueprint\n-from flask import current_app, session, request, abort\n+import os\n+import warnings\n+from functools import wraps\n+\n+from flask import Blueprint, current_app, request, session\n+from itsdangerous import BadData, URLSafeTimedSerializer\n+from werkzeug.exceptions import BadRequest\n from werkzeug.security import safe_str_cmp\n-from ._compat import to_bytes, string_types\n-try:\n-    from urlparse import urlparse\n-except ImportError:\n-    # python 3\n-    from urllib.parse import urlparse\n \n+from ._compat import FlaskWTFDeprecationWarning, string_types, urlparse\n \n __all__ = ('generate_csrf', 'validate_csrf', 'CsrfProtect')\n \n \n-def generate_csrf(secret_key=None, time_limit=None, token_key='csrf_token', url_safe=False):\n-    \"\"\"Generate csrf token code.\n-\n-    :param secret_key: A secret key for mixing in the token,\n-                       default is Flask.secret_key.\n-    :param time_limit: Token valid in the time limit,\n-                       default is 3600s.\n-    \"\"\"\n+def _get_secret_key(secret_key=None):\n     if not secret_key:\n-        secret_key = current_app.config.get(\n-            'WTF_CSRF_SECRET_KEY', current_app.secret_key\n-        )\n+        secret_key = current_app.config.get('WTF_CSRF_SECRET_KEY', current_app.secret_key)\n \n     if not secret_key:\n-        raise Exception('Must provide secret_key to use csrf.')\n+        raise Exception('Must provide secret_key to use CSRF.')\n+\n+    return secret_key\n \n-    if time_limit is None:\n-        time_limit = current_app.config.get('WTF_CSRF_TIME_LIMIT', 3600)\n \n-    if token_key not in session:\n-        session[token_key] = hashlib.sha1(os.urandom(64)).hexdigest()\n-\n-    if time_limit:\n-        expires = int(time.time() + time_limit)\n-        csrf_build = '%s%s' % (session[token_key], expires)\n-    else:\n-        expires = ''\n-        csrf_build = session[token_key]\n-\n-    hmac_csrf = hmac.new(\n-        to_bytes(secret_key),\n-        to_bytes(csrf_build),\n-        digestmod=hashlib.sha1\n-    ).hexdigest()\n-    delimiter = '--' if url_safe else '##'\n-    return '%s%s%s' % (expires, delimiter, hmac_csrf)\n-\n-\n-def validate_csrf(data, secret_key=None, time_limit=None, token_key='csrf_token', url_safe=False):\n-    \"\"\"Check if the given data is a valid csrf token.\n-\n-    :param data: The csrf token value to be checked.\n-    :param secret_key: A secret key for mixing in the token,\n-                       default is Flask.secret_key.\n-    :param time_limit: Check if the csrf token is expired.\n-                       default is True.\n+def generate_csrf(secret_key=None, token_key='csrf_token'):\n+    \"\"\"Generate a CSRF token. The token is cached for a request, so multiple\n+    calls to this function will generate the same token.\n+\n+    During testing, it might be useful to access the signed token in\n+    ``request.csrf_token`` and the raw token in ``session['csrf_token']``.\n+\n+    :param secret_key: Used to securely sign the token. Default is\n+        ``WTF_CSRF_SECRET_KEY`` or ``SECRET_KEY``.\n+    :param token_key: key where token is stored in session for comparision.\n     \"\"\"\n-    delimiter = '--' if url_safe else '##'\n-    if not data or delimiter not in data:\n-        return False\n \n-    try:\n-        expires, hmac_csrf = data.split(delimiter, 1)\n-    except ValueError:\n-        return False  # unpack error\n+    if not getattr(request, token_key, None):\n+        if token_key not in session:\n+            session[token_key] = hashlib.sha1(os.urandom(64)).hexdigest()\n \n-    if time_limit is None:\n-        time_limit = current_app.config.get('WTF_CSRF_TIME_LIMIT', 3600)\n+        s = URLSafeTimedSerializer(_get_secret_key(secret_key), salt='wtf-csrf-token')\n+        setattr(request, token_key, s.dumps(session[token_key]))\n \n-    if time_limit:\n-        try:\n-            expires = int(expires)\n-        except ValueError:\n-            return False\n+    return getattr(request, token_key)\n \n-        now = int(time.time())\n-        if now > expires:\n-            return False\n \n-    if not secret_key:\n-        secret_key = current_app.config.get(\n-            'WTF_CSRF_SECRET_KEY', current_app.secret_key\n-        )\n+def validate_csrf(data, secret_key=None, time_limit=None, token_key='csrf_token'):\n+    \"\"\"Check if the given data is a valid CSRF token. This compares the given\n+    signed token to the one stored in the session.\n \n-    if token_key not in session:\n+    :param data: The signed CSRF token to be checked.\n+    :param secret_key: Used to securely sign the token. Default is\n+        ``WTF_CSRF_SECRET_KEY`` or ``SECRET_KEY``.\n+    :param time_limit: Number of seconds that the token is valid. Default is\n+        ``WTF_CSRF_TIME_LIMIT`` or 3600 seconds (60 minutes).\n+    :param token_key: key where token is stored in session for comparision.\n+    \"\"\"\n+\n+    if not data or token_key not in session:\n         return False\n \n-    csrf_build = '%s%s' % (session[token_key], expires)\n-    hmac_compare = hmac.new(\n-        to_bytes(secret_key),\n-        to_bytes(csrf_build),\n-        digestmod=hashlib.sha1\n-    ).hexdigest()\n+    s = URLSafeTimedSerializer(_get_secret_key(secret_key), salt='wtf-csrf-token')\n \n-    return safe_str_cmp(hmac_compare, hmac_csrf)\n+    if time_limit is None:\n+        time_limit = current_app.config.get('WTF_CSRF_TIME_LIMIT', 3600)\n \n+    try:\n+        token = s.loads(data, max_age=time_limit)\n+    except BadData:\n+        return False\n \n-class CsrfProtect(object):\n-    \"\"\"Enable csrf protect for Flask.\n+    return safe_str_cmp(session[token_key], token)\n \n-    Register it with::\n \n-        app = Flask(__name__)\n-        CsrfProtect(app)\n-\n-    And in the templates, add the token input::\n+class CsrfProtect(object):\n+    \"\"\"Enable CSRF protection globally for a Flask app.\n \n-        <input type=\"hidden\" name=\"csrf_token\" value=\"{{ csrf_token() }}\"/>\n+    ::\n \n-    If you need to send the token via AJAX, and there is no form::\n+        app = Flask(__name__)\n+        csrf = CsrfProtect(app)\n \n-        <meta name=\"csrf_token\" content=\"{{ csrf_token() }}\" />\n+    Checks the ``csrf_token`` field sent with forms, or the ``X-CSRFToken``\n+    header sent with JavaScript requests. Render the token in templates using\n+    ``{{ csrf_token() }}``.\n \n-    You can grab the csrf token with JavaScript, and send the token together.\n+    See the :ref:`csrf` documentation.\n     \"\"\"\n \n     def __init__(self, app=None):\n@@ -140,24 +106,19 @@ def __init__(self, app=None):\n             self.init_app(app)\n \n     def init_app(self, app):\n-        self._app = app\n-        app.jinja_env.globals['csrf_token'] = generate_csrf\n-        app.config.setdefault(\n-            'WTF_CSRF_HEADERS', ['X-CSRFToken', 'X-CSRF-Token']\n-        )\n-        app.config.setdefault('WTF_CSRF_SSL_STRICT', True)\n         app.config.setdefault('WTF_CSRF_ENABLED', True)\n         app.config.setdefault('WTF_CSRF_CHECK_DEFAULT', True)\n-        app.config.setdefault('WTF_CSRF_METHODS', ['POST', 'PUT', 'PATCH'])\n+        app.config['WTF_CSRF_METHODS'] = set(app.config.get(\n+            'WTF_CSRF_METHODS', ['POST', 'PUT', 'PATCH', 'DELETE']\n+        ))\n+        app.config.setdefault('WTF_CSRF_HEADERS', ['X-CSRFToken', 'X-CSRF-Token'])\n+        app.config.setdefault('WTF_CSRF_SSL_STRICT', True)\n \n-        # expose csrf_token as a helper in all templates\n-        @app.context_processor\n-        def csrf_token():\n-            return dict(csrf_token=generate_csrf)\n+        app.jinja_env.globals['csrf_token'] = generate_csrf\n+        app.context_processor(lambda: {'csrf_token': generate_csrf})\n \n         @app.before_request\n         def _csrf_protect():\n-            # many things come from django.middleware.csrf\n             if not app.config['WTF_CSRF_ENABLED']:\n                 return\n \n@@ -171,15 +132,17 @@ def _csrf_protect():\n                 return\n \n             view = app.view_functions.get(request.endpoint)\n+\n             if not view:\n                 return\n \n-            if self._exempt_views or self._exempt_blueprints:\n-                dest = '%s.%s' % (view.__module__, view.__name__)\n-                if dest in self._exempt_views:\n-                    return\n-                if request.blueprint in self._exempt_blueprints:\n-                    return\n+            if request.blueprint in self._exempt_blueprints:\n+                return\n+\n+            dest = '%s.%s' % (view.__module__, view.__name__)\n+\n+            if dest in self._exempt_views:\n+                return\n \n             self.protect()\n \n@@ -190,85 +153,119 @@ def _get_csrf_token(self):\n         for key in request.form:\n             if key.endswith('csrf_token'):\n                 csrf_token = request.form[key]\n+\n                 if csrf_token:\n                     return csrf_token\n \n-        for header_name in self._app.config['WTF_CSRF_HEADERS']:\n+        for header_name in current_app.config['WTF_CSRF_HEADERS']:\n             csrf_token = request.headers.get(header_name)\n+\n             if csrf_token:\n                 return csrf_token\n+\n         return None\n \n     def protect(self):\n-        if request.method not in self._app.config['WTF_CSRF_METHODS']:\n+        if request.method not in current_app.config['WTF_CSRF_METHODS']:\n             return\n \n         if not validate_csrf(self._get_csrf_token()):\n-            reason = 'CSRF token missing or incorrect.'\n-            return self._error_response(reason)\n+            self._error_response('CSRF token missing or incorrect.')\n \n-        if request.is_secure and self._app.config['WTF_CSRF_SSL_STRICT']:\n+        if request.is_secure and current_app.config['WTF_CSRF_SSL_STRICT']:\n             if not request.referrer:\n-                reason = 'Referrer checking failed - no Referrer.'\n-                return self._error_response(reason)\n+                self._error_response('Referrer checking failed - no Referrer.')\n \n             good_referrer = 'https://%s/' % request.host\n+\n             if not same_origin(request.referrer, good_referrer):\n-                reason = 'Referrer checking failed - origin does not match.'\n-                return self._error_response(reason)\n+                self._error_response('Referrer checking failed - origin does not match.')\n \n         request.csrf_valid = True  # mark this request is csrf valid\n \n     def exempt(self, view):\n-        \"\"\"A decorator that can exclude a view from csrf protection.\n-\n-        Remember to put the decorator above the `route`::\n+        \"\"\"Mark a view or blueprint to be excluded from CSRF protection.\n \n-            csrf = CsrfProtect(app)\n+        ::\n \n-            @csrf.exempt\n             @app.route('/some-view', methods=['POST'])\n+            @csrf.exempt\n             def some_view():\n-                return\n+                ...\n+\n+        ::\n+\n+            bp = Blueprint(...)\n+            csrf.exempt(bp)\n+\n         \"\"\"\n+\n         if isinstance(view, Blueprint):\n             self._exempt_blueprints.add(view.name)\n             return view\n+\n         if isinstance(view, string_types):\n             view_location = view\n         else:\n             view_location = '%s.%s' % (view.__module__, view.__name__)\n+\n         self._exempt_views.add(view_location)\n         return view\n \n     def _error_response(self, reason):\n-        return abort(400, reason)\n+        raise CsrfError(reason)\n \n     def error_handler(self, view):\n-        \"\"\"A decorator that set the error response handler.\n+        \"\"\"Register a function that will generate the response for CSRF errors.\n \n-        It accepts one parameter `reason`::\n+        .. deprecated:: 0.14\n+            Use the standard Flask error system with\n+            ``@app.errorhandler(CsrfError)`` instead. This will be removed in\n+            version 1.0.\n+\n+        The function will be passed one argument, ``reason``. By default it will\n+        raise a :class:`~flask_wtf.csrf.CsrfError`. ::\n \n             @csrf.error_handler\n             def csrf_error(reason):\n                 return render_template('error.html', reason=reason)\n \n-        By default, it will return a 400 response.\n+        Due to historical reasons, the function may either return a response\n+        or raise an exception with :func:`flask.abort`.\n         \"\"\"\n-        self._error_response = view\n+\n+        warnings.warn(FlaskWTFDeprecationWarning(\n+            '\"@csrf.error_handler\" is deprecated. Use the standard Flask error '\n+            'system with \"@app.errorhandler(CsrfError)\" instead. This will be'\n+            'removed in 1.0.'\n+        ), stacklevel=2)\n+\n+        @wraps(view)\n+        def handler(reason):\n+            response = current_app.make_response(view(reason))\n+            raise CsrfError(response.get_data(as_text=True), response=response)\n+\n+        self._error_response = handler\n         return view\n \n \n-def same_origin(current_uri, compare_uri):\n-    parsed_uri = urlparse(current_uri)\n-    parsed_compare = urlparse(compare_uri)\n+class CsrfError(BadRequest):\n+    \"\"\"Raise if the client sends invalid CSRF data with the request.\n \n-    if parsed_uri.scheme != parsed_compare.scheme:\n-        return False\n+    Generates a 400 Bad Request response with the failure reason by default.\n+    Customize the response by registering a handler with\n+    :meth:`flask.Flask.errorhandler`.\n+    \"\"\"\n \n-    if parsed_uri.hostname != parsed_compare.hostname:\n-        return False\n+    description = 'CSRF token missing or incorrect.'\n \n-    if parsed_uri.port != parsed_compare.port:\n-        return False\n-    return True\n+\n+def same_origin(current_uri, compare_uri):\n+    current = urlparse(current_uri)\n+    compare = urlparse(compare_uri)\n+\n+    return (\n+        current.scheme == compare.scheme\n+        and current.hostname == compare.hostname\n+        and current.port == compare.port\n+    )\ndiff --git a/flask_wtf/form.py b/flask_wtf/form.py\n--- a/flask_wtf/form.py\n+++ b/flask_wtf/form.py\n@@ -1,16 +1,14 @@\n # coding: utf-8\n import warnings\n \n-import werkzeug.datastructures\n-from flask import request, session, current_app\n+from flask import current_app, request, session\n from jinja2 import Markup\n-from wtforms.compat import with_metaclass\n+from werkzeug.datastructures import MultiDict\n from wtforms.ext.csrf.form import SecureForm\n-from wtforms.form import FormMeta\n from wtforms.validators import ValidationError\n-from wtforms.widgets import HiddenInput, SubmitInput\n+from wtforms.widgets import HiddenInput\n \n-from ._compat import text_type, string_types, FlaskWTFDeprecationWarning\n+from ._compat import FlaskWTFDeprecationWarning, string_types, text_type\n from .csrf import generate_csrf, validate_csrf\n \n try:\n@@ -70,7 +68,7 @@ def __init__(self, formdata=_Auto, obj=None, prefix='', csrf_context=None,\n                     formdata = formdata.copy()\n                     formdata.update(request.files)\n                 elif request.get_json():\n-                    formdata = werkzeug.datastructures.MultiDict(request.get_json())\n+                    formdata = MultiDict(request.get_json())\n             else:\n                 formdata = None\n \n@@ -94,25 +92,24 @@ def __init__(self, formdata=_Auto, obj=None, prefix='', csrf_context=None,\n     def generate_csrf_token(self, csrf_context=None):\n         if not self.csrf_enabled:\n             return None\n-        return generate_csrf(self.SECRET_KEY, self.TIME_LIMIT)\n+\n+        return generate_csrf(secret_key=self.SECRET_KEY)\n \n     def validate_csrf_token(self, field):\n         if not self.csrf_enabled:\n             return True\n-        if hasattr(request, 'csrf_valid') and request.csrf_valid:\n+\n+        if getattr(request, 'csrf_valid', False):\n             # this is validated by CsrfProtect\n             return True\n-        if not validate_csrf(field.data, self.SECRET_KEY, self.TIME_LIMIT):\n+\n+        if not self.validate_csrf_data(field.data):\n             raise ValidationError(field.gettext('CSRF token missing'))\n \n     def validate_csrf_data(self, data):\n-        \"\"\"Check if the csrf data is valid.\n+        \"\"\"Check if the given data is a valid CSRF token.\"\"\"\n \n-        .. versionadded: 0.9.0\n-\n-        :param data: the csrf string to be validated.\n-        \"\"\"\n-        return validate_csrf(data, self.SECRET_KEY, self.TIME_LIMIT)\n+        return validate_csrf(data, secret_key=self.SECRET_KEY, time_limit=self.TIME_LIMIT)\n \n     def is_submitted(self):\n         \"\"\"Consider the form submitted if there is an active request and\n", "test_patch": "diff --git a/tests/base.py b/tests/base.py\n--- a/tests/base.py\n+++ b/tests/base.py\n@@ -1,10 +1,12 @@\n from __future__ import with_statement\n \n-from flask import Flask, render_template, jsonify\n-from wtforms import StringField, HiddenField, SubmitField\n-from wtforms.validators import DataRequired\n+from unittest import TestCase as _TestCase\n+\n+from flask import Flask, jsonify, render_template\n from flask_wtf import FlaskForm\n from flask_wtf._compat import text_type\n+from wtforms import HiddenField, StringField, SubmitField\n+from wtforms.validators import DataRequired\n \n \n def to_unicode(text):\n@@ -37,7 +39,7 @@ class SimpleForm(FlaskForm):\n     pass\n \n \n-class TestCase(object):\n+class TestCase(_TestCase):\n     def setUp(self):\n         self.app = self.create_app()\n         self.client = self.app.test_client()\ndiff --git a/tests/templates/csrf_macro.html b/tests/templates/csrf_macro.html\n--- a/tests/templates/csrf_macro.html\n+++ b/tests/templates/csrf_macro.html\n@@ -1,3 +1,3 @@\n {% macro render_csrf_token() %}\n-  <input type=\"hidden\" name=\"csrf_token\" value=\"{{ csrf_token() }}\">\n+  <input name=\"csrf_token\" type=\"hidden\" value=\"{{ csrf_token() }}\">\n {% endmacro %}\ndiff --git a/tests/test_csrf.py b/tests/test_csrf.py\n--- a/tests/test_csrf.py\n+++ b/tests/test_csrf.py\n@@ -1,21 +1,13 @@\n from __future__ import with_statement\n \n import re\n-from flask import Blueprint\n-from flask import render_template\n-from flask_wtf.csrf import CsrfProtect\n-from flask_wtf.csrf import validate_csrf, generate_csrf\n-from .base import TestCase, MyForm, to_unicode\n+import warnings\n \n-csrf_token_input = re.compile(\n-    r'name=\"csrf_token\" type=\"hidden\" value=\"([0-9a-z#A-Z-\\.]*)\"'\n-)\n+from flask import Blueprint, abort, render_template, request\n+from flask_wtf._compat import FlaskWTFDeprecationWarning\n+from flask_wtf.csrf import CsrfError, CsrfProtect, generate_csrf, validate_csrf\n \n-\n-def get_csrf_token(data):\n-    match = csrf_token_input.search(to_unicode(data))\n-    assert match\n-    return match.groups()[0]\n+from .base import MyForm, TestCase\n \n \n class TestCSRF(TestCase):\n@@ -59,9 +51,9 @@ def test_invalid_csrf(self):\n         response = self.client.post(\"/\", data={\"name\": \"danny\"})\n         assert response.status_code == 400\n \n-        @self.csrf.error_handler\n-        def invalid(reason):\n-            return reason\n+        @self.app.errorhandler(CsrfError)\n+        def handle_csrf_error(e):\n+            return e, 200\n \n         response = self.client.post(\"/\", data={\"name\": \"danny\"})\n         assert response.status_code == 200\n@@ -86,8 +78,9 @@ def test_invalid_secure_csrf3(self):\n         assert response.status_code == 400\n \n     def test_valid_csrf(self):\n-        response = self.client.get(\"/\")\n-        csrf_token = get_csrf_token(response.data)\n+        with self.client:\n+            self.client.get('/')\n+            csrf_token = request.csrf_token\n \n         response = self.client.post(\"/\", data={\n             \"name\": \"danny\",\n@@ -96,8 +89,9 @@ def test_valid_csrf(self):\n         assert b'DANNY' in response.data\n \n     def test_prefixed_csrf(self):\n-        response = self.client.get('/')\n-        csrf_token = get_csrf_token(response.data)\n+        with self.client:\n+            self.client.get('/')\n+            csrf_token = request.csrf_token\n \n         response = self.client.post('/', data={\n             'prefix-name': 'David',\n@@ -106,8 +100,9 @@ def test_prefixed_csrf(self):\n         assert response.status_code == 200\n \n     def test_invalid_secure_csrf(self):\n-        response = self.client.get(\"/\", base_url='https://localhost/')\n-        csrf_token = get_csrf_token(response.data)\n+        with self.client:\n+            self.client.get('/', base_url='https://localhost/')\n+            csrf_token = request.csrf_token\n \n         response = self.client.post(\n             \"/\",\n@@ -161,8 +156,10 @@ def test_invalid_secure_csrf(self):\n         assert b'not match' in response.data\n \n     def test_valid_secure_csrf(self):\n-        response = self.client.get(\"/\", base_url='https://localhost/')\n-        csrf_token = get_csrf_token(response.data)\n+        with self.client:\n+            self.client.get('/', base_url='https://localhost/')\n+            csrf_token = request.csrf_token\n+\n         response = self.client.post(\n             \"/\",\n             data={\"name\": \"danny\"},\n@@ -177,8 +174,9 @@ def test_valid_secure_csrf(self):\n         assert response.status_code == 200\n \n     def test_valid_csrf_method(self):\n-        response = self.client.get(\"/\")\n-        csrf_token = get_csrf_token(response.data)\n+        with self.client:\n+            self.client.get('/')\n+            csrf_token = request.csrf_token\n \n         response = self.client.post(\"/csrf-protect-method\", data={\n             \"csrf_token\": csrf_token\n@@ -189,17 +187,19 @@ def test_invalid_csrf_method(self):\n         response = self.client.post(\"/csrf-protect-method\", data={\"name\": \"danny\"})\n         assert response.status_code == 400\n \n-        @self.csrf.error_handler\n-        def invalid(reason):\n-            return reason\n+        @self.app.errorhandler(CsrfError)\n+        def handle_csrf_error(e):\n+            return e, 200\n \n         response = self.client.post(\"/\", data={\"name\": \"danny\"})\n         assert response.status_code == 200\n         assert b'token missing' in response.data\n \n     def test_empty_csrf_headers(self):\n-        response = self.client.get(\"/\", base_url='https://localhost/')\n-        csrf_token = get_csrf_token(response.data)\n+        with self.client:\n+            self.client.get('/', base_url='https://localhost/')\n+            csrf_token = request.csrf_token\n+\n         self.app.config['WTF_CSRF_HEADERS'] = list()\n         response = self.client.post(\n             \"/\",\n@@ -215,8 +215,10 @@ def test_empty_csrf_headers(self):\n         assert response.status_code == 400\n \n     def test_custom_csrf_headers(self):\n-        response = self.client.get(\"/\", base_url='https://localhost/')\n-        csrf_token = get_csrf_token(response.data)\n+        with self.client:\n+            self.client.get('/', base_url='https://localhost/')\n+            csrf_token = request.csrf_token\n+\n         self.app.config['WTF_CSRF_HEADERS'] = ['X-XSRF-TOKEN']\n         response = self.client.post(\n             \"/\",\n@@ -239,9 +241,10 @@ def test_testing(self):\n         self.app.testing = True\n         self.client.post(\"/\", data={\"name\": \"danny\"})\n \n-    def test_csrf_exempt(self):\n-        response = self.client.get(\"/csrf-exempt\")\n-        csrf_token = get_csrf_token(response.data)\n+    def test_csrf_exempt_view_with_form(self):\n+        with self.client:\n+            self.client.get('/', base_url='https://localhost/')\n+            csrf_token = request.csrf_token\n \n         response = self.client.post(\"/csrf-exempt\", data={\n             \"name\": \"danny\",\n@@ -257,7 +260,7 @@ def test_validate_csrf(self):\n \n     def test_validate_not_expiring_csrf(self):\n         with self.app.test_request_context():\n-            csrf_token = generate_csrf(time_limit=False)\n+            csrf_token = generate_csrf()\n             assert validate_csrf(csrf_token, time_limit=False)\n \n     def test_csrf_token_helper(self):\n@@ -265,8 +268,9 @@ def test_csrf_token_helper(self):\n         def withtoken():\n             return render_template(\"csrf.html\")\n \n-        response = self.client.get('/token')\n-        assert b'#' in response.data\n+        with self.client:\n+            response = self.client.get('/token')\n+            assert re.search(br'token: ([0-9a-zA-Z\\-._]+)', response.data)\n \n     def test_csrf_blueprint(self):\n         response = self.client.post('/bar/foo')\n@@ -281,8 +285,9 @@ def test_csrf_token_macro(self):\n         def withtoken():\n             return render_template(\"import_csrf.html\")\n \n-        response = self.client.get('/token')\n-        assert b'#' in response.data\n+        with self.client:\n+            response = self.client.get('/token')\n+            assert request.csrf_token in response.data.decode('utf8')\n \n     def test_csrf_custom_token_key(self):\n         with self.app.test_request_context():\n@@ -296,16 +301,31 @@ def test_csrf_custom_token_key(self):\n             # However, the custom key can validate as well\n             assert validate_csrf(custom_csrf_token, token_key='oauth_state')\n \n-    def test_csrf_url_safe(self):\n-        with self.app.test_request_context():\n-            # Generate a normal and URL safe CSRF token\n-            default_csrf_token = generate_csrf()\n-            url_safe_csrf_token = generate_csrf(url_safe=True)\n+    def test_old_error_handler(self):\n+        with warnings.catch_warnings(record=True) as w:\n+            warnings.simplefilter('always', FlaskWTFDeprecationWarning)\n+\n+            @self.csrf.error_handler\n+            def handle_csrf_error(reason):\n+                return 'caught csrf return'\n+\n+            self.assertEqual(len(w), 1)\n+            assert issubclass(w[0].category, FlaskWTFDeprecationWarning)\n+            assert 'app.errorhandler(CsrfError)' in str(w[0].message)\n+\n+            rv = self.client.post('/', data={'name': 'david'})\n+            assert b'caught csrf return' in rv.data\n+\n+        with warnings.catch_warnings(record=True) as w:\n+            warnings.simplefilter('always', FlaskWTFDeprecationWarning)\n+\n+            @self.csrf.error_handler\n+            def handle_csrf_error(reason):\n+                abort(401, 'caught csrf abort')\n \n-            # Verify they are not the same and the URL one is truly URL safe\n-            assert default_csrf_token != url_safe_csrf_token\n-            assert '#' not in url_safe_csrf_token\n-            assert re.match(r'^[a-f0-9]+--[a-f0-9]+$', url_safe_csrf_token)\n+            self.assertEqual(len(w), 1)\n+            assert issubclass(w[0].category, FlaskWTFDeprecationWarning)\n+            assert 'app.errorhandler(CsrfError)' in str(w[0].message)\n \n-            # Verify we can validate our URL safe key\n-            assert validate_csrf(url_safe_csrf_token, url_safe=True)\n+            rv = self.client.post('/', data={'name': 'david'})\n+            assert b'caught csrf abort' in rv.data\ndiff --git a/tests/test_validation.py b/tests/test_validation.py\n--- a/tests/test_validation.py\n+++ b/tests/test_validation.py\n@@ -1,18 +1,8 @@\n from __future__ import with_statement\n \n-import re\n+from flask import request\n \n-from .base import TestCase, MyForm, to_unicode\n-\n-csrf_token_input = re.compile(\n-    r'name=\"csrf_token\" type=\"hidden\" value=\"([0-9a-z#A-Z-\\.]*)\"'\n-)\n-\n-\n-def get_csrf_token(data):\n-    match = csrf_token_input.search(to_unicode(data))\n-    assert match\n-    return match.groups()[0]\n+from .base import MyForm, TestCase, to_unicode\n \n \n class TestValidateOnSubmit(TestCase):\n@@ -93,18 +83,20 @@ def test_ajax(self):\n         assert response.status_code == 200\n \n     def test_valid_csrf(self):\n+        with self.client:\n+            self.client.get('/')\n+            csrf_token = request.csrf_token\n \n-        response = self.client.get(\"/\")\n-        csrf_token = get_csrf_token(response.data)\n-\n-        response = self.client.post(\"/\", data={\"name\": \"danny\",\n-                                               \"csrf_token\": csrf_token})\n+        response = self.client.post('/', data={\n+            'name': 'danny',\n+            'csrf_token': csrf_token\n+        })\n         assert b'DANNY' in response.data\n \n     def test_double_csrf(self):\n-\n-        response = self.client.get(\"/\")\n-        csrf_token = get_csrf_token(response.data)\n+        with self.client:\n+            self.client.get('/')\n+            csrf_token = request.csrf_token\n \n         response = self.client.post(\"/two_forms/\", data={\n             \"name\": \"danny\",\n@@ -114,6 +106,4 @@ def test_double_csrf(self):\n \n     def test_valid_csrf_data(self):\n         with self.app.test_request_context():\n-            form = MyForm()\n-            csrf_token = get_csrf_token(form.csrf_token())\n-            assert form.validate_csrf_data(csrf_token)\n+            assert MyForm().validate_csrf_data(request.csrf_token)\n", "problem_statement": "Make it easier to access a CSRF token in automated tests\nIf you want to run your automated tests with CSRF enabled (which is a good idea if it's enabled in production), there's no good built-in way to do so. Even the tests for this project [use regular expressions to parse the CSRF token out of the page](https://github.com/lepture/flask-wtf/blob/3c9dcf5cc/tests/test_csrf.py#L10-L18), which is brittle and confusing. It would be better to provide some way to access the CSRF token in the Flask test client itself.\n\nI've written a GitHub Gist that walks though how I implemented this myself, but maybe Flask-WTF could change some internals to make it cleaner and easier? https://gist.github.com/singingwolfboy/2fca1de64950d5dfed72\n\n", "hints_text": "", "created_at": 1476, "language": "python", "label": "Hard"}
{"repo": "rigetti/pyquil", "pull_number": 421, "instance_id": "rigetti__pyquil-421", "issue_numbers": ["384"], "base_commit": "9612be90f91405ecbc089b3496f1c85d9c177cc8", "patch": "diff --git a/pyquil/noise.py b/pyquil/noise.py\n--- a/pyquil/noise.py\n+++ b/pyquil/noise.py\n@@ -296,22 +296,51 @@ def damping_after_dephasing(T1, T2, gate_time):\n \n # You can only apply gate-noise to non-parametrized gates or parametrized gates at fixed parameters.\n NO_NOISE = [\"RZ\"]\n-NOISY_GATES = {\n-    (\"I\", ()): (np.eye(2), \"NOISY-I\"),\n-    (\"RX\", (np.pi / 2,)): (np.array([[1, -1j],\n-                                     [-1j, 1]]) / np.sqrt(2),\n-                           \"NOISY-RX-PLUS-90\"),\n-    (\"RX\", (-np.pi / 2,)): (np.array([[1, 1j],\n-                                      [1j, 1]]) / np.sqrt(2),\n-                            \"NOISY-RX-MINUS-90\"),\n-    (\"RX\", (np.pi,)): (np.array([[0, -1j],\n-                                 [-1j, 0]]),\n-                       \"NOISY-RX-PLUS-180\"),\n-    (\"RX\", (-np.pi,)): (np.array([[0, 1j],\n-                                  [1j, 0]]),\n-                        \"NOISY-RX-MINUS-180\"),\n-    (\"CZ\", ()): (np.diag([1, 1, 1, -1]), \"NOISY-CZ\"),\n-}\n+ANGLE_TOLERANCE = 1e-10\n+\n+\n+class NoisyGateUndefined(Exception):\n+    \"\"\"Raise when user attempts to use noisy gate outside of currently supported set.\"\"\"\n+    pass\n+\n+\n+def get_noisy_gate(gate_name, params):\n+    \"\"\"\n+    Look up the numerical gate representation and a proposed 'noisy' name.\n+\n+    :param str gate_name: The Quil gate name\n+    :param Tuple[float] params: The gate parameters.\n+    :return: A tuple (matrix, noisy_name) with the representation of the ideal gate matrix\n+        and a proposed name for the noisy version.\n+    :rtype: Tuple[np.array, str]\n+    \"\"\"\n+    params = tuple(params)\n+    if gate_name == \"I\":\n+        assert params == ()\n+        return np.eye(2), \"NOISY-I\"\n+    if gate_name == \"RX\":\n+        angle, = params\n+        if np.isclose(angle, np.pi / 2, atol=ANGLE_TOLERANCE):\n+            return (np.array([[1, -1j],\n+                              [-1j, 1]]) / np.sqrt(2),\n+                    \"NOISY-RX-PLUS-90\")\n+        elif np.isclose(angle, -np.pi / 2, atol=ANGLE_TOLERANCE):\n+            return (np.array([[1, 1j],\n+                              [1j, 1]]) / np.sqrt(2),\n+                    \"NOISY-RX-MINUS-90\")\n+        elif np.isclose(angle, np.pi, atol=ANGLE_TOLERANCE):\n+            return (np.array([[0, -1j],\n+                              [-1j, 0]]),\n+                    \"NOISY-RX-PLUS-180\")\n+        elif np.isclose(angle, -np.pi, atol=ANGLE_TOLERANCE):\n+            return (np.array([[0, 1j],\n+                              [1j, 0]]),\n+                    \"NOISY-RX-MINUS-180\")\n+    elif gate_name == \"CZ\":\n+        assert params == ()\n+        return np.diag([1, 1, 1, -1]), \"NOISY-CZ\"\n+    raise NoisyGateUndefined(\"Undefined gate and params: {}{}\\n\"\n+                             \"Please restrict yourself to I, RX(+/-pi), RX(+/-pi/2), CZ\")\n \n \n def _get_program_gates(prog):\n@@ -384,21 +413,18 @@ def _decoherence_noise_model(gates, T1=30e-6, T2=30e-6, gate_time_1q=50e-9,\n         key = (g.name, tuple(g.params))\n         if g.name in NO_NOISE:\n             continue\n-        if key in NOISY_GATES:\n-            matrix, _ = NOISY_GATES[key]\n-            if len(targets) == 1:\n-                noisy_I = noisy_identities_1q[targets[0]]\n-            else:\n-                if len(targets) != 2:\n-                    raise ValueError(\"Noisy gates on more than 2Q not currently supported\")\n-\n-                # note this ordering of the tensor factors is necessary due to how the QVM orders\n-                # the wavefunction basis\n-                noisy_I = tensor_kraus_maps(noisy_identities_2q[targets[1]],\n-                                            noisy_identities_2q[targets[0]])\n+        matrix, _ = get_noisy_gate(g.name, g.params)\n+\n+        if len(targets) == 1:\n+            noisy_I = noisy_identities_1q[targets[0]]\n         else:\n-            raise ValueError(\"Cannot create noisy version of {}. \".format(g) +\n-                             \"Please restrict yourself to CZ, RX(+/-pi/2), I, RZ(theta)\")\n+            if len(targets) != 2:\n+                raise ValueError(\"Noisy gates on more than 2Q not currently supported\")\n+\n+            # note this ordering of the tensor factors is necessary due to how the QVM orders\n+            # the wavefunction basis\n+            noisy_I = tensor_kraus_maps(noisy_identities_2q[targets[1]],\n+                                        noisy_identities_2q[targets[0]])\n         kraus_maps.append(KrausModel(g.name, tuple(g.params), targets,\n                                      combine_kraus_maps(noisy_I, [matrix]),\n                                      # FIXME (Nik): compute actual avg gate fidelity for this simple\n@@ -434,13 +460,13 @@ def _noise_model_program_header(noise_model):\n \n         # obtain ideal gate matrix and new, noisy name by looking it up in the NOISY_GATES dict\n         try:\n-            ideal_gate, new_name = NOISY_GATES[k.gate, tuple(k.params)]\n+            ideal_gate, new_name = get_noisy_gate(k.gate, tuple(k.params))\n \n             # if ideal version of gate has not yet been DEFGATE'd, do this\n             if new_name not in defgates:\n                 p.defgate(new_name, ideal_gate)\n                 defgates.add(new_name)\n-        except KeyError:\n+        except NoisyGateUndefined:\n             print(\"WARNING: Could not find ideal gate definition for gate {}\".format(k.gate),\n                   file=sys.stderr)\n             new_name = k.gate\n@@ -468,11 +494,10 @@ def apply_noise_model(prog, noise_model):\n     new_prog = _noise_model_program_header(noise_model)\n     for i in prog:\n         if isinstance(i, Gate):\n-            key = (i.name, tuple(i.params))\n-            if key in NOISY_GATES:\n-                _, new_name = NOISY_GATES[key]\n+            try:\n+                _, new_name = get_noisy_gate(i.name, tuple(i.params))\n                 new_prog += Gate(new_name, [], i.qubits)\n-            else:\n+            except NoisyGateUndefined:\n                 new_prog += i\n         else:\n             new_prog += i\n", "test_patch": "diff --git a/pyquil/tests/test_noise.py b/pyquil/tests/test_noise.py\n--- a/pyquil/tests/test_noise.py\n+++ b/pyquil/tests/test_noise.py\n@@ -208,3 +208,17 @@ def test_apply_noise_model():\n             assert i.command in ['ADD-KRAUS', 'READOUT-POVM']\n         elif isinstance(i, Gate):\n             assert i.name in NO_NOISE or not i.params\n+\n+\n+def test_apply_noise_model_perturbed_angles():\n+    eps = 1e-15\n+    p = Program(RX(np.pi / 2 + eps)(0), RX(np.pi / 2 - eps)(1), CZ(0, 1), RX(np.pi / 2 + eps)(1))\n+    noise_model = _decoherence_noise_model(_get_program_gates(p))\n+    pnoisy = apply_noise_model(p, noise_model)\n+    for i in pnoisy:\n+        if isinstance(i, DefGate):\n+            pass\n+        elif isinstance(i, Pragma):\n+            assert i.command in ['ADD-KRAUS', 'READOUT-POVM']\n+        elif isinstance(i, Gate):\n+            assert i.name in NO_NOISE or not i.params\n", "problem_statement": "Adding decoherence noise models fails when `RX` angles are perturbed from +/-pi or +/-pi/2\nTwo ways to fix this:\r\n1. Quick: allow angles to deviate from pi within some tolerance (e.g., 10^{-10}) that is much stricter than any anticipated gate error.\r\n2. Slow: actually implement a mechanism to translate arbitrary pyquil gates (including parameters) to symbolic or numeric matrices. This would have to be able to resolve the default gateset AND check the program for `defgates` and extract those when applicable. As a benefit, we could support helpers for noise models for arbitrary gates.\n", "hints_text": "@mpharrigan what are your thoughts?\nIs this an issue in practice? Can we do quick in the near term and slow eventually in the context of noise models for arbitrary gates\nYeah, it was an issue for me today when I tried to add noise after compiling the program an external user wants to simulate with noise. I am happy to do the quick fix first\r\n", "created_at": 1525, "language": "python", "label": "Hard"}
{"repo": "marcelotduarte/cx_Freeze", "pull_number": 2759, "instance_id": "marcelotduarte__cx_Freeze-2759", "issue_numbers": ["2738"], "base_commit": "aee3a1a3195a358e814c4fcbdc116e192132bbf5", "patch": "diff --git a/cx_Freeze/_compat.py b/cx_Freeze/_compat.py\n--- a/cx_Freeze/_compat.py\n+++ b/cx_Freeze/_compat.py\n@@ -7,6 +7,7 @@\n from pathlib import Path\n \n __all__ = [\n+    \"ABI_THREAD\",\n     \"BUILD_EXE_DIR\",\n     \"EXE_SUFFIX\",\n     \"EXT_SUFFIX\",\n@@ -21,8 +22,9 @@\n \n PLATFORM = sysconfig.get_platform()\n PYTHON_VERSION = sysconfig.get_python_version()\n+ABI_THREAD = sysconfig.get_config_var(\"abi_thread\") or \"\"\n \n-BUILD_EXE_DIR = Path(f\"build/exe.{PLATFORM}-{PYTHON_VERSION}\")\n+BUILD_EXE_DIR = Path(f\"build/exe.{PLATFORM}-{PYTHON_VERSION}{ABI_THREAD}\")\n EXE_SUFFIX = sysconfig.get_config_var(\"EXE\")\n EXT_SUFFIX = sysconfig.get_config_var(\"EXT_SUFFIX\")\n \ndiff --git a/cx_Freeze/executable.py b/cx_Freeze/executable.py\n--- a/cx_Freeze/executable.py\n+++ b/cx_Freeze/executable.py\n@@ -11,6 +11,7 @@\n from typing import TYPE_CHECKING\n \n from cx_Freeze._compat import (\n+    ABI_THREAD,\n     EXE_SUFFIX,\n     IS_MACOS,\n     IS_MINGW,\n@@ -74,12 +75,17 @@ def base(self) -> Path:\n \n     @base.setter\n     def base(self, name: str | Path | None) -> None:\n-        # The default base is the legacy console, except for\n+        # The default base is the legacy console, except for Python 3.13t and\n         # Python 3.13 on macOS, that supports only the new console\n-        if IS_MACOS and sys.version_info[:2] >= (3, 13):\n-            name = name or \"console\"\n-        else:\n+        version = sys.version_info[:2]\n+        if (\n+            version <= (3, 13)\n+            and ABI_THREAD == \"\"\n+            and not (IS_MACOS and version == (3, 13))\n+        ):\n             name = name or \"console_legacy\"\n+        else:\n+            name = name or \"console\"\n         # silently ignore gui and service on non-windows systems\n         if not (IS_WINDOWS or IS_MINGW) and name in (\"gui\", \"service\"):\n             name = \"console\"\ndiff --git a/cx_Freeze/freezer.py b/cx_Freeze/freezer.py\n--- a/cx_Freeze/freezer.py\n+++ b/cx_Freeze/freezer.py\n@@ -22,11 +22,13 @@\n from setuptools import Distribution\n \n from cx_Freeze._compat import (\n+    ABI_THREAD,\n     BUILD_EXE_DIR,\n     IS_CONDA,\n     IS_MACOS,\n     IS_MINGW,\n     IS_WINDOWS,\n+    PYTHON_VERSION,\n )\n from cx_Freeze.common import get_resource_file_path, process_path_specs\n from cx_Freeze.exception import FileError, OptionError\n@@ -1035,9 +1037,10 @@ def _default_bin_includes(self) -> list[str]:\n             # MSYS2 python returns a static library.\n             names = [name.replace(\".dll.a\", \".dll\")]\n         else:\n+            py_version = f\"{PYTHON_VERSION}{ABI_THREAD}\"\n             names = [\n                 f\"python{sys.version_info[0]}.dll\",\n-                f\"python{sys.version_info[0]}{sys.version_info[1]}.dll\",\n+                f\"python{py_version.replace('.','')}.dll\",\n             ]\n         python_shared_libs: list[Path] = []\n         for name in names:\n@@ -1113,7 +1116,7 @@ def _default_bin_excludes(self) -> list[str]:\n     def _default_bin_includes(self) -> list[str]:\n         python_shared_libs: list[Path] = []\n         # Check for distributed \"cx_Freeze/bases/lib/Python\"\n-        name = \"Python\"\n+        name = f\"Python{ABI_THREAD.upper()}\"\n         for bin_path in self._default_bin_path_includes():\n             fullname = Path(bin_path, name).resolve()\n             if fullname.is_file():\ndiff --git a/setup.py b/setup.py\n--- a/setup.py\n+++ b/setup.py\n@@ -97,7 +97,8 @@ def build_extension(self, ext) -> None:\n             library_dirs.append(get_config_var(\"LIBPL\"))\n             if not ENABLE_SHARED or IS_CONDA:\n                 library_dirs.append(get_config_var(\"LIBDIR\"))\n-            libraries.append(f\"python{get_python_version()}\")\n+            abi_thread = get_config_var(\"abi_thread\") or \"\"\n+            libraries.append(f\"python{get_python_version()}{abi_thread}\")\n             if get_config_var(\"LIBS\"):\n                 extra_args.extend(get_config_var(\"LIBS\").split())\n             if get_config_var(\"LIBM\"):\n@@ -275,38 +276,48 @@ def get_extensions() -> list[Extension]:\n         os.environ.get(\"CI\", \"\") != \"true\"\n         or os.environ.get(\"CIBUILDWHEEL\", \"0\") != \"1\"\n     )\n+    abi_thread = get_config_var(\"abi_thread\") or \"\"\n+    version = sys.version_info[:2]\n     extensions = [\n         Extension(\n             \"cx_Freeze.bases.console\",\n             [\"source/bases/console.c\", \"source/bases/_common.c\"],\n             optional=optional,\n-        ),\n-        Extension(\n-            \"cx_Freeze.bases.console_legacy\",\n-            [\"source/legacy/console.c\"],\n-            depends=[\"source/legacy/common.c\"],\n-            optional=optional\n-            or (sys.version_info[:2] >= (3, 13) and IS_MACOS),\n-        ),\n+        )\n     ]\n-\n-    if IS_MINGW or IS_WINDOWS:\n+    if (\n+        version <= (3, 13)\n+        and abi_thread == \"\"\n+        and not (IS_MACOS and version == (3, 13))\n+    ):\n         extensions += [\n             Extension(\n-                \"cx_Freeze.bases.Win32GUI\",\n-                [\"source/legacy/Win32GUI.c\"],\n+                \"cx_Freeze.bases.console_legacy\",\n+                [\"source/legacy/console.c\"],\n                 depends=[\"source/legacy/common.c\"],\n-                libraries=[\"user32\"],\n                 optional=optional,\n-            ),\n-            Extension(\n-                \"cx_Freeze.bases.Win32Service\",\n-                [\"source/legacy/Win32Service.c\"],\n-                depends=[\"source/legacy/common.c\"],\n-                extra_link_args=[\"/DELAYLOAD:cx_Logging\"],\n-                libraries=[\"advapi32\"],\n-                optional=optional,\n-            ),\n+            )\n+        ]\n+    if IS_MINGW or IS_WINDOWS:\n+        if version <= (3, 13) and abi_thread == \"\":\n+            extensions += [\n+                Extension(\n+                    \"cx_Freeze.bases.Win32GUI\",\n+                    [\"source/legacy/Win32GUI.c\"],\n+                    depends=[\"source/legacy/common.c\"],\n+                    libraries=[\"user32\"],\n+                    optional=optional,\n+                ),\n+                Extension(\n+                    \"cx_Freeze.bases.Win32Service\",\n+                    [\"source/legacy/Win32Service.c\"],\n+                    depends=[\"source/legacy/common.c\"],\n+                    extra_link_args=[\"/DELAYLOAD:cx_Logging\"],\n+                    libraries=[\"advapi32\"],\n+                    optional=optional,\n+                ),\n+            ]\n+        extensions += [\n             Extension(\n                 \"cx_Freeze.bases.gui\",\n                 [\"source/bases/Win32GUI.c\", \"source/bases/_common.c\"],\n", "test_patch": "diff --git a/tests/test_executables.py b/tests/test_executables.py\n--- a/tests/test_executables.py\n+++ b/tests/test_executables.py\n@@ -12,6 +12,7 @@\n \n from cx_Freeze import Executable\n from cx_Freeze._compat import (\n+    ABI_THREAD,\n     BUILD_EXE_DIR,\n     EXE_SUFFIX,\n     IS_MACOS,\n@@ -241,14 +242,18 @@ def test_executables(\n         (\"icon.ico\", \"icon.icns\", \"icon.png\", \"icon.svg\"),\n     ),\n ]\n-if IS_MACOS and sys.version_info[:2] >= (3, 13):\n+if (\n+    sys.version_info[:2] <= (3, 13)\n+    and ABI_THREAD == \"\"\n+    and not (IS_MACOS and sys.version_info[:2] == (3, 13))\n+):\n     TEST_VALID_PARAMETERS += [\n-        (\"base\", None, \"console-\"),\n+        (\"base\", None, \"console_legacy-\"),\n+        (\"base\", \"console_legacy\", \"console_legacy-\"),\n     ]\n else:\n     TEST_VALID_PARAMETERS += [\n-        (\"base\", None, \"console_legacy-\"),\n-        (\"base\", \"console_legacy\", \"console_legacy-\"),\n+        (\"base\", None, \"console-\"),\n     ]\n if IS_WINDOWS or IS_MINGW:\n     TEST_VALID_PARAMETERS += [\ndiff --git a/tests/test_freezer.py b/tests/test_freezer.py\n--- a/tests/test_freezer.py\n+++ b/tests/test_freezer.py\n@@ -12,6 +12,7 @@\n \n from cx_Freeze import Freezer\n from cx_Freeze._compat import (\n+    ABI_THREAD,\n     BUILD_EXE_DIR,\n     EXE_SUFFIX,\n     IS_CONDA,\n@@ -99,19 +100,20 @@ def test_freezer_default_bin_includes(tmp_path: Path, monkeypatch) -> None:\n     monkeypatch.chdir(tmp_path)\n \n     freezer = Freezer(executables=[\"hello.py\"])\n+    py_version = f\"{PYTHON_VERSION}{ABI_THREAD}\"\n     if IS_MINGW:\n-        expected = f\"libpython{PYTHON_VERSION}.dll\"\n+        expected = f\"libpython{py_version}.dll\"\n     elif IS_WINDOWS:\n-        expected = f\"python{PYTHON_VERSION.replace('.','')}.dll\"\n+        expected = f\"python{py_version.replace('.','')}.dll\"\n     elif IS_CONDA:  # macOS or Linux\n         if IS_MACOS:\n-            expected = f\"libpython{PYTHON_VERSION}.dylib\"\n+            expected = f\"libpython{py_version}.dylib\"\n         else:\n-            expected = f\"libpython{PYTHON_VERSION}.so*\"\n+            expected = f\"libpython{py_version}.so*\"\n     elif IS_MACOS:\n-        expected = \"Python\"\n+        expected = f\"Python{ABI_THREAD.upper()}\"\n     elif ENABLE_SHARED:  # Linux\n-        expected = f\"libpython{PYTHON_VERSION}.so*\"\n+        expected = f\"libpython{py_version}.so*\"\n     else:\n         assert freezer.default_bin_includes == []\n         return\n", "problem_statement": "Replace _PyMem_RawStrdup with strdup\nPer https://github.com/python/cpython/issues/127991#issuecomment-2547810583\r\n\r\nFixes #2568 \n", "hints_text": "", "created_at": 1735, "language": "python", "label": "Easy"}
{"repo": "marcelotduarte/cx_Freeze", "pull_number": 2583, "instance_id": "marcelotduarte__cx_Freeze-2583", "issue_numbers": ["2572"], "base_commit": "cf4dc4997e54208d90d4bdc419276da6af39dbc4", "patch": "diff --git a/cx_Freeze/executable.py b/cx_Freeze/executable.py\n--- a/cx_Freeze/executable.py\n+++ b/cx_Freeze/executable.py\n@@ -116,7 +116,7 @@ def init_module_name(self) -> str:\n         :rtype: str\n \n         \"\"\"\n-        return f\"{self._internal_name}__init__\"\n+        return f\"__init__{self._internal_name}\"\n \n     @property\n     def init_script(self) -> Path:\n@@ -143,7 +143,7 @@ def main_module_name(self) -> str:\n         :rtype: str\n \n         \"\"\"\n-        return f\"{self._internal_name}__main__\"\n+        return f\"__main__{self._internal_name}\"\n \n     @property\n     def main_script(self) -> Path:\n@@ -231,10 +231,10 @@ def target_name(self, name: str | None) -> None:\n             for invalid in STRINGREPLACE:\n                 name = name.replace(invalid, \"_\")\n         name = os.path.normcase(name)\n-        if not name.isidentifier():\n+        self._internal_name: str = name\n+        if not self.init_module_name.isidentifier():\n             msg = f\"target_name is invalid: {self._name!r}\"\n             raise OptionError(msg)\n-        self._internal_name: str = name\n \n \n def validate_executables(dist: Distribution, attr: str, value) -> None:\ndiff --git a/cx_Freeze/initscripts/__startup__.py b/cx_Freeze/initscripts/__startup__.py\n--- a/cx_Freeze/initscripts/__startup__.py\n+++ b/cx_Freeze/initscripts/__startup__.py\n@@ -124,8 +124,8 @@ def run() -> None:\n     \"\"\"Determines the name of the initscript and execute it.\"\"\"\n     name = get_name(sys.executable)\n     try:\n-        # basically, the basename of the executable plus __init__\n-        module_init = __import__(name + \"__init__\")\n+        # basically is __init__ plus the basename of the executable\n+        module_init = __import__(f\"__init__{name}\")\n     except ModuleNotFoundError:\n         # but can be renamed when only one executable exists\n         num = BUILD_CONSTANTS._EXECUTABLES_NUMBER  # noqa: SLF001\n@@ -137,5 +137,5 @@ def run() -> None:\n             )\n             raise RuntimeError(msg) from None\n         name = get_name(BUILD_CONSTANTS._EXECUTABLE_NAME_0)  # noqa: SLF001\n-        module_init = __import__(name + \"__init__\")\n-    module_init.run(name + \"__main__\")\n+        module_init = __import__(f\"__init__{name}\")\n+    module_init.run(f\"__main__{name}\")\n", "test_patch": "diff --git a/tests/test_cli.py b/tests/test_cli.py\n--- a/tests/test_cli.py\n+++ b/tests/test_cli.py\n@@ -10,16 +10,16 @@\n import pytest\n from generate_samples import create_package, run_command\n \n+from cx_Freeze._compat import BUILD_EXE_DIR, EXE_SUFFIX\n+\n if TYPE_CHECKING:\n     from pathlib import Path\n \n-SUFFIX = \".exe\" if sys.platform == \"win32\" else \"\"\n-\n SOURCE = \"\"\"\n test.py\n     print(\"Hello from cx_Freeze\")\n command\n-    cxfreeze test.py --target-dir=dist --excludes=tkinter\n+    cxfreeze --script test.py --target-dir=dist --excludes=tkinter\n \"\"\"\n \n \n@@ -28,7 +28,7 @@ def test_cxfreeze(tmp_path: Path) -> None:\n     create_package(tmp_path, SOURCE)\n     output = run_command(tmp_path)\n \n-    file_created = tmp_path / \"dist\" / f\"test{SUFFIX}\"\n+    file_created = tmp_path / \"dist\" / f\"test{EXE_SUFFIX}\"\n     assert file_created.is_file(), f\"file not found: {file_created}\"\n \n     output = run_command(tmp_path, file_created, timeout=10)\n@@ -49,15 +49,30 @@ def test_cxfreeze_additional_help(tmp_path: Path) -> None:\n     assert \"usage: \" in output\n \n \n+def test_cxfreeze_target_name_not_isidentifier(tmp_path: Path) -> None:\n+    \"\"\"Test cxfreeze --target-name not isidentifier, but valid filename.\"\"\"\n+    create_package(tmp_path, SOURCE)\n+    output = run_command(\n+        tmp_path,\n+        \"cxfreeze --script test.py --target-name=12345 --excludes=tkinter\",\n+    )\n+\n+    file_created = tmp_path / BUILD_EXE_DIR / f\"12345{EXE_SUFFIX}\"\n+    assert file_created.is_file(), f\"file not found: {file_created}\"\n+\n+    output = run_command(tmp_path, file_created, timeout=10)\n+    assert output.startswith(\"Hello from cx_Freeze\")\n+\n+\n def test_cxfreeze_deprecated_behavior(tmp_path: Path) -> None:\n     \"\"\"Test cxfreeze deprecated behavior.\"\"\"\n     create_package(tmp_path, SOURCE)\n     tmp_path.joinpath(\"test.py\").rename(tmp_path / \"test2\")\n     output = run_command(\n-        tmp_path, \"cxfreeze --target-dir=dist --excludes=tkinter test2\"\n+        tmp_path, \"cxfreeze --install-dir=dist --excludes=tkinter test2\"\n     )\n \n-    file_created = tmp_path / \"dist\" / f\"test2{SUFFIX}\"\n+    file_created = tmp_path / \"dist\" / f\"test2{EXE_SUFFIX}\"\n     assert file_created.is_file(), f\"file not found: {file_created}\"\n \n     output = run_command(tmp_path, file_created, timeout=10)\n@@ -73,7 +88,7 @@ def test_cxfreeze_deprecated_option(tmp_path: Path) -> None:\n     )\n     assert \"WARNING: deprecated\" in output\n \n-    file_created = tmp_path / \"dist\" / f\"test{SUFFIX}\"\n+    file_created = tmp_path / \"dist\" / f\"test{EXE_SUFFIX}\"\n     assert file_created.is_file(), f\"file not found: {file_created}\"\n \n     output = run_command(tmp_path, file_created, timeout=10)\n@@ -127,12 +142,12 @@ def test_cxfreeze_include_path(tmp_path: Path) -> None:\n     create_package(tmp_path, SOURCE_TEST_PATH)\n     output = run_command(tmp_path)\n \n-    executable = tmp_path / \"dist\" / f\"advanced_1{SUFFIX}\"\n+    executable = tmp_path / \"dist\" / f\"advanced_1{EXE_SUFFIX}\"\n     assert executable.is_file()\n     output = run_command(tmp_path, executable, timeout=10)\n     assert output == OUTPUT1\n \n-    executable = tmp_path / \"dist\" / f\"advanced_2{SUFFIX}\"\n+    executable = tmp_path / \"dist\" / f\"advanced_2{EXE_SUFFIX}\"\n     assert executable.is_file()\n     output = run_command(tmp_path, executable, timeout=10)\n     assert output == OUTPUT2\ndiff --git a/tests/test_executables.py b/tests/test_executables.py\n--- a/tests/test_executables.py\n+++ b/tests/test_executables.py\n@@ -232,6 +232,7 @@ def test_executables(\n         (\"init_script\", \"console\", \"console.py\"),\n         (\"target_name\", None, f\"test{EXE_SUFFIX}\"),\n         (\"target_name\", \"test1\", f\"test1{EXE_SUFFIX}\"),\n+        (\"target_name\", \"12345\", f\"12345{EXE_SUFFIX}\"),\n         (\"target_name\", \"test-0.1\", f\"test-0.1{EXE_SUFFIX}\"),\n         (\"target_name\", \"test.exe\", \"test.exe\"),\n         (\"icon\", \"icon\", (\"icon.ico\", \"icon.icns\", \"icon.png\", \"icon.svg\")),\n@@ -279,12 +280,6 @@ def test_valid(option, value, result) -> None:\n             OptionError,\n             \"target_name cannot contain the path, only the filename: \",\n         ),\n-        (\n-            Executable,\n-            {\"script\": \"test.py\", \"target_name\": \"0test\"},\n-            OptionError,\n-            \"target_name is invalid: \",\n-        ),\n     ],\n     ids=[\n         \"executables-invalid-empty\",\n@@ -292,7 +287,6 @@ def test_valid(option, value, result) -> None:\n         \"executable-invalid-base\",\n         \"executable-invalid-init_script\",\n         \"executable-invalid-target_name\",\n-        \"executable-invalid-target_name-isidentifier\",\n     ],\n )\n def test_invalid(\n", "problem_statement": "Why is Executable target_name has to be  A valid identifier?\nIn https://github.com/marcelotduarte/cx_Freeze/blob/7.2.1/cx_Freeze/executable.py#L234 target_name is required to be a valid identifier.\r\n\r\nIs there any reason for that? I removed that condition and it seems to work fine.\r\nmy\r\ntarget_name=\"6578e4ecf0464d7fb253de58\"\r\n\n", "hints_text": "Maybe a regression - issue #884 fixed by #889\r\n\r\n", "created_at": 1727, "language": "python", "label": "Easy"}
{"repo": "rigetti/pyquil", "pull_number": 745, "instance_id": "rigetti__pyquil-745", "issue_numbers": ["744"], "base_commit": "98dec8330958af4723b7befb51345cea182a886c", "patch": "diff --git a/pyquil/noise.py b/pyquil/noise.py\n--- a/pyquil/noise.py\n+++ b/pyquil/noise.py\n@@ -324,10 +324,24 @@ def damping_after_dephasing(T1, T2, gate_time):\n     :param float gate_time: The gate duration.\n     :return: A list of Kraus operators.\n     \"\"\"\n-    damping = damping_kraus_map(p=1 - np.exp(-float(gate_time) / float(T1))) \\\n-        if T1 != INFINITY else [np.eye(2)]\n-    dephasing = dephasing_kraus_map(p=.5 * (1 - np.exp(-2 * gate_time / float(T2)))) \\\n-        if T2 != INFINITY else [np.eye(2)]\n+    assert T1 >= 0\n+    assert T2 >= 0\n+\n+    if T1 != INFINITY:\n+        damping = damping_kraus_map(p=1 - np.exp(-float(gate_time) / float(T1)))\n+    else:\n+        damping = [np.eye(2)]\n+\n+    if T2 != INFINITY:\n+        gamma_phi = float(gate_time) / float(T2)\n+        if T1 != INFINITY:\n+            if T2 > 2 * T1:\n+                raise ValueError(\"T2 is upper bounded by 2 * T1\")\n+            gamma_phi -= float(gate_time) / float(2 * T1)\n+\n+        dephasing = dephasing_kraus_map(p=.5 * (1 - np.exp(-2 * gamma_phi)))\n+    else:\n+        dephasing = [np.eye(2)]\n     return combine_kraus_maps(damping, dephasing)\n \n \n", "test_patch": "diff --git a/pyquil/tests/test_noise.py b/pyquil/tests/test_noise.py\n--- a/pyquil/tests/test_noise.py\n+++ b/pyquil/tests/test_noise.py\n@@ -70,7 +70,7 @@ def test_damping_after_dephasing():\n     dephasing = dephasing_kraus_map(p=.5 * (1 - np.exp(-.2)))\n     ks_ref = combine_kraus_maps(damping, dephasing)\n \n-    ks_actual = damping_after_dephasing(10, 10, 1)\n+    ks_actual = damping_after_dephasing(20, 40 / 3., 2.)\n     np.testing.assert_allclose(ks_actual, ks_ref)\n \n \n", "problem_statement": "T2 noise model is wrong when T1 is finite\nIn particular, a damping noise model with T1 will lead to a contribution to the dephasing rate 1/T2 that equals 1/(2*T1).\n", "hints_text": "", "created_at": 1545, "language": "python", "label": "Hard"}
{"repo": "pytest-dev/pytest-django", "pull_number": 231, "instance_id": "pytest-dev__pytest-django-231", "issue_numbers": ["228"], "base_commit": "1f279deb0d46c4f7dd161945b50f6e2add85793a", "patch": "diff --git a/pytest_django/plugin.py b/pytest_django/plugin.py\n--- a/pytest_django/plugin.py\n+++ b/pytest_django/plugin.py\n@@ -51,6 +51,9 @@ def pytest_addoption(parser):\n     group._addoption('--nomigrations',\n                      action='store_true', dest='nomigrations', default=False,\n                      help='Disable Django 1.7 migrations on test setup')\n+    group._addoption('--no-force-no-debug',\n+                     action='store_true', dest='noforcenodebug', default=False,\n+                     help='Disable forcing DEBUG setting to False on test setup')\n     parser.addini(CONFIGURATION_ENV,\n                   'django-configurations class to use by pytest-django.')\n     group._addoption('--liveserver', default=None,\n@@ -236,7 +239,8 @@ def _django_test_environment(request):\n     if django_settings_is_configured():\n         from django.conf import settings\n         from .compat import setup_test_environment, teardown_test_environment\n-        settings.DEBUG = False\n+        if not request.config.getvalue('noforcenodebug'):\n+            settings.DEBUG = False\n         setup_test_environment()\n         request.addfinalizer(teardown_test_environment)\n \n", "test_patch": "diff --git a/tests/test_django_settings_module.py b/tests/test_django_settings_module.py\n--- a/tests/test_django_settings_module.py\n+++ b/tests/test_django_settings_module.py\n@@ -244,6 +244,31 @@ def test_debug_is_false():\n     assert r.ret == 0\n \n \n+def test_debug_no_force(testdir, monkeypatch):\n+    monkeypatch.delenv('DJANGO_SETTINGS_MODULE')\n+    testdir.makeconftest(\"\"\"\n+        from django.conf import settings\n+\n+        def pytest_configure():\n+            settings.configure(SECRET_KEY='set from pytest_configure',\n+                               DEBUG=True,\n+                               DATABASES={'default': {\n+                                   'ENGINE': 'django.db.backends.sqlite3',\n+                                   'NAME': ':memory:'}},\n+                               INSTALLED_APPS=['django.contrib.auth',\n+                                               'django.contrib.contenttypes',])\n+    \"\"\")\n+\n+    testdir.makepyfile(\"\"\"\n+        from django.conf import settings\n+        def test_debug_is_true():\n+            assert settings.DEBUG is True\n+    \"\"\")\n+\n+    r = testdir.runpytest('--no-force-no-debug')\n+    assert r.ret == 0\n+\n+\n @pytest.mark.skipif(not hasattr(django, 'setup'),\n                     reason=\"This Django version does not support app loading\")\n @pytest.mark.django_project(extra_settings=\"\"\"\n", "problem_statement": "why DEBUG is hardcoded to False?\nHi\n\nhttps://github.com/pytest-dev/pytest-django/blob/master/pytest_django/plugin.py#L239\n\nthis looks not too flexible\nI tried a lot of things before i found this hardcode - i needed to understand why my liveserver fails, and it returned just standard 500 instead of debug page, and debug is set to True in my test settings\nSo i think this hardcode should be removed to respect test settings\n\n", "hints_text": "IIRC the setup with Django's testrunner is also False, to reflect what would be used in production, but I am not certain.\n\n:+1: for a way to configure/override this.\n\nok i'll prepare PR\n", "created_at": 1428, "language": "python", "label": "Easy"}
{"repo": "rigetti/pyquil", "pull_number": 1477, "instance_id": "rigetti__pyquil-1477", "issue_numbers": ["1476"], "base_commit": "57f0501c2d2bc438f983f81fd5793dc969a04ed3", "patch": "diff --git a/pyquil/quil.py b/pyquil/quil.py\n--- a/pyquil/quil.py\n+++ b/pyquil/quil.py\n@@ -874,9 +874,9 @@ def __add__(self, other: InstructionDesignator) -> \"Program\":\n         p = Program()\n         p.inst(self)\n         p.inst(other)\n-        p._calibrations = self.calibrations\n-        p._waveforms = self.waveforms\n-        p._frames = self.frames\n+        p._calibrations = self.calibrations.copy()\n+        p._waveforms = self.waveforms.copy()\n+        p._frames = self.frames.copy()\n         p._memory = self._memory.copy()\n         if isinstance(other, Program):\n             p.calibrations.extend(other.calibrations)\n", "test_patch": "diff --git a/test/unit/test_program.py b/test/unit/test_program.py\n--- a/test/unit/test_program.py\n+++ b/test/unit/test_program.py\n@@ -56,3 +56,31 @@ def test_parameterized_readout_symmetrization():\n     p += RX(symmetrization[0], 0)\n     p += RX(symmetrization[1], 1)\n     assert parameterized_readout_symmetrization([0, 1]).out() == p.out()\n+\n+\n+def test_adding_does_not_mutate():\n+    # https://github.com/rigetti/pyquil/issues/1476\n+    p1 = Program(\n+        \"\"\"\n+DEFCAL RX(pi/2) 32:\n+    FENCE 32\n+    NONBLOCKING PULSE 32 \"rf\" drag_gaussian(duration: 3.2e-08, fwhm: 8e-09, t0: 1.6e-08, anh: -190000000.0, alpha: -1.8848698349348032, scale: 0.30631340170943533, phase: 0.0, detuning: 1622438.2425563578)\n+    FENCE 32\n+\n+RX(pi/2) 32\n+\"\"\"\n+    )\n+    original_p1 = p1.copy()\n+    p2 = Program(\n+        \"\"\"\n+DEFCAL RX(pi/2) 33:\n+    FENCE 33\n+    NONBLOCKING PULSE 33 \"rf\" drag_gaussian(duration: 2e-08, fwhm: 5e-09, t0: 1e-08, anh: -190000000.0, alpha: -0.9473497322033984, scale: 0.25680107985232403, phase: 0.0, detuning: 1322130.5458282642)\n+    FENCE 33\n+\n+RX(pi/2) 33\n+\"\"\"\n+    )\n+    p_all = p1 + p2\n+    assert p1 == original_p1\n+    assert p1.calibrations != p_all.calibrations\ndiff --git a/test/unit/test_quil.py b/test/unit/test_quil.py\nold mode 100755\nnew mode 100644\n", "problem_statement": "Adding two `Program`s together unexpectedly mutates first `Program`\nPre-Report Checklist\r\n--------------------\r\n\r\n- [x] I am running the latest versions of pyQuil and the Forest SDK\r\n- [x] I checked to make sure that this bug has not already been reported\r\n\r\nIssue Description\r\n-----------------\r\n\r\nSummary: when adding two Programs together, like p1 + p2, the first program p1 gets mutated â€” p1.calibrations will as a result contain the combined calibrations. But I would have expected both p1 and p2 to remain unchanged.\r\n\r\nI believe the reason for issue is that in the source code, it uses `p.calibrations.extend(other.calibrations)`\r\nwhich mutates the originalâ€™s list\r\n. https://github.com/rigetti/pyquil/blob/master/pyquil/quil.py#L882\r\n\r\nHow to Reproduce\r\n----------------\r\n### Code Snippet\r\n\r\n```python\r\nprint(\"@@@ p32 before adding\")\r\nprint(p32)\r\n\r\nprint(\"@@@ p33 before adding\")\r\nprint(p33)\r\n\r\np_all = p32 + p33\r\n\r\nprint(\"@@@ p32 after adding <-- here is the unexpected behavior\")\r\nprint(p32)\r\n\r\nprint(\"@@@ p33 after adding\")\r\nprint(p33)\r\n\r\nprint(\"@@@ p_all after adding\")\r\nprint(p_all)\r\n```\r\n\r\n### Error Output\r\n\r\n```\r\n@@@ p32 before adding\r\nDEFCAL RX(pi/2) 32:\r\n    FENCE 32\r\n    NONBLOCKING PULSE 32 \"rf\" drag_gaussian(duration: 3.2e-08, fwhm: 8e-09, t0: 1.6e-08, anh: -190000000.0, alpha: -1.8848698349348032, scale: 0.30631340170943533, phase: 0.0, detuning: 1622438.2425563578)\r\n    FENCE 32\r\n\r\nRX(pi/2) 32\r\n\r\n@@@ p33 before adding\r\nDEFCAL RX(pi/2) 33:\r\n    FENCE 33\r\n    NONBLOCKING PULSE 33 \"rf\" drag_gaussian(duration: 2e-08, fwhm: 5e-09, t0: 1e-08, anh: -190000000.0, alpha: -0.9473497322033984, scale: 0.25680107985232403, phase: 0.0, detuning: 1322130.5458282642)\r\n    FENCE 33\r\n\r\nRX(pi/2) 33\r\n\r\n@@@ p32 after adding <-- here is the unexpected behavior\r\nDEFCAL RX(pi/2) 32:\r\n    FENCE 32\r\n    NONBLOCKING PULSE 32 \"rf\" drag_gaussian(duration: 3.2e-08, fwhm: 8e-09, t0: 1.6e-08, anh: -190000000.0, alpha: -1.8848698349348032, scale: 0.30631340170943533, phase: 0.0, detuning: 1622438.2425563578)\r\n    FENCE 32\r\n\r\nDEFCAL RX(pi/2) 33:\r\n    FENCE 33\r\n    NONBLOCKING PULSE 33 \"rf\" drag_gaussian(duration: 2e-08, fwhm: 5e-09, t0: 1e-08, anh: -190000000.0, alpha: -0.9473497322033984, scale: 0.25680107985232403, phase: 0.0, detuning: 1322130.5458282642)\r\n    FENCE 33\r\n\r\nRX(pi/2) 32\r\n\r\n@@@ p33 after adding\r\nDEFCAL RX(pi/2) 33:\r\n    FENCE 33\r\n    NONBLOCKING PULSE 33 \"rf\" drag_gaussian(duration: 2e-08, fwhm: 5e-09, t0: 1e-08, anh: -190000000.0, alpha: -0.9473497322033984, scale: 0.25680107985232403, phase: 0.0, detuning: 1322130.5458282642)\r\n    FENCE 33\r\n\r\nRX(pi/2) 33\r\n\r\n@@@ p_all after adding\r\nDEFCAL RX(pi/2) 32:\r\n    FENCE 32\r\n    NONBLOCKING PULSE 32 \"rf\" drag_gaussian(duration: 3.2e-08, fwhm: 8e-09, t0: 1.6e-08, anh: -190000000.0, alpha: -1.8848698349348032, scale: 0.30631340170943533, phase: 0.0, detuning: 1622438.2425563578)\r\n    FENCE 32\r\n\r\nDEFCAL RX(pi/2) 33:\r\n    FENCE 33\r\n    NONBLOCKING PULSE 33 \"rf\" drag_gaussian(duration: 2e-08, fwhm: 5e-09, t0: 1e-08, anh: -190000000.0, alpha: -0.9473497322033984, scale: 0.25680107985232403, phase: 0.0, detuning: 1322130.5458282642)\r\n    FENCE 33\r\n\r\nRX(pi/2) 32\r\nRX(pi/2) 33\r\n```\r\n\r\nEnvironment Context\r\n-------------------\r\n\r\nOperating System:  macOS Monterey\r\n\r\nPython Version (`python -V`):  3.9.13\r\n\r\nQuilc Version (`quilc --version`): N/A\r\n\r\nQVM Version (`qvm --version`): N/A\r\n\r\nPython Environment Details (`pip freeze` or `conda list`): \r\n\r\n```\r\nPackage                       Version\r\n----------------------------- -----------\r\naiohttp                       3.8.1\r\naiohttp-retry                 2.4.6\r\naiosignal                     1.2.0\r\nalabaster                     0.7.12\r\nansiwrap                      0.8.4\r\nanyio                         3.6.1\r\nappdirs                       1.4.4\r\nargon2-cffi                   21.3.0\r\nargon2-cffi-bindings          21.2.0\r\nasteval                       0.9.26\r\nasttokens                     2.0.5\r\nasync-timeout                 4.0.2\r\nasyncssh                      2.10.1\r\natpublic                      3.0.1\r\nattrs                         20.3.0\r\nBabel                         2.10.1\r\nbackcall                      0.2.0\r\nbeautifulsoup4                4.11.1\r\nbenchmark-quantum-gates       0.5.0\r\nbitarray                      2.5.1\r\nblack                         22.3.0\r\nbleach                        5.0.0\r\ncachetools                    5.0.0\r\ncertifi                       2021.10.8\r\ncffi                          1.15.0\r\ncharset-normalizer            2.0.12\r\nclick                         8.1.3\r\ncolorama                      0.4.4\r\ncommonmark                    0.9.1\r\nconfigobj                     5.0.6\r\ncoverage                      6.3.3\r\ncryptography                  37.0.2\r\ncvxopt                        1.3.0\r\ncvxpy                         1.2.0\r\ncycler                        0.11.0\r\ndebugpy                       1.6.3\r\ndecorator                     5.1.1\r\ndefusedxml                    0.7.1\r\ndictdiffer                    0.9.0\r\ndiskcache                     5.4.0\r\ndistro                        1.7.0\r\ndocutils                      0.17.1\r\ndpath                         2.0.6\r\ndulwich                       0.20.35\r\ndvc                           2.10.2\r\ndvc-render                    0.0.5\r\ndvclive                       0.8.0\r\necos                          2.0.10\r\nentrypoints                   0.4\r\nexecuting                     0.8.3\r\nfastjsonschema                2.15.3\r\nflake8                        4.0.1\r\nflake8-black                  0.3.2\r\nflake8-docstrings             1.6.0\r\nflatten-dict                  0.4.2\r\nflufl.lock                    7.0\r\nfonttools                     4.33.3\r\nforest-benchmarking           0.8.0\r\nfrozenlist                    1.3.0\r\nfsspec                        2022.3.0\r\nftfy                          6.1.1\r\nfuncy                         1.17\r\nfuture                        0.18.2\r\nfuture-fstrings               1.2.0\r\ngitdb                         4.0.9\r\nGitPython                     3.1.27\r\ngoogle-api-core               2.7.3\r\ngoogle-api-python-client      2.47.0\r\ngoogle-auth                   2.6.6\r\ngoogle-auth-httplib2          0.1.0\r\ngoogleapis-common-protos      1.56.1\r\ngprof2dot                     2021.2.21\r\ngrandalf                      0.6\r\nh11                           0.9.0\r\nhttpcore                      0.11.1\r\nhttplib2                      0.20.4\r\nhttpx                         0.15.5\r\nidna                          3.3\r\nimagesize                     1.3.0\r\nimportlib-metadata            4.11.3\r\niniconfig                     1.1.1\r\nipykernel                     6.13.0\r\nipympl                        0.9.2\r\nipython                       8.3.0\r\nipython-genutils              0.2.0\r\nipywidgets                    7.7.0\r\niso8601                       0.1.16\r\nisort                         5.10.1\r\njedi                          0.18.1\r\nJinja2                        3.1.2\r\njoblib                        1.1.0\r\njson5                         0.9.8\r\njsonschema                    4.5.1\r\njupyter-client                7.3.1\r\njupyter-core                  4.10.0\r\njupyter-lsp                   1.5.1\r\njupyter-server                1.17.0\r\njupyter-server-mathjax        0.2.5\r\njupyterlab                    3.4.2\r\njupyterlab-git                0.34.2\r\njupyterlab-lsp                3.10.1\r\njupyterlab-pygments           0.2.2\r\njupyterlab-server             2.13.0\r\njupyterlab-widgets            1.1.0\r\nkaleido                       0.2.1\r\nkiwisolver                    1.4.2\r\nlark                          0.11.3\r\nlmfit                         1.0.3\r\nmailchecker                   4.1.16\r\nMako                          1.2.1\r\nMarkupSafe                    2.1.1\r\nmatplotlib                    3.5.2\r\nmatplotlib-inline             0.1.3\r\nmccabe                        0.6.1\r\nmistune                       0.8.4\r\nmpmath                        1.2.1\r\nmsgpack                       0.6.2\r\nmultidict                     6.0.2\r\nmypy-extensions               0.4.3\r\nnanotime                      0.5.2\r\nnbclassic                     0.3.7\r\nnbclient                      0.6.3\r\nnbconvert                     6.5.0\r\nnbdime                        3.1.1\r\nnbformat                      5.4.0\r\nnest-asyncio                  1.5.5\r\nnetworkx                      2.8\r\nnotebook                      6.4.11\r\nnotebook-shim                 0.1.0\r\nnumexpr                       2.8.1\r\nnumpy                         1.21.0\r\noauth2client                  4.1.3\r\nosqp                          0.6.2.post5\r\npackaging                     21.3\r\npandas                        1.4.2\r\npandocfilters                 1.5.0\r\npapermill                     2.3.4\r\nparso                         0.8.3\r\npathspec                      0.9.0\r\npatsy                         0.5.2\r\npexpect                       4.8.0\r\nphonenumbers                  8.12.48\r\npickleshare                   0.7.5\r\nPillow                        9.1.0\r\npip                           22.2.2\r\nplatformdirs                  2.5.2\r\nplotly                        5.8.0\r\npluggy                        1.0.0\r\nprometheus-client             0.14.1\r\nprompt-toolkit                3.0.29\r\nprotobuf                      3.20.1\r\npsutil                        5.9.0\r\nptyprocess                    0.7.0\r\npure-eval                     0.2.2\r\npy                            1.11.0\r\npyaml                         21.10.1\r\npyarrow                       5.0.0\r\npyasn1                        0.4.8\r\npyasn1-modules                0.2.8\r\npycodestyle                   2.8.0\r\npycparser                     2.21\r\npydantic                      1.9.0\r\npydocstyle                    6.1.1\r\npydot                         1.4.2\r\nPyDrive2                      1.10.1\r\npyflakes                      2.4.0\r\npygit2                        1.9.1\r\nPygments                      2.12.0\r\npygtrie                       2.4.2\r\nPyJWT                         1.7.1\r\npyOpenSSL                     22.0.0\r\npyparsing                     3.0.9\r\npyquil                        3.1.0\r\npyrsistent                    0.18.1\r\npytest                        7.1.2\r\npytest-cov                    3.0.0\r\npytest-depends                1.0.1\r\npytest-profiling              1.7.0\r\npython-benedict               0.25.1\r\npython-dateutil               2.8.2\r\npython-fsutil                 0.6.0\r\npython-rapidjson              1.6\r\npython-slugify                6.1.2\r\npytz                          2022.1\r\nPyYAML                        6.0\r\npyzmq                         22.3.0\r\nqcs-api-client                0.20.13\r\nqdldl                         0.1.5.post2\r\nqpu-hybrid-benchmark-trueq    0.5.8\r\nqutip                         4.7.0\r\nqutip-qip                     0.2.1\r\nrequests                      2.27.1\r\nretry                         0.9.2\r\nretrying                      1.3.3\r\nrfc3339                       6.2\r\nrfc3986                       1.5.0\r\nrich                          12.4.1\r\nrigetti-qpu-hybrid-benchmark  0.5.24\r\nrpcq                          3.10.0\r\nrsa                           4.8\r\nruamel.yaml                   0.17.21\r\nruamel.yaml.clib              0.2.6\r\nscikit-learn                  1.1.0\r\nscikit-optimize               0.9.0\r\nscipy                         1.8.0\r\nscmrepo                       0.0.19\r\nscs                           3.2.0\r\nseaborn                       0.11.2\r\nSend2Trash                    1.8.0\r\nsetuptools                    63.4.1\r\nsetuptools-scm                6.4.2\r\nshortuuid                     1.0.9\r\nshtab                         1.5.4\r\nsix                           1.16.0\r\nsmmap                         5.0.0\r\nsniffio                       1.2.0\r\nsnowballstemmer               2.2.0\r\nsoupsieve                     2.3.2.post1\r\nSphinx                        4.5.0\r\nsphinx-autodoc-typehints      1.18.1\r\nsphinx-rtd-theme              0.4.3\r\nsphinxcontrib-applehelp       1.0.2\r\nsphinxcontrib-devhelp         1.0.2\r\nsphinxcontrib-htmlhelp        2.0.0\r\nsphinxcontrib-jsmath          1.0.1\r\nsphinxcontrib-qthelp          1.0.3\r\nsphinxcontrib-serializinghtml 1.1.5\r\nstack-data                    0.2.0\r\nstatsmodels                   0.13.2\r\nsympy                         1.10.1\r\ntables                        3.7.0\r\ntabulate                      0.8.9\r\ntenacity                      8.0.1\r\nterminado                     0.13.3\r\ntext-unidecode                1.3\r\ntextwrap3                     0.9.2\r\nthreadpoolctl                 3.1.0\r\ntinycss2                      1.1.1\r\ntokenize-rt                   4.2.1\r\ntoml                          0.10.2\r\ntomli                         2.0.1\r\ntornado                       6.1\r\ntqdm                          4.64.0\r\ntraitlets                     5.2.0\r\ntrueq                         2.13.1\r\ntyping_extensions             4.2.0\r\nuncertainties                 3.1.6\r\nuritemplate                   4.1.1\r\nurllib3                       1.26.9\r\nvoluptuous                    0.13.1\r\nwcwidth                       0.2.5\r\nwebencodings                  0.5.1\r\nwebsocket-client              1.3.2\r\nwheel                         0.37.1\r\nwidgetsnbextension            3.6.0\r\nxmltodict                     0.13.0\r\nyarl                          1.7.2\r\nzc.lockfile                   2.0\r\nzipp                          3.8.0\r\n```\r\n\n", "hints_text": "", "created_at": 1663, "language": "python", "label": "Hard"}
{"repo": "pytest-dev/pytest-django", "pull_number": 881, "instance_id": "pytest-dev__pytest-django-881", "issue_numbers": ["513"], "base_commit": "bb9e86e0c0141a30d07078f71b288026b6e583d2", "patch": "diff --git a/pytest_django/fixtures.py b/pytest_django/fixtures.py\n--- a/pytest_django/fixtures.py\n+++ b/pytest_django/fixtures.py\n@@ -304,7 +304,7 @@ def admin_client(db, admin_user):\n     from django.test.client import Client\n \n     client = Client()\n-    client.login(username=admin_user.username, password=\"password\")\n+    client.force_login(admin_user)\n     return client\n \n \n", "test_patch": "diff --git a/tests/test_fixtures.py b/tests/test_fixtures.py\n--- a/tests/test_fixtures.py\n+++ b/tests/test_fixtures.py\n@@ -49,6 +49,17 @@ def test_admin_client_no_db_marker(admin_client):\n     assert force_str(resp.content) == \"You are an admin\"\n \n \n+# For test below.\n+@pytest.fixture\n+def existing_admin_user(django_user_model):\n+    return django_user_model._default_manager.create_superuser('admin', None, None)\n+\n+\n+def test_admin_client_existing_user(db, existing_admin_user, admin_user, admin_client):\n+    resp = admin_client.get(\"/admin-required/\")\n+    assert force_str(resp.content) == \"You are an admin\"\n+\n+\n @pytest.mark.django_db\n def test_admin_user(admin_user, django_user_model):\n     assert isinstance(admin_user, django_user_model)\n", "problem_statement": "admin_client is not checking for login success\n`client.login` inside `admin_client` can return `False` in the case when there's an existing admin user with a password set to something other than `'password'`. Perhaps, `admin_client` should use `force_login` instead?\n", "hints_text": "Seems sensible\r\nCan you provide a failing test and fix in a PR?\nSure, I'll do that in the next couple of days.", "created_at": 1602, "language": "python", "label": "Easy"}
{"repo": "pytest-dev/pytest-django", "pull_number": 869, "instance_id": "pytest-dev__pytest-django-869", "issue_numbers": ["660"], "base_commit": "9d91f0b5492c136d4cd9d6012672783171b4034c", "patch": "diff --git a/docs/conf.py b/docs/conf.py\n--- a/docs/conf.py\n+++ b/docs/conf.py\n@@ -1,5 +1,3 @@\n-# -*- coding: utf-8 -*-\n-\n import os\n import sys\n import datetime\ndiff --git a/pytest_django/asserts.py b/pytest_django/asserts.py\n--- a/pytest_django/asserts.py\n+++ b/pytest_django/asserts.py\n@@ -23,10 +23,10 @@ def assertion_func(*args, **kwargs):\n __all__ = []\n assertions_names = set()\n assertions_names.update(\n-    set(attr for attr in vars(TestCase) if attr.startswith('assert')),\n-    set(attr for attr in vars(SimpleTestCase) if attr.startswith('assert')),\n-    set(attr for attr in vars(LiveServerTestCase) if attr.startswith('assert')),\n-    set(attr for attr in vars(TransactionTestCase) if attr.startswith('assert')),\n+    {attr for attr in vars(TestCase) if attr.startswith('assert')},\n+    {attr for attr in vars(SimpleTestCase) if attr.startswith('assert')},\n+    {attr for attr in vars(LiveServerTestCase) if attr.startswith('assert')},\n+    {attr for attr in vars(TransactionTestCase) if attr.startswith('assert')},\n )\n \n for assert_func in assertions_names:\ndiff --git a/pytest_django/compat.py b/pytest_django/compat.py\ndeleted file mode 100644\n--- a/pytest_django/compat.py\n+++ /dev/null\n@@ -1,12 +0,0 @@\n-# This file cannot be imported from until Django sets up\n-try:\n-    # Django 1.11+\n-    from django.test.utils import setup_databases, teardown_databases  # noqa: F401, F811\n-except ImportError:\n-    # In Django prior to 1.11, teardown_databases is only available as a method on DiscoverRunner\n-    from django.test.runner import setup_databases, DiscoverRunner  # noqa: F401, F811\n-\n-    def teardown_databases(db_cfg, verbosity):\n-        DiscoverRunner(verbosity=verbosity, interactive=False).teardown_databases(\n-            db_cfg\n-        )\ndiff --git a/pytest_django/fixtures.py b/pytest_django/fixtures.py\n--- a/pytest_django/fixtures.py\n+++ b/pytest_django/fixtures.py\n@@ -1,9 +1,7 @@\n \"\"\"All pytest-django fixtures\"\"\"\n \n-from __future__ import with_statement\n \n import os\n-import warnings\n from contextlib import contextmanager\n from functools import partial\n \n@@ -91,7 +89,7 @@ def django_db_setup(\n     django_db_modify_db_settings,\n ):\n     \"\"\"Top level fixture to ensure test databases are available\"\"\"\n-    from .compat import setup_databases, teardown_databases\n+    from django.test.utils import setup_databases, teardown_databases\n \n     setup_databases_args = {}\n \n@@ -164,7 +162,7 @@ def _disable_native_migrations():\n     class MigrateSilentCommand(migrate.Command):\n         def handle(self, *args, **kwargs):\n             kwargs[\"verbosity\"] = 0\n-            return super(MigrateSilentCommand, self).handle(*args, **kwargs)\n+            return super().handle(*args, **kwargs)\n \n     migrate.Command = MigrateSilentCommand\n \n@@ -320,7 +318,7 @@ def rf():\n     return RequestFactory()\n \n \n-class SettingsWrapper(object):\n+class SettingsWrapper:\n     _to_restore = []\n \n     def __delattr__(self, attr):\n@@ -370,8 +368,8 @@ def live_server(request):\n     The address the server is started from is taken from the\n     --liveserver command line option or if this is not provided from\n     the DJANGO_LIVE_TEST_SERVER_ADDRESS environment variable.  If\n-    neither is provided ``localhost:8081,8100-8200`` is used.  See the\n-    Django documentation for its full syntax.\n+    neither is provided ``localhost`` is used.  See the Django\n+    documentation for its full syntax.\n \n     NOTE: If the live server needs database access to handle a request\n           your test will have to request database access.  Furthermore\n@@ -385,27 +383,9 @@ def live_server(request):\n     \"\"\"\n     skip_if_no_django()\n \n-    import django\n-\n     addr = request.config.getvalue(\"liveserver\") or os.getenv(\n         \"DJANGO_LIVE_TEST_SERVER_ADDRESS\"\n-    )\n-\n-    if addr and \":\" in addr:\n-        if django.VERSION >= (1, 11):\n-            ports = addr.split(\":\")[1]\n-            if \"-\" in ports or \",\" in ports:\n-                warnings.warn(\n-                    \"Specifying multiple live server ports is not supported \"\n-                    \"in Django 1.11. This will be an error in a future \"\n-                    \"pytest-django release.\"\n-                )\n-\n-    if not addr:\n-        if django.VERSION < (1, 11):\n-            addr = \"localhost:8081,8100-8200\"\n-        else:\n-            addr = \"localhost\"\n+    ) or \"localhost\"\n \n     server = live_server_helper.LiveServer(addr)\n     request.addfinalizer(server.stop)\n@@ -458,14 +438,14 @@ def _assert_num_queries(config, num, exact=True, connection=None, info=None):\n                 num,\n                 \"\" if exact else \"or less \",\n                 \"but {} done\".format(\n-                    num_performed == 1 and \"1 was\" or \"%d were\" % (num_performed,)\n+                    num_performed == 1 and \"1 was\" or \"{} were\".format(num_performed)\n                 ),\n             )\n             if info:\n                 msg += \"\\n{}\".format(info)\n             if verbose:\n                 sqls = (q[\"sql\"] for q in context.captured_queries)\n-                msg += \"\\n\\nQueries:\\n========\\n\\n%s\" % \"\\n\\n\".join(sqls)\n+                msg += \"\\n\\nQueries:\\n========\\n\\n\" + \"\\n\\n\".join(sqls)\n             else:\n                 msg += \" (add -v option to show queries)\"\n             pytest.fail(msg)\ndiff --git a/pytest_django/live_server_helper.py b/pytest_django/live_server_helper.py\n--- a/pytest_django/live_server_helper.py\n+++ b/pytest_django/live_server_helper.py\n@@ -1,8 +1,4 @@\n-import six\n-\n-\n-@six.python_2_unicode_compatible\n-class LiveServer(object):\n+class LiveServer:\n     \"\"\"The liveserver fixture\n \n     This is the object that the ``live_server`` fixture returns.\n@@ -10,7 +6,6 @@ class LiveServer(object):\n     \"\"\"\n \n     def __init__(self, addr):\n-        import django\n         from django.db import connections\n         from django.test.testcases import LiveServerThread\n         from django.test.utils import modify_settings\n@@ -39,17 +34,13 @@ def __init__(self, addr):\n \n             liveserver_kwargs[\"static_handler\"] = _StaticFilesHandler\n \n-        if django.VERSION < (1, 11):\n-            host, possible_ports = parse_addr(addr)\n-            self.thread = LiveServerThread(host, possible_ports, **liveserver_kwargs)\n+        try:\n+            host, port = addr.split(\":\")\n+        except ValueError:\n+            host = addr\n         else:\n-            try:\n-                host, port = addr.split(\":\")\n-            except ValueError:\n-                host = addr\n-            else:\n-                liveserver_kwargs[\"port\"] = int(port)\n-            self.thread = LiveServerThread(host, **liveserver_kwargs)\n+            liveserver_kwargs[\"port\"] = int(port)\n+        self.thread = LiveServerThread(host, **liveserver_kwargs)\n \n         self._live_server_modified_settings = modify_settings(\n             ALLOWED_HOSTS={\"append\": host}\n@@ -69,41 +60,13 @@ def stop(self):\n \n     @property\n     def url(self):\n-        return \"http://%s:%s\" % (self.thread.host, self.thread.port)\n+        return \"http://{}:{}\".format(self.thread.host, self.thread.port)\n \n     def __str__(self):\n         return self.url\n \n     def __add__(self, other):\n-        return \"%s%s\" % (self, other)\n+        return \"{}{}\".format(self, other)\n \n     def __repr__(self):\n         return \"<LiveServer listening at %s>\" % self.url\n-\n-\n-def parse_addr(specified_address):\n-    \"\"\"Parse the --liveserver argument into a host/IP address and port range\"\"\"\n-    # This code is based on\n-    # django.test.testcases.LiveServerTestCase.setUpClass\n-\n-    # The specified ports may be of the form '8000-8010,8080,9200-9300'\n-    # i.e. a comma-separated list of ports or ranges of ports, so we break\n-    # it down into a detailed list of all possible ports.\n-    possible_ports = []\n-    try:\n-        host, port_ranges = specified_address.split(\":\")\n-        for port_range in port_ranges.split(\",\"):\n-            # A port range can be of either form: '8000' or '8000-8010'.\n-            extremes = list(map(int, port_range.split(\"-\")))\n-            assert len(extremes) in (1, 2)\n-            if len(extremes) == 1:\n-                # Port range of the form '8000'\n-                possible_ports.append(extremes[0])\n-            else:\n-                # Port range of the form '8000-8010'\n-                for port in range(extremes[0], extremes[1] + 1):\n-                    possible_ports.append(port)\n-    except Exception:\n-        raise Exception('Invalid address (\"%s\") for live server.' % specified_address)\n-\n-    return host, possible_ports\ndiff --git a/pytest_django/migrations.py b/pytest_django/migrations.py\n--- a/pytest_django/migrations.py\n+++ b/pytest_django/migrations.py\n@@ -2,7 +2,7 @@\n from pytest_django.lazy_django import get_django_version\n \n \n-class DisableMigrations(object):\n+class DisableMigrations:\n     def __init__(self):\n         self._django_version = get_django_version()\n \n@@ -10,7 +10,4 @@ def __contains__(self, item):\n         return True\n \n     def __getitem__(self, item):\n-        if self._django_version >= (1, 9):\n-            return None\n-        else:\n-            return \"notmigrations\"\n+        return None\ndiff --git a/pytest_django/plugin.py b/pytest_django/plugin.py\n--- a/pytest_django/plugin.py\n+++ b/pytest_django/plugin.py\n@@ -8,6 +8,7 @@\n import inspect\n from functools import reduce\n import os\n+import pathlib\n import sys\n import types\n \n@@ -39,22 +40,11 @@\n \n from .lazy_django import django_settings_is_configured, skip_if_no_django\n \n-try:\n-    import pathlib\n-except ImportError:\n-    import pathlib2 as pathlib\n-\n \n SETTINGS_MODULE_ENV = \"DJANGO_SETTINGS_MODULE\"\n CONFIGURATION_ENV = \"DJANGO_CONFIGURATION\"\n INVALID_TEMPLATE_VARS_ENV = \"FAIL_INVALID_TEMPLATE_VARS\"\n \n-PY2 = sys.version_info[0] == 2\n-\n-# pytest 4.2 handles unittest setup/teardown itself via wrapping fixtures.\n-_pytest_version_info = tuple(int(x) for x in pytest.__version__.split(\".\", 2)[:2])\n-_handle_unittest_methods = _pytest_version_info < (4, 2)\n-\n _report_header = []\n \n \n@@ -303,11 +293,11 @@ def _get_option_with_source(option, envname):\n     dc, dc_source = _get_option_with_source(options.dc, CONFIGURATION_ENV)\n \n     if ds:\n-        _report_header.append(\"settings: %s (from %s)\" % (ds, ds_source))\n+        _report_header.append(\"settings: {} (from {})\".format(ds, ds_source))\n         os.environ[SETTINGS_MODULE_ENV] = ds\n \n         if dc:\n-            _report_header.append(\"configuration: %s (from %s)\" % (dc, dc_source))\n+            _report_header.append(\"configuration: {} (from {})\".format(dc, dc_source))\n             os.environ[CONFIGURATION_ENV] = dc\n \n             # Install the django-configurations importer\n@@ -330,7 +320,7 @@ def pytest_report_header():\n         return [\"django: \" + \", \".join(_report_header)]\n \n \n-@pytest.mark.trylast\n+@pytest.hookimpl(trylast=True)\n def pytest_configure():\n     # Allow Django settings to be configured in a user pytest_configure call,\n     # but make sure we call django.setup()\n@@ -354,13 +344,7 @@ def _classmethod_is_defined_at_leaf(cls, method_name):\n     try:\n         f = method.__func__\n     except AttributeError:\n-        pytest.fail(\"%s.%s should be a classmethod\" % (cls, method_name))\n-    if PY2 and not (\n-        inspect.ismethod(method)\n-        and inspect.isclass(method.__self__)\n-        and issubclass(cls, method.__self__)\n-    ):\n-        pytest.fail(\"%s.%s should be a classmethod\" % (cls, method_name))\n+        pytest.fail(\"{}.{} should be a classmethod\".format(cls, method_name))\n     return f is not super_method.__func__\n \n \n@@ -409,12 +393,6 @@ def _restore_class_methods(cls):\n         cls.tearDownClass = tearDownClass\n \n \n-def pytest_runtest_setup(item):\n-    if _handle_unittest_methods:\n-        if django_settings_is_configured() and is_django_unittest(item):\n-            _disable_class_methods(item.cls)\n-\n-\n @pytest.hookimpl(tryfirst=True)\n def pytest_collection_modifyitems(items):\n     # If Django is not configured we don't need to bother\n@@ -523,33 +501,21 @@ def _django_setup_unittest(request, django_db_blocker):\n     # Fix/patch pytest.\n     # Before pytest 5.4: https://github.com/pytest-dev/pytest/issues/5991\n     # After pytest 5.4: https://github.com/pytest-dev/pytest-django/issues/824\n-    from _pytest.monkeypatch import MonkeyPatch\n+    from _pytest.unittest import TestCaseFunction\n+    original_runtest = TestCaseFunction.runtest\n \n     def non_debugging_runtest(self):\n         self._testcase(result=self)\n \n-    mp_debug = MonkeyPatch()\n-    mp_debug.setattr(\"_pytest.unittest.TestCaseFunction.runtest\", non_debugging_runtest)\n-\n-    request.getfixturevalue(\"django_db_setup\")\n-\n-    cls = request.node.cls\n-\n-    with django_db_blocker.unblock():\n-        if _handle_unittest_methods:\n-            _restore_class_methods(cls)\n-            cls.setUpClass()\n-            _disable_class_methods(cls)\n+    try:\n+        TestCaseFunction.runtest = non_debugging_runtest\n \n-            yield\n+        request.getfixturevalue(\"django_db_setup\")\n \n-            _restore_class_methods(cls)\n-            cls.tearDownClass()\n-        else:\n+        with django_db_blocker.unblock():\n             yield\n-\n-    if mp_debug:\n-        mp_debug.undo()\n+    finally:\n+        TestCaseFunction.runtest = original_runtest\n \n \n @pytest.fixture(scope=\"function\", autouse=True)\n@@ -591,12 +557,7 @@ def _django_set_urlconf(request):\n     if marker:\n         skip_if_no_django()\n         import django.conf\n-\n-        try:\n-            from django.urls import clear_url_caches, set_urlconf\n-        except ImportError:\n-            # Removed in Django 2.0\n-            from django.core.urlresolvers import clear_url_caches, set_urlconf\n+        from django.urls import clear_url_caches, set_urlconf\n \n         urls = validate_urls(marker)\n         original_urlconf = django.conf.settings.ROOT_URLCONF\n@@ -629,7 +590,7 @@ def _fail_for_invalid_template_variable():\n     ``pytest.mark.ignore_template_errors``\n     \"\"\"\n \n-    class InvalidVarException(object):\n+    class InvalidVarException:\n         \"\"\"Custom handler for invalid strings in templates.\"\"\"\n \n         def __init__(self):\n@@ -677,7 +638,7 @@ def __mod__(self, var):\n             \"\"\"Handle TEMPLATE_STRING_IF_INVALID % var.\"\"\"\n             origin = self._get_origin()\n             if origin:\n-                msg = \"Undefined template variable '%s' in '%s'\" % (var, origin)\n+                msg = \"Undefined template variable '{}' in '{}'\".format(var, origin)\n             else:\n                 msg = \"Undefined template variable '%s'\" % var\n             if self.fail:\n@@ -732,7 +693,7 @@ def _django_clear_site_cache():\n # ############### Helper Functions ################\n \n \n-class _DatabaseBlockerContextManager(object):\n+class _DatabaseBlockerContextManager:\n     def __init__(self, db_blocker):\n         self._db_blocker = db_blocker\n \n@@ -743,7 +704,7 @@ def __exit__(self, exc_type, exc_value, traceback):\n         self._db_blocker.restore()\n \n \n-class _DatabaseBlocker(object):\n+class _DatabaseBlocker:\n     \"\"\"Manager for django.db.backends.base.base.BaseDatabaseWrapper.\n \n     This is the object returned by django_db_blocker.\ndiff --git a/setup.py b/setup.py\n--- a/setup.py\n+++ b/setup.py\n@@ -1,5 +1,4 @@\n #!/usr/bin/env python\n-# -*- coding: utf-8 -*-\n \n import codecs\n import os\n@@ -28,11 +27,10 @@ def read(fname):\n     license='BSD-3-Clause',\n     packages=['pytest_django'],\n     long_description=read('README.rst'),\n-    python_requires='>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*',\n+    python_requires='>=3.5',\n     setup_requires=['setuptools_scm>=1.11.1'],\n     install_requires=[\n-        'pytest>=3.6',\n-        'pathlib2;python_version<\"3.4\"',\n+        'pytest>=5.4.0',\n     ],\n     extras_require={\n         'docs': [\n@@ -42,17 +40,10 @@ def read(fname):\n         'testing': [\n             'Django',\n             'django-configurations>=2.0',\n-            'six',\n         ],\n     },\n     classifiers=['Development Status :: 5 - Production/Stable',\n                  'Framework :: Django',\n-                 'Framework :: Django :: 1.8',\n-                 'Framework :: Django :: 1.9',\n-                 'Framework :: Django :: 1.10',\n-                 'Framework :: Django :: 1.11',\n-                 'Framework :: Django :: 2.0',\n-                 'Framework :: Django :: 2.1',\n                  'Framework :: Django :: 2.2',\n                  'Framework :: Django :: 3.0',\n                  'Framework :: Django :: 3.1',\n@@ -60,8 +51,6 @@ def read(fname):\n                  'License :: OSI Approved :: BSD License',\n                  'Operating System :: OS Independent',\n                  'Programming Language :: Python',\n-                 'Programming Language :: Python :: 2.7',\n-                 'Programming Language :: Python :: 3.4',\n                  'Programming Language :: Python :: 3.5',\n                  'Programming Language :: Python :: 3.6',\n                  'Programming Language :: Python :: 3.7',\n", "test_patch": "diff --git a/pytest_django_test/app/migrations/0001_initial.py b/pytest_django_test/app/migrations/0001_initial.py\n--- a/pytest_django_test/app/migrations/0001_initial.py\n+++ b/pytest_django_test/app/migrations/0001_initial.py\n@@ -1,6 +1,4 @@\n-# -*- coding: utf-8 -*-\n # Generated by Django 1.9a1 on 2016-06-22 04:33\n-from __future__ import unicode_literals\n \n from django.db import migrations, models\n \ndiff --git a/pytest_django_test/compat.py b/pytest_django_test/compat.py\ndeleted file mode 100644\n--- a/pytest_django_test/compat.py\n+++ /dev/null\n@@ -1,4 +0,0 @@\n-try:\n-    from urllib2 import urlopen, HTTPError\n-except ImportError:\n-    from urllib.request import urlopen, HTTPError  # noqa: F401\ndiff --git a/pytest_django_test/db_helpers.py b/pytest_django_test/db_helpers.py\n--- a/pytest_django_test/db_helpers.py\n+++ b/pytest_django_test/db_helpers.py\n@@ -31,7 +31,7 @@ def get_db_engine():\n     return _settings[\"ENGINE\"].split(\".\")[-1]\n \n \n-class CmdResult(object):\n+class CmdResult:\n     def __init__(self, status_code, std_out, std_err):\n         self.status_code = status_code\n         self.std_out = std_out\n@@ -64,7 +64,7 @@ def skip_if_sqlite_in_memory():\n def _get_db_name(db_suffix=None):\n     name = TEST_DB_NAME\n     if db_suffix:\n-        name = \"%s_%s\" % (name, db_suffix)\n+        name = \"{}_{}\".format(name, db_suffix)\n     return name\n \n \n@@ -72,7 +72,7 @@ def drop_database(db_suffix=None):\n     name = _get_db_name(db_suffix)\n     db_engine = get_db_engine()\n \n-    if db_engine == \"postgresql_psycopg2\":\n+    if db_engine == \"postgresql\":\n         r = run_cmd(\"psql\", \"postgres\", \"-c\", \"DROP DATABASE %s\" % name)\n         assert \"DROP DATABASE\" in force_str(\n             r.std_out\n@@ -94,7 +94,7 @@ def db_exists(db_suffix=None):\n     name = _get_db_name(db_suffix)\n     db_engine = get_db_engine()\n \n-    if db_engine == \"postgresql_psycopg2\":\n+    if db_engine == \"postgresql\":\n         r = run_cmd(\"psql\", name, \"-c\", \"SELECT 1\")\n         return r.status_code == 0\n \n@@ -111,7 +111,7 @@ def db_exists(db_suffix=None):\n def mark_database():\n     db_engine = get_db_engine()\n \n-    if db_engine == \"postgresql_psycopg2\":\n+    if db_engine == \"postgresql\":\n         r = run_cmd(\"psql\", TEST_DB_NAME, \"-c\", \"CREATE TABLE mark_table();\")\n         assert r.status_code == 0\n         return\n@@ -136,7 +136,7 @@ def mark_database():\n def mark_exists():\n     db_engine = get_db_engine()\n \n-    if db_engine == \"postgresql_psycopg2\":\n+    if db_engine == \"postgresql\":\n         r = run_cmd(\"psql\", TEST_DB_NAME, \"-c\", \"SELECT 1 FROM mark_table\")\n \n         # When something pops out on std_out, we are good\ndiff --git a/pytest_django_test/settings_base.py b/pytest_django_test/settings_base.py\n--- a/pytest_django_test/settings_base.py\n+++ b/pytest_django_test/settings_base.py\n@@ -1,5 +1,3 @@\n-import django\n-\n ROOT_URLCONF = \"pytest_django_test.urls\"\n INSTALLED_APPS = [\n     \"django.contrib.auth\",\n@@ -20,9 +18,6 @@\n     \"django.contrib.messages.middleware.MessageMiddleware\",\n ]\n \n-if django.VERSION < (1, 10):\n-    MIDDLEWARE_CLASSES = MIDDLEWARE\n-\n \n TEMPLATES = [\n     {\ndiff --git a/pytest_django_test/settings_postgres.py b/pytest_django_test/settings_postgres.py\n--- a/pytest_django_test/settings_postgres.py\n+++ b/pytest_django_test/settings_postgres.py\n@@ -2,7 +2,7 @@\n \n # PyPy compatibility\n try:\n-    from psycopg2ct import compat\n+    from psycopg2cffi import compat\n \n     compat.register()\n except ImportError:\n@@ -11,9 +11,7 @@\n \n DATABASES = {\n     \"default\": {\n-        \"ENGINE\": \"django.db.backends.postgresql_psycopg2\",\n+        \"ENGINE\": \"django.db.backends.postgresql\",\n         \"NAME\": \"pytest_django_should_never_get_accessed\",\n-        \"HOST\": \"localhost\",\n-        \"USER\": \"\",\n     }\n }\ndiff --git a/pytest_django_test/urls.py b/pytest_django_test/urls.py\n--- a/pytest_django_test/urls.py\n+++ b/pytest_django_test/urls.py\n@@ -1,8 +1,8 @@\n-from django.conf.urls import url\n+from django.urls import path\n \n from .app import views\n \n urlpatterns = [\n-    url(r\"^item_count/$\", views.item_count),\n-    url(r\"^admin-required/$\", views.admin_required_view),\n+    path(\"item_count/\", views.item_count),\n+    path(\"admin-required/\", views.admin_required_view),\n ]\ndiff --git a/pytest_django_test/urls_overridden.py b/pytest_django_test/urls_overridden.py\n--- a/pytest_django_test/urls_overridden.py\n+++ b/pytest_django_test/urls_overridden.py\n@@ -1,6 +1,6 @@\n-from django.conf.urls import url\n+from django.urls import path\n from django.http import HttpResponse\n \n urlpatterns = [\n-    url(r\"^overridden_url/$\", lambda r: HttpResponse(\"Overridden urlconf works!\"))\n+    path(\"overridden_url/\", lambda r: HttpResponse(\"Overridden urlconf works!\"))\n ]\ndiff --git a/tests/conftest.py b/tests/conftest.py\n--- a/tests/conftest.py\n+++ b/tests/conftest.py\n@@ -3,7 +3,6 @@\n from textwrap import dedent\n \n import pytest\n-import six\n from django.conf import settings\n \n try:\n@@ -58,7 +57,7 @@ def django_testdir(request, testdir, monkeypatch):\n \n         # Pypy compatibility\n         try:\n-            from psycopg2ct import compat\n+            from psycopg2cffi import compat\n         except ImportError:\n             pass\n         else:\n@@ -81,9 +80,6 @@ def django_testdir(request, testdir, monkeypatch):\n             'django.contrib.messages.middleware.MessageMiddleware',\n         ]\n \n-        if django.VERSION < (1, 10):\n-            MIDDLEWARE_CLASSES = MIDDLEWARE\n-\n         TEMPLATES = [\n             {\n                 'BACKEND': 'django.template.backends.django.DjangoTemplates',\n@@ -118,7 +114,7 @@ def django_testdir(request, testdir, monkeypatch):\n     test_app_path = tpkg_path.join(\"app\")\n \n     # Copy the test app to make it available in the new test run\n-    shutil.copytree(six.text_type(app_source), six.text_type(test_app_path))\n+    shutil.copytree(str(app_source), str(test_app_path))\n     tpkg_path.join(\"the_settings.py\").write(test_settings)\n \n     monkeypatch.setenv(\"DJANGO_SETTINGS_MODULE\", \"tpkg.the_settings\")\ndiff --git a/tests/test_database.py b/tests/test_database.py\n--- a/tests/test_database.py\n+++ b/tests/test_database.py\n@@ -1,5 +1,3 @@\n-from __future__ import with_statement\n-\n import pytest\n from django.db import connection\n from django.test.testcases import connections_support_transactions\ndiff --git a/tests/test_db_setup.py b/tests/test_db_setup.py\n--- a/tests/test_db_setup.py\n+++ b/tests/test_db_setup.py\n@@ -1,6 +1,5 @@\n import pytest\n \n-from pytest_django.lazy_django import get_django_version\n from pytest_django_test.db_helpers import (\n     db_exists,\n     drop_database,\n@@ -453,33 +452,7 @@ def test_a():\n         result.stdout.fnmatch_lines([\"*PASSED*test_a*\"])\n \n \n-@pytest.mark.skipif(\n-    get_django_version() >= (1, 9),\n-    reason=(\n-        \"Django 1.9 requires migration and has no concept of initial data fixtures\"\n-    ),\n-)\n-def test_initial_data(django_testdir_initial):\n-    \"\"\"Test that initial data gets loaded.\"\"\"\n-    django_testdir_initial.create_test_module(\n-        \"\"\"\n-        import pytest\n-\n-        from .app.models import Item\n-\n-        @pytest.mark.django_db\n-        def test_inner():\n-            assert [x.name for x in Item.objects.all()] \\\n-                == [\"mark_initial_data\"]\n-    \"\"\"\n-    )\n-\n-    result = django_testdir_initial.runpytest_subprocess(\"--tb=short\", \"-v\")\n-    assert result.ret == 0\n-    result.stdout.fnmatch_lines([\"*test_inner*PASSED*\"])\n-\n-\n-class TestNativeMigrations(object):\n+class TestNativeMigrations:\n     \"\"\" Tests for Django Migrations \"\"\"\n \n     def test_no_migrations(self, django_testdir):\ndiff --git a/tests/test_django_settings_module.py b/tests/test_django_settings_module.py\n--- a/tests/test_django_settings_module.py\n+++ b/tests/test_django_settings_module.py\n@@ -3,7 +3,6 @@\n If these tests fail you probably forgot to run \"python setup.py develop\".\n \"\"\"\n \n-import django\n import pytest\n \n \n@@ -308,10 +307,6 @@ def test_debug_is_false():\n     assert r.ret == 0\n \n \n-@pytest.mark.skipif(\n-    not hasattr(django, \"setup\"),\n-    reason=\"This Django version does not support app loading\",\n-)\n @pytest.mark.django_project(\n     extra_settings=\"\"\"\n     INSTALLED_APPS = [\n@@ -329,10 +324,7 @@ class TestApp(AppConfig):\n             name = 'tpkg.app'\n \n             def ready(self):\n-                try:\n-                    populating = apps.loading\n-                except AttributeError:  # Django < 2.0\n-                    populating = apps._lock.locked()\n+                populating = apps.loading\n                 print('READY(): populating=%r' % populating)\n         \"\"\",\n         \"apps.py\",\n@@ -342,10 +334,7 @@ def ready(self):\n         \"\"\"\n         from django.apps import apps\n \n-        try:\n-            populating = apps.loading\n-        except AttributeError:  # Django < 2.0\n-            populating = apps._lock.locked()\n+        populating = apps.loading\n \n         print('IMPORT: populating=%r,ready=%r' % (populating, apps.ready))\n         SOME_THING = 1234\n@@ -360,10 +349,7 @@ def ready(self):\n         from tpkg.app.models import SOME_THING\n \n         def test_anything():\n-            try:\n-                populating = apps.loading\n-            except AttributeError:  # Django < 2.0\n-                populating = apps._lock.locked()\n+            populating = apps.loading\n \n             print('TEST: populating=%r,ready=%r' % (populating, apps.ready))\n         \"\"\"\n@@ -372,10 +358,7 @@ def test_anything():\n     result = django_testdir.runpytest_subprocess(\"-s\", \"--tb=line\")\n     result.stdout.fnmatch_lines([\"*IMPORT: populating=True,ready=False*\"])\n     result.stdout.fnmatch_lines([\"*READY(): populating=True*\"])\n-    if django.VERSION < (2, 0):\n-        result.stdout.fnmatch_lines([\"*TEST: populating=False,ready=True*\"])\n-    else:\n-        result.stdout.fnmatch_lines([\"*TEST: populating=True,ready=True*\"])\n+    result.stdout.fnmatch_lines([\"*TEST: populating=True,ready=True*\"])\n     assert result.ret == 0\n \n \ndiff --git a/tests/test_environment.py b/tests/test_environment.py\n--- a/tests/test_environment.py\n+++ b/tests/test_environment.py\n@@ -1,5 +1,3 @@\n-from __future__ import with_statement\n-\n import os\n \n import pytest\n@@ -8,7 +6,6 @@\n from django.core import mail\n from django.db import connection\n from django.test import TestCase\n-from pytest_django.lazy_django import get_django_version\n \n from pytest_django_test.app.models import Item\n \n@@ -57,11 +54,11 @@ def test_two(self):\n def test_invalid_template_variable(django_testdir):\n     django_testdir.create_app_file(\n         \"\"\"\n-        from django.conf.urls import url\n+        from django.urls import path\n \n         from tpkg.app import views\n \n-        urlpatterns = [url(r'invalid_template/', views.invalid_template)]\n+        urlpatterns = [path('invalid_template/', views.invalid_template)]\n         \"\"\",\n         \"urls.py\",\n     )\n@@ -95,10 +92,7 @@ def test_ignore(client):\n     )\n     result = django_testdir.runpytest_subprocess(\"-s\", \"--fail-on-template-vars\")\n \n-    if get_django_version() >= (1, 9):\n-        origin = \"'*/tpkg/app/templates/invalid_template_base.html'\"\n-    else:\n-        origin = \"'invalid_template.html'\"\n+    origin = \"'*/tpkg/app/templates/invalid_template_base.html'\"\n     result.stdout.fnmatch_lines_random(\n         [\n             \"tpkg/test_the_test.py F.*\",\n@@ -163,11 +157,11 @@ def test_for_invalid_template():\n def test_invalid_template_variable_opt_in(django_testdir):\n     django_testdir.create_app_file(\n         \"\"\"\n-        from django.conf.urls import url\n+        from django.urls import path\n \n         from tpkg.app import views\n \n-        urlpatterns = [url(r'invalid_template/', views.invalid_template)]\n+        urlpatterns = [path('invalid_template', views.invalid_template)]\n         \"\"\",\n         \"urls.py\",\n     )\n@@ -255,14 +249,9 @@ def test_verbose_with_v(self, testdir):\n         \"\"\"Verbose output with '-v'.\"\"\"\n         result = testdir.runpytest_subprocess(\"-s\", \"-v\")\n         result.stdout.fnmatch_lines_random([\"tpkg/test_the_test.py:*\", \"*PASSED*\"])\n-        if get_django_version() >= (2, 2):\n-            result.stderr.fnmatch_lines(\n-                [\"*Destroying test database for alias 'default'*\"]\n-            )\n-        else:\n-            result.stdout.fnmatch_lines(\n-                [\"*Destroying test database for alias 'default'...*\"]\n-            )\n+        result.stderr.fnmatch_lines(\n+            [\"*Destroying test database for alias 'default'*\"]\n+        )\n \n     def test_more_verbose_with_vv(self, testdir):\n         \"\"\"More verbose output with '-v -v'.\"\"\"\n@@ -275,37 +264,22 @@ def test_more_verbose_with_vv(self, testdir):\n                 \"*PASSED*\",\n             ]\n         )\n-        if get_django_version() >= (2, 2):\n-            result.stderr.fnmatch_lines(\n-                [\n-                    \"*Creating test database for alias*\",\n-                    \"*Destroying test database for alias 'default'*\",\n-                ]\n-            )\n-        else:\n-            result.stdout.fnmatch_lines(\n-                [\n-                    \"*Creating test database for alias*\",\n-                    \"*Destroying test database for alias 'default'*\",\n-                ]\n-            )\n+        result.stderr.fnmatch_lines(\n+            [\n+                \"*Creating test database for alias*\",\n+                \"*Destroying test database for alias 'default'*\",\n+            ]\n+        )\n \n     def test_more_verbose_with_vv_and_reusedb(self, testdir):\n         \"\"\"More verbose output with '-v -v', and --create-db.\"\"\"\n         result = testdir.runpytest_subprocess(\"-s\", \"-v\", \"-v\", \"--create-db\")\n         result.stdout.fnmatch_lines([\"tpkg/test_the_test.py:*\", \"*PASSED*\"])\n-        if get_django_version() >= (2, 2):\n-            result.stderr.fnmatch_lines([\"*Creating test database for alias*\"])\n-            assert (\n-                \"*Destroying test database for alias 'default' ('*')...*\"\n-                not in result.stderr.str()\n-            )\n-        else:\n-            result.stdout.fnmatch_lines([\"*Creating test database for alias*\"])\n-            assert (\n-                \"*Destroying test database for alias 'default' ('*')...*\"\n-                not in result.stdout.str()\n-            )\n+        result.stderr.fnmatch_lines([\"*Creating test database for alias*\"])\n+        assert (\n+            \"*Destroying test database for alias 'default' ('*')...*\"\n+            not in result.stderr.str()\n+        )\n \n \n @pytest.mark.django_db\ndiff --git a/tests/test_fixtures.py b/tests/test_fixtures.py\n--- a/tests/test_fixtures.py\n+++ b/tests/test_fixtures.py\n@@ -4,10 +4,10 @@\n fixtures are tested in test_database.\n \"\"\"\n \n-from __future__ import with_statement\n \n import socket\n from contextlib import contextmanager\n+from urllib.request import urlopen, HTTPError\n \n import pytest\n from django.conf import settings as real_settings\n@@ -17,9 +17,7 @@\n from django.test.testcases import connections_support_transactions\n from django.utils.encoding import force_str\n \n-from pytest_django.lazy_django import get_django_version\n from pytest_django_test.app.models import Item\n-from pytest_django_test.compat import HTTPError, urlopen\n \n \n @contextmanager\n@@ -322,7 +320,7 @@ def test_settings_before(self):\n         from django.conf import settings\n \n         assert (\n-            \"%s.%s\" % (settings.__class__.__module__, settings.__class__.__name__)\n+            \"{}.{}\".format(settings.__class__.__module__, settings.__class__.__name__)\n             == \"django.conf.Settings\"\n         )\n         TestLiveServer._test_settings_before_run = True\n@@ -335,18 +333,14 @@ def test_change_settings(self, live_server, settings):\n \n     def test_settings_restored(self):\n         \"\"\"Ensure that settings are restored after test_settings_before.\"\"\"\n-        import django\n         from django.conf import settings\n \n         assert TestLiveServer._test_settings_before_run is True\n         assert (\n-            \"%s.%s\" % (settings.__class__.__module__, settings.__class__.__name__)\n+            \"{}.{}\".format(settings.__class__.__module__, settings.__class__.__name__)\n             == \"django.conf.Settings\"\n         )\n-        if django.VERSION >= (1, 11):\n-            assert settings.ALLOWED_HOSTS == [\"testserver\"]\n-        else:\n-            assert settings.ALLOWED_HOSTS == [\"*\"]\n+        assert settings.ALLOWED_HOSTS == [\"testserver\"]\n \n     def test_transactions(self, live_server):\n         if not connections_support_transactions():\n@@ -417,12 +411,9 @@ def test_serve_static_with_staticfiles_app(self, django_testdir, settings):\n         \"\"\"\n         django_testdir.create_test_module(\n             \"\"\"\n-            from django.utils.encoding import force_str\n+            from urllib.request import urlopen\n \n-            try:\n-                from urllib2 import urlopen\n-            except ImportError:\n-                from urllib.request import urlopen\n+            from django.utils.encoding import force_str\n \n             class TestLiveServer:\n                 def test_a(self, live_server, settings):\n@@ -445,28 +436,6 @@ def test_serve_static_dj17_without_staticfiles_app(self, live_server, settings):\n         with pytest.raises(HTTPError):\n             urlopen(live_server + \"/static/a_file.txt\").read()\n \n-    @pytest.mark.skipif(\n-        get_django_version() < (1, 11), reason=\"Django >= 1.11 required\"\n-    )\n-    def test_specified_port_range_error_message_django_111(self, django_testdir):\n-        django_testdir.create_test_module(\n-            \"\"\"\n-        def test_with_live_server(live_server):\n-            pass\n-        \"\"\"\n-        )\n-\n-        result = django_testdir.runpytest_subprocess(\"--liveserver=localhost:1234-2345\")\n-        result.stdout.fnmatch_lines(\n-            [\n-                \"*Specifying multiple live server ports is not supported in Django 1.11. This \"\n-                \"will be an error in a future pytest-django release.*\"\n-            ]\n-        )\n-\n-    @pytest.mark.skipif(\n-        get_django_version() < (1, 11, 2), reason=\"Django >= 1.11.2 required\"\n-    )\n     def test_specified_port_django_111(self, django_testdir):\n         sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n         try:\n@@ -516,16 +485,11 @@ class MyCustomUser(AbstractUser):\n     )\n     django_testdir.create_app_file(\n         \"\"\"\n-        from tpkg.app import views\n+        from django.urls import path\n \n-        try:\n-            from django.urls import path\n-        except ImportError:\n-            from django.conf.urls import url\n+        from tpkg.app import views\n \n-            urlpatterns = [url(r'admin-required/', views.admin_required_view)]\n-        else:\n-            urlpatterns = [path('admin-required/', views.admin_required_view)]\n+        urlpatterns = [path('admin-required/', views.admin_required_view)]\n         \"\"\",\n         \"urls.py\",\n     )\n@@ -556,9 +520,6 @@ def test_custom_user_model(admin_client):\n     django_testdir.create_app_file(\"\", \"migrations/__init__.py\")\n     django_testdir.create_app_file(\n         \"\"\"\n-# -*- coding: utf-8 -*-\n-from __future__ import unicode_literals\n-\n from django.db import models, migrations\n import django.utils.timezone\n import django.core.validators\ndiff --git a/tests/test_unittest.py b/tests/test_unittest.py\n--- a/tests/test_unittest.py\n+++ b/tests/test_unittest.py\n@@ -1,7 +1,6 @@\n import pytest\n from django.test import TestCase\n \n-from pytest_django.plugin import _pytest_version_info\n from pytest_django_test.app.models import Item\n \n \n@@ -161,16 +160,8 @@ def test_pass(self):\n         result = django_testdir.runpytest_subprocess(\"-v\", \"-s\")\n         expected_lines = [\n             \"* ERROR at setup of TestFoo.test_pass *\",\n+            \"E * TypeError: *\",\n         ]\n-        if _pytest_version_info < (4, 2):\n-            expected_lines += [\n-                \"E *Failed: <class 'tpkg.test_the_test.TestFoo'>.setUpClass should be a classmethod\",  # noqa:E501\n-            ]\n-        else:\n-            expected_lines += [\n-                \"E * TypeError: *\",\n-            ]\n-\n         result.stdout.fnmatch_lines(expected_lines)\n         assert result.ret == 1\n \n@@ -217,7 +208,7 @@ def test_setUpClass_mixin(self, django_testdir):\n             \"\"\"\n             from django.test import TestCase\n \n-            class TheMixin(object):\n+            class TheMixin:\n                 @classmethod\n                 def setUpClass(cls):\n                     super(TheMixin, cls).setUpClass()\n@@ -289,7 +280,7 @@ def test_multi_inheritance_setUpClass(self, django_testdir):\n             # Using a mixin is a regression test, see #280 for more details:\n             # https://github.com/pytest-dev/pytest-django/issues/280\n \n-            class SomeMixin(object):\n+            class SomeMixin:\n                 pass\n \n             class TestA(SomeMixin, TestCase):\ndiff --git a/tests/test_urls.py b/tests/test_urls.py\n--- a/tests/test_urls.py\n+++ b/tests/test_urls.py\n@@ -1,14 +1,11 @@\n import pytest\n from django.conf import settings\n+from django.urls import is_valid_path\n from django.utils.encoding import force_str\n \n \n @pytest.mark.urls(\"pytest_django_test.urls_overridden\")\n def test_urls():\n-    try:\n-        from django.urls import is_valid_path\n-    except ImportError:\n-        from django.core.urlresolvers import is_valid_path\n     assert settings.ROOT_URLCONF == \"pytest_django_test.urls_overridden\"\n     assert is_valid_path(\"/overridden_url/\")\n \n@@ -22,21 +19,18 @@ def test_urls_client(client):\n def test_urls_cache_is_cleared(testdir):\n     testdir.makepyfile(\n         myurls=\"\"\"\n-        from django.conf.urls import url\n+        from django.urls import path\n \n         def fake_view(request):\n             pass\n \n-        urlpatterns = [url(r'first/$', fake_view, name='first')]\n+        urlpatterns = [path('first', fake_view, name='first')]\n     \"\"\"\n     )\n \n     testdir.makepyfile(\n         \"\"\"\n-        try:\n-            from django.urls import reverse, NoReverseMatch\n-        except ImportError:  # Django < 2.0\n-            from django.core.urlresolvers import reverse, NoReverseMatch\n+        from django.urls import reverse, NoReverseMatch\n         import pytest\n \n         @pytest.mark.urls('myurls')\n@@ -58,32 +52,29 @@ def test_something_else():\n def test_urls_cache_is_cleared_and_new_urls_can_be_assigned(testdir):\n     testdir.makepyfile(\n         myurls=\"\"\"\n-        from django.conf.urls import url\n+        from django.urls import path\n \n         def fake_view(request):\n             pass\n \n-        urlpatterns = [url(r'first/$', fake_view, name='first')]\n+        urlpatterns = [path('first', fake_view, name='first')]\n     \"\"\"\n     )\n \n     testdir.makepyfile(\n         myurls2=\"\"\"\n-        from django.conf.urls import url\n+        from django.urls import path\n \n         def fake_view(request):\n             pass\n \n-        urlpatterns = [url(r'second/$', fake_view, name='second')]\n+        urlpatterns = [path('second', fake_view, name='second')]\n     \"\"\"\n     )\n \n     testdir.makepyfile(\n         \"\"\"\n-        try:\n-            from django.urls import reverse, NoReverseMatch\n-        except ImportError:  # Django < 2.0\n-            from django.core.urlresolvers import reverse, NoReverseMatch\n+        from django.urls import reverse, NoReverseMatch\n         import pytest\n \n         @pytest.mark.urls('myurls')\n", "problem_statement": "Import pathlib from pytest\nAs discussed on #636 when all supported versions of pytest offer an import of `pathlib`, use that rather than direct dependency on `pathlib2`\n", "hints_text": "", "created_at": 1600, "language": "python", "label": "Easy"}
{"repo": "pytest-dev/pytest-django", "pull_number": 664, "instance_id": "pytest-dev__pytest-django-664", "issue_numbers": ["662"], "base_commit": "5000ff814584e67eda6085f36a3644f6a834f6c2", "patch": "diff --git a/pytest_django/plugin.py b/pytest_django/plugin.py\n--- a/pytest_django/plugin.py\n+++ b/pytest_django/plugin.py\n@@ -120,7 +120,10 @@ def _handle_import_error(extra_message):\n \n def _add_django_project_to_path(args):\n     def is_django_project(path):\n-        return path.is_dir() and (path / 'manage.py').exists()\n+        try:\n+            return path.is_dir() and (path / 'manage.py').exists()\n+        except OSError:\n+            return False\n \n     def arg_to_path(arg):\n         # Test classes or functions can be appended to paths separated by ::\n@@ -130,7 +133,6 @@ def arg_to_path(arg):\n     def find_django_path(args):\n         args = map(str, args)\n         args = [arg_to_path(x) for x in args if not x.startswith(\"-\")]\n-        args = [p for p in args if p.is_dir()]\n \n         if not args:\n             args = [pathlib.Path.cwd()]\n", "test_patch": "diff --git a/tests/test_manage_py_scan.py b/tests/test_manage_py_scan.py\n--- a/tests/test_manage_py_scan.py\n+++ b/tests/test_manage_py_scan.py\n@@ -83,3 +83,15 @@ def test_django_project_found_invalid_settings_version(django_testdir, monkeypat\n     result = django_testdir.runpytest_subprocess('django_project_root', '--help')\n     assert result.ret == 0\n     result.stdout.fnmatch_lines(['*usage:*'])\n+\n+\n+@pytest.mark.django_project(project_root='django_project_root',\n+                            create_manage_py=True)\n+def test_runs_without_error_on_long_args(django_testdir):\n+    django_testdir.create_test_module(\"\"\"\n+    def test_this_is_a_long_message_which_caused_a_bug_when_scanning_for_manage_py_12346712341234123412341234123412341234123412341234123412341234123412341234123412341234123412341234123412341234123412341234123412341234123412341234123412341234112341234112451234123412341234123412341234123412341234123412341234123412341234123412341234123412341234():\n+        assert 1 + 1 == 2\n+    \"\"\")\n+\n+    result = django_testdir.runpytest_subprocess('-k', 'this_is_a_long_message_which_caused_a_bug_when_scanning_for_manage_py_12346712341234123412341234123412341234123412341234123412341234123412341234123412341234123412341234123412341234123412341234123412341234123412341234123412341234112341234112451234123412341234123412341234123412341234123412341234123412341234123412341234123412341234', 'django_project_root')\n+    assert result.ret == 0\n", "problem_statement": "OSError on long command-line args\nIn the logic of django_find_project there exist these lines:\r\n```\r\n    def find_django_path(args):\r\n        args = map(str, args)\r\n        args = [arg_to_path(x) for x in args if not x.startswith(\"-\")]\r\n        args = [p for p in args if p.is_dir()]\r\n...\r\n```\r\nUnfortunately, this means that if there are really long command-line args that this can get a `OSError: [Errno 36] File name too long: ...` which prevents me from, for example, using really long args to pytest's `-k` option.\r\nThanks for looking into this.\n", "hints_text": "Please consider creating a failing test and fix for this yourself.\r\nI assume the `args = [p for p in args if p.is_dir()]` should be turned into a loop that try/catches any OSError and ignores it.\n/cc @voidus for the pathlib change that appears to trigger this", "created_at": 1539, "language": "python", "label": "Easy"}
{"repo": "pytest-dev/pytest-django", "pull_number": 970, "instance_id": "pytest-dev__pytest-django-970", "issue_numbers": ["329", "956"], "base_commit": "904a99507bfd2d9570ce5d21deb006c4ae3f7ad3", "patch": "diff --git a/pytest_django/fixtures.py b/pytest_django/fixtures.py\n--- a/pytest_django/fixtures.py\n+++ b/pytest_django/fixtures.py\n@@ -20,7 +20,8 @@\n     import django\n \n     _DjangoDbDatabases = Optional[Union[\"Literal['__all__']\", Iterable[str]]]\n-    _DjangoDb = Tuple[bool, bool, _DjangoDbDatabases]\n+    # transaction, reset_sequences, databases, serialized_rollback\n+    _DjangoDb = Tuple[bool, bool, _DjangoDbDatabases, bool]\n \n \n __all__ = [\n@@ -28,6 +29,7 @@\n     \"db\",\n     \"transactional_db\",\n     \"django_db_reset_sequences\",\n+    \"django_db_serialized_rollback\",\n     \"admin_user\",\n     \"django_user_model\",\n     \"django_username_field\",\n@@ -151,9 +153,19 @@ def _django_db_helper(\n \n     marker = request.node.get_closest_marker(\"django_db\")\n     if marker:\n-        transactional, reset_sequences, databases = validate_django_db(marker)\n+        (\n+            transactional,\n+            reset_sequences,\n+            databases,\n+            serialized_rollback,\n+        ) = validate_django_db(marker)\n     else:\n-        transactional, reset_sequences, databases = False, False, None\n+        (\n+            transactional,\n+            reset_sequences,\n+            databases,\n+            serialized_rollback,\n+        ) = False, False, None, False\n \n     transactional = transactional or (\n         \"transactional_db\" in request.fixturenames\n@@ -162,6 +174,9 @@ def _django_db_helper(\n     reset_sequences = reset_sequences or (\n         \"django_db_reset_sequences\" in request.fixturenames\n     )\n+    serialized_rollback = serialized_rollback or (\n+        \"django_db_serialized_rollback\" in request.fixturenames\n+    )\n \n     django_db_blocker.unblock()\n     request.addfinalizer(django_db_blocker.restore)\n@@ -175,10 +190,12 @@ def _django_db_helper(\n         test_case_class = django.test.TestCase\n \n     _reset_sequences = reset_sequences\n+    _serialized_rollback = serialized_rollback\n     _databases = databases\n \n     class PytestDjangoTestCase(test_case_class):  # type: ignore[misc,valid-type]\n         reset_sequences = _reset_sequences\n+        serialized_rollback = _serialized_rollback\n         if _databases is not None:\n             databases = _databases\n \n@@ -196,18 +213,20 @@ def validate_django_db(marker) -> \"_DjangoDb\":\n     \"\"\"Validate the django_db marker.\n \n     It checks the signature and creates the ``transaction``,\n-    ``reset_sequences`` and ``databases`` attributes on the marker\n-    which will have the correct values.\n+    ``reset_sequences``, ``databases`` and ``serialized_rollback`` attributes on\n+    the marker which will have the correct values.\n \n-    A sequence reset is only allowed when combined with a transaction.\n+    Sequence reset and serialized_rollback are only allowed when combined with\n+    transaction.\n     \"\"\"\n \n     def apifun(\n         transaction: bool = False,\n         reset_sequences: bool = False,\n         databases: \"_DjangoDbDatabases\" = None,\n+        serialized_rollback: bool = False,\n     ) -> \"_DjangoDb\":\n-        return transaction, reset_sequences, databases\n+        return transaction, reset_sequences, databases, serialized_rollback\n \n     return apifun(*marker.args, **marker.kwargs)\n \n@@ -303,6 +322,27 @@ def django_db_reset_sequences(\n     # is requested.\n \n \n+@pytest.fixture(scope=\"function\")\n+def django_db_serialized_rollback(\n+    _django_db_helper: None,\n+    db: None,\n+) -> None:\n+    \"\"\"Require a test database with serialized rollbacks.\n+\n+    This requests the ``db`` fixture, and additionally performs rollback\n+    emulation - serializes the database contents during setup and restores\n+    it during teardown.\n+\n+    This fixture may be useful for transactional tests, so is usually combined\n+    with ``transactional_db``, but can also be useful on databases which do not\n+    support transactions.\n+\n+    Note that this will slow down that test suite by approximately 3x.\n+    \"\"\"\n+    # The `_django_db_helper` fixture checks if `django_db_serialized_rollback`\n+    # is requested.\n+\n+\n @pytest.fixture()\n def client() -> \"django.test.client.Client\":\n     \"\"\"A Django test client instance.\"\"\"\ndiff --git a/pytest_django/plugin.py b/pytest_django/plugin.py\n--- a/pytest_django/plugin.py\n+++ b/pytest_django/plugin.py\n@@ -33,6 +33,7 @@\n from .fixtures import django_db_modify_db_settings_tox_suffix  # noqa\n from .fixtures import django_db_modify_db_settings_xdist_suffix  # noqa\n from .fixtures import django_db_reset_sequences  # noqa\n+from .fixtures import django_db_serialized_rollback  # noqa\n from .fixtures import django_db_setup  # noqa\n from .fixtures import django_db_use_migrations  # noqa\n from .fixtures import django_user_model  # noqa\n@@ -265,14 +266,17 @@ def pytest_load_initial_conftests(\n     # Register the marks\n     early_config.addinivalue_line(\n         \"markers\",\n-        \"django_db(transaction=False, reset_sequences=False, databases=None): \"\n+        \"django_db(transaction=False, reset_sequences=False, databases=None, \"\n+        \"serialized_rollback=False): \"\n         \"Mark the test as using the Django test database.  \"\n         \"The *transaction* argument allows you to use real transactions \"\n         \"in the test like Django's TransactionTestCase.  \"\n         \"The *reset_sequences* argument resets database sequences before \"\n         \"the test.  \"\n         \"The *databases* argument sets which database aliases the test \"\n-        \"uses (by default, only 'default'). Use '__all__' for all databases.\",\n+        \"uses (by default, only 'default'). Use '__all__' for all databases.  \"\n+        \"The *serialized_rollback* argument enables rollback emulation for \"\n+        \"the test.\",\n     )\n     early_config.addinivalue_line(\n         \"markers\",\n@@ -387,7 +391,12 @@ def get_order_number(test: pytest.Item) -> int:\n         else:\n             marker_db = test.get_closest_marker('django_db')\n             if marker_db:\n-                transaction, reset_sequences, databases = validate_django_db(marker_db)\n+                (\n+                    transaction,\n+                    reset_sequences,\n+                    databases,\n+                    serialized_rollback,\n+                ) = validate_django_db(marker_db)\n                 uses_db = True\n                 transactional = transaction or reset_sequences\n             else:\n", "test_patch": "diff --git a/tests/test_database.py b/tests/test_database.py\n--- a/tests/test_database.py\n+++ b/tests/test_database.py\n@@ -48,7 +48,12 @@ def non_zero_sequences_counter(db: None) -> None:\n class TestDatabaseFixtures:\n     \"\"\"Tests for the different database fixtures.\"\"\"\n \n-    @pytest.fixture(params=[\"db\", \"transactional_db\", \"django_db_reset_sequences\"])\n+    @pytest.fixture(params=[\n+        \"db\",\n+        \"transactional_db\",\n+        \"django_db_reset_sequences\",\n+        \"django_db_serialized_rollback\",\n+    ])\n     def all_dbs(self, request) -> None:\n         if request.param == \"django_db_reset_sequences\":\n             return request.getfixturevalue(\"django_db_reset_sequences\")\n@@ -56,6 +61,10 @@ def all_dbs(self, request) -> None:\n             return request.getfixturevalue(\"transactional_db\")\n         elif request.param == \"db\":\n             return request.getfixturevalue(\"db\")\n+        elif request.param == \"django_db_serialized_rollback\":\n+            return request.getfixturevalue(\"django_db_serialized_rollback\")\n+        else:\n+            assert False  # pragma: no cover\n \n     def test_access(self, all_dbs: None) -> None:\n         Item.objects.create(name=\"spam\")\n@@ -113,6 +122,51 @@ def test_django_db_reset_sequences_requested(\n             [\"*test_django_db_reset_sequences_requested PASSED*\"]\n         )\n \n+    def test_serialized_rollback(self, db: None, django_testdir) -> None:\n+        django_testdir.create_app_file(\n+            \"\"\"\n+            from django.db import migrations\n+\n+            def load_data(apps, schema_editor):\n+                Item = apps.get_model(\"app\", \"Item\")\n+                Item.objects.create(name=\"loaded-in-migration\")\n+\n+            class Migration(migrations.Migration):\n+                dependencies = [\n+                    (\"app\", \"0001_initial\"),\n+                ]\n+\n+                operations = [\n+                    migrations.RunPython(load_data),\n+                ]\n+            \"\"\",\n+            \"migrations/0002_data_migration.py\",\n+        )\n+\n+        django_testdir.create_test_module(\n+            \"\"\"\n+            import pytest\n+            from .app.models import Item\n+\n+            @pytest.mark.django_db(transaction=True, serialized_rollback=True)\n+            def test_serialized_rollback_1():\n+                assert Item.objects.filter(name=\"loaded-in-migration\").exists()\n+\n+            @pytest.mark.django_db(transaction=True)\n+            def test_serialized_rollback_2(django_db_serialized_rollback):\n+                assert Item.objects.filter(name=\"loaded-in-migration\").exists()\n+                Item.objects.create(name=\"test2\")\n+\n+            @pytest.mark.django_db(transaction=True, serialized_rollback=True)\n+            def test_serialized_rollback_3():\n+                assert Item.objects.filter(name=\"loaded-in-migration\").exists()\n+                assert not Item.objects.filter(name=\"test2\").exists()\n+            \"\"\"\n+        )\n+\n+        result = django_testdir.runpytest_subprocess(\"-v\")\n+        assert result.ret == 0\n+\n     @pytest.fixture\n     def mydb(self, all_dbs: None) -> None:\n         # This fixture must be able to access the database\n@@ -160,6 +214,10 @@ def fixture_with_transdb(self, transactional_db: None) -> None:\n     def fixture_with_reset_sequences(self, django_db_reset_sequences: None) -> None:\n         Item.objects.create(name=\"spam\")\n \n+    @pytest.fixture\n+    def fixture_with_serialized_rollback(self, django_db_serialized_rollback: None) -> None:\n+        Item.objects.create(name=\"ham\")\n+\n     def test_trans(self, fixture_with_transdb: None) -> None:\n         pass\n \n@@ -180,6 +238,16 @@ def test_reset_sequences(\n     ) -> None:\n         pass\n \n+    # The test works when transactions are not supported, but it interacts\n+    # badly with other tests.\n+    @pytest.mark.skipif('not connection.features.supports_transactions')\n+    def test_serialized_rollback(\n+        self,\n+        fixture_with_serialized_rollback: None,\n+        fixture_with_db: None,\n+    ) -> None:\n+        pass\n+\n \n class TestDatabaseMarker:\n     \"Tests for the django_db marker.\"\n@@ -264,6 +332,19 @@ def test_all_databases(self, request) -> None:\n         SecondItem.objects.count()\n         SecondItem.objects.create(name=\"spam\")\n \n+    @pytest.mark.django_db\n+    def test_serialized_rollback_disabled(self, request):\n+        marker = request.node.get_closest_marker(\"django_db\")\n+        assert not marker.kwargs\n+\n+    # The test works when transactions are not supported, but it interacts\n+    # badly with other tests.\n+    @pytest.mark.skipif('not connection.features.supports_transactions')\n+    @pytest.mark.django_db(serialized_rollback=True)\n+    def test_serialized_rollback_enabled(self, request):\n+        marker = request.node.get_closest_marker(\"django_db\")\n+        assert marker.kwargs[\"serialized_rollback\"]\n+\n \n def test_unittest_interaction(django_testdir) -> None:\n     \"Test that (non-Django) unittests cannot access the DB.\"\ndiff --git a/tests/test_db_setup.py b/tests/test_db_setup.py\n--- a/tests/test_db_setup.py\n+++ b/tests/test_db_setup.py\n@@ -56,6 +56,10 @@ def test_run_second_reset_sequences_decorator():\n         def test_run_first_decorator():\n             pass\n \n+        @pytest.mark.django_db(serialized_rollback=True)\n+        def test_run_first_serialized_rollback_decorator():\n+            pass\n+\n         class MyTestCase(TestCase):\n             def test_run_last_test_case(self):\n                 pass\n@@ -77,6 +81,7 @@ def test_run_second_transaction_test_case(self):\n     result.stdout.fnmatch_lines([\n         \"*test_run_first_fixture*\",\n         \"*test_run_first_decorator*\",\n+        \"*test_run_first_serialized_rollback_decorator*\",\n         \"*test_run_first_django_test_case*\",\n         \"*test_run_second_decorator*\",\n         \"*test_run_second_fixture*\",\n", "problem_statement": "Tests using live_server fixture removing data from data migrations\nI've created a simple test case to reproduce this behavior https://github.com/ekiro/case_pytest/blob/master/app/tests.py which fails after second test using live_server fixture. \nMyModel objects are created in migration, using RunPython. It seems like after any test with live_server, every row from the database is truncated. Both, postgresql and sqlite3 was tested.\n\nEDIT:\nTests\n\n``` python\n\"\"\"\nMyModel objects are created in migration\nTest results:\n    app/tests.py::test_no_live_server PASSED\n    app/tests.py::test_live_server PASSED\n    app/tests.py::test_live_server2 FAILED\n    app/tests.py::test_no_live_server_after_live_server FAILED\n\"\"\"\n\nimport pytest\n\nfrom .models import MyModel\n\n\n@pytest.mark.django_db()\ndef test_no_live_server():\n    \"\"\"Passed\"\"\"\n    assert MyModel.objects.count() == 10\n\n\n@pytest.mark.django_db()\ndef test_live_server(live_server):\n    \"\"\"Passed\"\"\"\n    assert MyModel.objects.count() == 10\n\n\n@pytest.mark.django_db()\ndef test_live_server2(live_server):\n    \"\"\"Failed, because count() returns 0\"\"\"\n    assert MyModel.objects.count() == 10\n\n\n@pytest.mark.django_db()\ndef test_no_live_server_after_live_server():\n    \"\"\"Failed, because count() returns 0\"\"\"\n    assert MyModel.objects.count() == 10\n```\n\nFeature/serialized rollback\n\n", "hints_text": "That's because of the `transactional_db` fixture being used automatically by `live_server` (there is no need to mark it with `@pytest.mark.django_db`).  There are several issues / discussions in this regard, but the last time I looked closer at this, there was no easy solution to this problem that comes with using data migrations.\nA workaround is to use pytest fixtures to wrap your data migrations / data fixtures.\n(btw: better put the tests inline in the issue rather than into an external resource that might change over time.)\n\nI just hit this as well and it took me a long time to track it down, even though I'm reasonably familiar with Django's test framework and migrations.\n\nThis is actually a surprising performance tradeoff of Django's `TestCase`. It's documented here:\nhttps://docs.djangoproject.com/en/1.9/topics/testing/overview/#rollback-emulation\n\nIn a regular Django test suite, the workaround consists in setting a `serialized_rollback = True` class attribute on the test case.\n\nI don't know how to achieve the same effect with pytest-django's [dynamically generated test classes](https://github.com/pytest-dev/pytest-django/blob/3529fea78e9931434e1812268fe022e3fb30a9f2/pytest_django/fixtures.py#L107).\n\nThe following change \"solves\" the issue at the expense of unconditionally selecting the least efficient behavior.\n\n``` diff\n--- pytest_django/fixtures.py.orig  2016-04-27 17:12:25.000000000 +0200\n+++ pytest_django/fixtures.py   2016-04-27 17:21:50.000000000 +0200\n@@ -103,6 +103,7 @@\n\n     if django_case:\n         case = django_case(methodName='__init__')\n+        case.serialized_rollback = True\n         case._pre_setup()\n         request.addfinalizer(case._post_teardown)\n\n```\n\nThe following technique works, but I can't recommend it for rather obvious reasons...\n\n``` python\nimport pytest\nfrom django.core.management import call_command\nfrom pytest_django.fixtures import transactional_db as _transactional_db\n\n\ndef _reload_fixture_data():\n    fixture_names = [\n        # Create fixtures for the data created by data migrations\n        # and list them here.\n    ]\n    call_command('loaddata', *fixture_names)\n\n\n@pytest.fixture(scope='function')\ndef transactional_db(request, _django_db_setup, _django_cursor_wrapper):\n    \"\"\"\n    Override a pytest-django fixture to restore the contents of the database.\n\n    This works around https://github.com/pytest-dev/pytest-django/issues/329 by\n    restoring data created by data migrations. We know what data matters and we\n    maintain it in (Django) fixtures. We don't read it from the database. This\n    causes some repetition but keeps this (pytest) fixture (almost) simple.\n\n    \"\"\"\n    try:\n        return _transactional_db(request, _django_db_setup, _django_cursor_wrapper)\n    finally:\n        # /!\\ Epically shameful hack /!\\ _transactional_db adds two finalizers:\n        # _django_cursor_wrapper.disable() and case._post_teardown(). Note that\n        # finalizers run in the opposite order of that in which they are added.\n        # We want to run after case._post_teardown() which flushes the database\n        # but before _django_cursor_wrapper.disable() which prevents further\n        # database queries. Hence, open heart surgery in pytest internals...\n        finalizers = request._fixturedef._finalizer\n        assert len(finalizers) == 2\n        assert finalizers[0].__qualname__ == 'CursorManager.disable'\n        assert finalizers[1].__qualname__ == 'TransactionTestCase._post_teardown'\n        finalizers.insert(1, _reload_fixture_data)\n```\n\nWould an option to conditionally enable `serialized_rollback` be a good solution?\n\nI.e. something like\n\n``` python\n@pytest.mark.django_db(transaction=True, serialized_rollback=True)\ndef test_foo():\n    ...\n```\n\nI think that would be good.\n\nIn my use case:\n- the `transactional_db` fixture is triggered by `live_server`, but I wouldn't mind adding a `django_db` fixture to specify serialized rollback\n- unrelated to pytest-django -- `case.serialized_rollback = True` still fails because Django attemps to deserialized objects in an order that doesn't respect FK constraints, I think that's a bug in Django\n\nOk, perfect :)\n\nI don't have time to work on a fix right now, but adding such an option to the `django_db` marker should and setting `case.serialized_rollback = True` (like you did above) should be relatively straightforward.\n\nTicket for the Django bug I mentioned above: https://code.djangoproject.com/ticket/26552\n\n@pelme -- does this pull request implement the \"relatively straightforward\" approach you're envisionning?\n\nThanks a lot for the PR. The implementation looks correct and what I imagined. I did not think of having a serialized_rollback fixture but it is indeed useful to be able to force this behaviour from other fixtures.\n\nWe would need a test for this too, but the implementation looks correct!\n\nI'll try to find time to polish the patch (I haven't even run it yet). I need to get the aformentionned bug in Django fixed as well before I can use this.\n\nUpdated version of the hack above for pytest-django â‰¥ 3.0:\n\n``` python\n@pytest.fixture(scope='function')\ndef transactional_db(request, django_db_setup, django_db_blocker):\n    \"\"\"\n    Override a pytest-django fixture to restore the contents of the database.\n\n    This works around https://github.com/pytest-dev/pytest-django/issues/329 by\n    restoring data created by data migrations. We know what data matters and we\n    maintain it in (Django) fixtures. We don't read it from the database. This\n    causes some repetition but keeps this (pytest) fixture (almost) simple.\n\n    \"\"\"\n    try:\n        return _transactional_db(request, django_db_setup, django_db_blocker)\n    finally:\n        # /!\\ Epically shameful hack /!\\ _transactional_db adds two finalizers:\n        # django_db_blocker.restore() and test_case._post_teardown(). Note that\n        # finalizers run in the opposite order of that in which they are added.\n        # We want to run after test_case._post_teardown() flushes the database\n        # but before django_db_blocker.restore() prevents further database\n        # queries. Hence, open heart surgery in pytest internals...\n        finalizers = request._fixturedef._finalizer\n        assert len(finalizers) == 2\n        assert finalizers[0].__qualname__ == '_DatabaseBlocker.restore'\n        assert finalizers[1].__qualname__ == 'TransactionTestCase._post_teardown'\n        finalizers.insert(1, _reload_fixture_data)\n```\n\nThanks for the update and sorry I couldn't get this into 3.0. I will try to get to this for the next release!\n\nIs there any chance to see it in next release?\r\n\r\nThanks\n@Wierrat \r\nYes, probably.\r\n\r\nCan help us with a test for https://github.com/pytest-dev/pytest-django/pull/353 before that then please?\nHi folks,\r\nwhat is the latest status of this? In particular I'm using pytest as my test runner with the StaticLiveServerTestCase class from Django. I've set the class attribute `serialized_rollback = True` but that seems to be in effect only when executing the first test from the sequence. \r\n\r\n\nJust got caught by this one. Looking around it seems there have been some PR on this issue but none of them appear to have been merged.\r\nIs there any particular reason this issue remain open?\n> some PR\r\n\r\nLikely/only https://github.com/pytest-dev/pytest-django/issues/329, no?\r\n\r\nThe last time I've asked about help with a test, and it has several conflicts (maybe only due to black).\r\n\r\nI still suggest for anyone affected to help with that - I am not using it myself.\r\n\nThanks for the quick reply @blueyed.\r\nMy knowledge of pytest / pytest-django is minimal but I'll put that on my somday/maybe list! :D\nUpdated version of the above hack for pytest 5.2.1, pytest-django 3.5.1:\r\n\r\n```python\r\nfrom functools import partial\r\n\r\n@pytest.fixture\r\ndef transactional_db(request, transactional_db, django_db_blocker):\r\n    # Restore DB content after all of transactional_db's finalizers have\r\n    # run. Finalizers are run in the opposite order of that in which they\r\n    # are added, so we prepend the restore to the front of the list.\r\n    #\r\n    # Works for pytest 5.2.1, pytest-django 3.5.1\r\n    restore = partial(_restore_db_content, django_db_blocker)\r\n    finalizers = request._fixture_defs['transactional_db']._finalizers\r\n    finalizers.insert(0, restore)\r\n\r\n    # Simply restoring after yielding transactional_db wouldn't work because\r\n    # it would run before transactional_db's finalizers which contains the truncate.\r\n    return transactional_db\r\n\r\ndef _restore_db_content(django_db_fixture, django_db_blocker):\r\n    with django_db_blocker.unblock():\r\n        call_command('loaddata', '--verbosity', '0', 'TODO your fixture')\r\n```\r\n\r\nI had to depend on the original `transactional_db` fixture instead of calling it as pytest no longer allows calling fixture functions directly. I then get the fixture def of the original fixture and prepend a finalizer to it. While inserting at index 1 still worked, I insert before all finalizers and use `django_db_blocker` in the restore function as that seems slightly less fragile.\r\n\r\nEdit: removed unnecessary try finally.\n@lukaszb \r\n\r\nhttps://github.com/pytest-dev/pytest-django/issues/848\r\n\r\nI use this version of pytest-django (https://github.com/pytest-dev/pytest-django/pull/721/files), \r\nBut still error.\r\n\r\n![image](https://user-images.githubusercontent.com/30521429/84665887-f45aec80-af52-11ea-9c8f-68ffc9230f5a.png)\r\n\r\n\nWhile sorting my archives, I stumbled upon this attempt, which is probably not very useful but who knows. So here it is.\r\n\r\n<details>\r\n\r\n```diff\r\ncommit c1a6a3fe939d9516ec7cabe1dfd6903c512db22a\r\nAuthor: Aymeric Augustin <aymeric.augustin@m4x.org>\r\nDate:   Thu Apr 28 11:51:06 2016 +0200\r\n\r\n    Add support for serialized rollback. Fix #329.\r\n    \r\n    WORK IN PROGRESS - UNTESTED\r\n\r\ndiff --git a/docs/changelog.rst b/docs/changelog.rst\r\nindex 9b4c510..c50981c 100644\r\n--- a/docs/changelog.rst\r\n+++ b/docs/changelog.rst\r\n@@ -3,6 +3,15 @@ Changelog\r\n \r\n NEXT\r\n ----\r\n+\r\n+Features\r\n+^^^^^^^^\r\n+* Add support for serialized rollback in transactional tests.\r\n+  Thanks to Piotr Karkut for `the bug report\r\n+  <https://github.com/pytest-dev/pytest-django/issues/329>`_.\r\n+\r\n+Bug fixes\r\n+^^^^^^^^^\r\n * Fix error when Django happens to be imported before pytest-django runs.\r\n   Thanks to Will Harris for `the bug report\r\n   <https://github.com/pytest-dev/pytest-django/issues/289>`_.\r\ndiff --git a/docs/helpers.rst b/docs/helpers.rst\r\nindex 7c60f90..1860ee1 100644\r\n--- a/docs/helpers.rst\r\n+++ b/docs/helpers.rst\r\n@@ -16,7 +16,7 @@ on what marks are and for notes on using_ them.\r\n ``pytest.mark.django_db`` - request database access\r\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n \r\n-.. py:function:: pytest.mark.django_db([transaction=False])\r\n+.. py:function:: pytest.mark.django_db([transaction=False, serialized_rollback=False])\r\n \r\n    This is used to mark a test function as requiring the database. It\r\n    will ensure the database is setup correctly for the test. Each test\r\n@@ -38,6 +38,14 @@ on what marks are and for notes on using_ them.\r\n      uses. When ``transaction=True``, the behavior will be the same as\r\n      `django.test.TransactionTestCase`_\r\n \r\n+   :type serialized_rollback: bool\r\n+   :param serialized_rollback:\r\n+     The ``serialized_rollback`` argument enables `rollback emulation`_.\r\n+     After a `django.test.TransactionTestCase`_ runs, the database is\r\n+     flushed, destroying data created in data migrations. This is the\r\n+     default behavior of Django. Setting ``serialized_rollback=True``\r\n+     tells Django to restore that data.\r\n+\r\n    .. note::\r\n \r\n       If you want access to the Django database *inside a fixture*\r\n@@ -54,6 +62,7 @@ on what marks are and for notes on using_ them.\r\n      Test classes that subclass Python's ``unittest.TestCase`` need to have the\r\n      marker applied in order to access the database.\r\n \r\n+.. _rollback emulation: https://docs.djangoproject.com/en/stable/topics/testing/overview/#rollback-emulation\r\n .. _django.test.TestCase: https://docs.djangoproject.com/en/dev/topics/testing/overview/#testcase\r\n .. _django.test.TransactionTestCase: https://docs.djangoproject.com/en/dev/topics/testing/overview/#transactiontestcase\r\n \r\n@@ -191,6 +200,16 @@ transaction support.  This is only required for fixtures which need\r\n database access themselves.  A test function would normally use the\r\n :py:func:`~pytest.mark.django_db` mark to signal it needs the database.\r\n \r\n+``serialized_rollback``\r\n+~~~~~~~~~~~~~~~~~~~~~~~\r\n+\r\n+When the ``transactional_db`` fixture is enabled, this fixture can be\r\n+added to trigger `rollback emulation`_ and thus restores data created\r\n+in data migrations after each transaction test.  This is only required\r\n+for fixtures which need to enforce this behavior.  A test function\r\n+would use :py:func:`~pytest.mark.django_db(serialized_rollback=True)`\r\n+to request this behavior.\r\n+\r\n ``live_server``\r\n ~~~~~~~~~~~~~~~\r\n \r\n@@ -200,6 +219,12 @@ or by requesting it's string value: ``unicode(live_server)``.  You can\r\n also directly concatenate a string to form a URL: ``live_server +\r\n '/foo``.\r\n \r\n+Since the live server and the tests run in different threads, they\r\n+cannot share a database transaction. For this reason, ``live_server``\r\n+depends on the ``transactional_db`` fixture. If tests depend on data\r\n+created in data migrations, you should add the ``serialized_rollback``\r\n+fixture.\r\n+\r\n ``settings``\r\n ~~~~~~~~~~~~\r\n \r\ndiff --git a/pytest_django/fixtures.py b/pytest_django/fixtures.py\r\nindex cae7d47..ca2fc72 100644\r\n--- a/pytest_django/fixtures.py\r\n+++ b/pytest_django/fixtures.py\r\n@@ -64,7 +64,8 @@ def _django_db_setup(request,\r\n         request.addfinalizer(teardown_database)\r\n \r\n \r\n-def _django_db_fixture_helper(transactional, request, _django_cursor_wrapper):\r\n+def _django_db_fixture_helper(transactional, serialized_rollback,\r\n+                              request, _django_cursor_wrapper):\r\n     if is_django_unittest(request):\r\n         return\r\n \r\n@@ -105,6 +106,7 @@ def _django_db_fixture_helper(transactional, request, _django_cursor_wrapper):\r\n \r\n     if django_case:\r\n         case = django_case(methodName='__init__')\r\n+        case.serialized_rollback = serialized_rollback\r\n         case._pre_setup()\r\n         request.addfinalizer(case._post_teardown)\r\n \r\n@@ -177,7 +179,9 @@ def db(request, _django_db_setup, _django_cursor_wrapper):\r\n     if 'transactional_db' in request.funcargnames \\\r\n             or 'live_server' in request.funcargnames:\r\n         return request.getfuncargvalue('transactional_db')\r\n-    return _django_db_fixture_helper(False, request, _django_cursor_wrapper)\r\n+    return _django_db_fixture_helper(\r\n+        transaction=False, serialized_rollback=False,\r\n+        request=request, _django_cursor_wrapper=_django_cursor_wrapper)\r\n \r\n \r\n @pytest.fixture(scope='function')\r\n@@ -192,7 +196,22 @@ def transactional_db(request, _django_db_setup, _django_cursor_wrapper):\r\n     database setup will behave as only ``transactional_db`` was\r\n     requested.\r\n     \"\"\"\r\n-    return _django_db_fixture_helper(True, request, _django_cursor_wrapper)\r\n+    # TODO -- is request.getfuncargvalue('serialized_rollback') enough\r\n+    #         to add 'serialized_rollback' to request.funcargnames?\r\n+    serialized_rollback = 'serialized_rollback' in request.funcargnames\r\n+    return _django_db_fixture_helper(\r\n+        transaction=True, serialized_rollback=serialized_rollback,\r\n+        request=request, _django_cursor_wrapper=_django_cursor_wrapper)\r\n+\r\n+\r\n+@pytest.fixture(scope='function')\r\n+def serialized_rollback(request):\r\n+    \"\"\"Enable serialized rollback after transaction test cases\r\n+\r\n+    This fixture only has an effect when the ``transactional_db``\r\n+    fixture is active, which happen as a side-effect of requesting\r\n+    ``live_server``.\r\n+    \"\"\"\r\n \r\n \r\n @pytest.fixture()\r\ndiff --git a/pytest_django/plugin.py b/pytest_django/plugin.py\r\nindex d499e6f..204f16f 100644\r\n--- a/pytest_django/plugin.py\r\n+++ b/pytest_django/plugin.py\r\n@@ -372,6 +372,8 @@ def _django_db_marker(request):\r\n             request.getfuncargvalue('transactional_db')\r\n         else:\r\n             request.getfuncargvalue('db')\r\n+        if marker.serialized_rollback:\r\n+            request.getfuncargvalue('serialized_rollback')\r\n \r\n \r\n @pytest.fixture(autouse=True, scope='class')\r\n@@ -564,8 +566,9 @@ def validate_django_db(marker):\r\n     It checks the signature and creates the `transaction` attribute on\r\n     the marker which will have the correct value.\r\n     \"\"\"\r\n-    def apifun(transaction=False):\r\n+    def apifun(transaction=False, serialized_rollback=False):\r\n         marker.transaction = transaction\r\n+        marker.serialized_rollback = serialized_rollback\r\n     apifun(*marker.args, **marker.kwargs)\r\n \r\n \r\n```\r\n\r\n</details>\nHow does this relate to #919? Also, you have some unhandled conflict indicators in the code itself.", "created_at": 1638, "language": "python", "label": "Easy"}
{"repo": "rigetti/pyquil", "pull_number": 191, "instance_id": "rigetti__pyquil-191", "issue_numbers": ["184"], "base_commit": "4fbcbd16a4963818daa73d700f7c26406ae19ec7", "patch": "diff --git a/pyquil/quilbase.py b/pyquil/quilbase.py\n--- a/pyquil/quilbase.py\n+++ b/pyquil/quilbase.py\n@@ -20,6 +20,7 @@\n import numpy as np\n from .slot import Slot\n from six import integer_types, string_types\n+from fractions import Fraction\n \n \n class QuilAtom(object):\n@@ -513,8 +514,10 @@ def format_parameter(element):\n \n     :param element: {int, float, long, complex, Slot} Formats a parameter for Quil output.\n     \"\"\"\n-    if isinstance(element, integer_types) or isinstance(element, float):\n+    if isinstance(element, integer_types):\n         return repr(element)\n+    elif isinstance(element, float):\n+        return check_for_pi(element)\n     elif isinstance(element, complex):\n         r = element.real\n         i = element.imag\n@@ -527,6 +530,33 @@ def format_parameter(element):\n     assert False, \"Invalid parameter: %r\" % element\n \n \n+def check_for_pi(element):\n+    \"\"\"\n+    Check to see if there exists a rational number r = p/q\n+    in reduced form for which the difference between element/np.pi\n+    and r is small and q <= 8.\n+\n+    :param element: float\n+    :return element: pretty print string if true, else standard representation.\n+    \"\"\"\n+    frac = Fraction(element / np.pi).limit_denominator(8)\n+    num, den = frac.numerator, frac.denominator\n+    sign = \"-\" if num < 0 else \"\"\n+    if np.isclose(num / float(den), element / np.pi):\n+        if num == 0:\n+            return \"0\"\n+        elif abs(num) == 1 and den == 1:\n+            return sign + \"pi\"\n+        elif abs(num) == 1:\n+            return sign + \"pi/\" + repr(den)\n+        elif den == 1:\n+            return repr(num) + \"*pi\"\n+        else:\n+            return repr(num) + \"*pi/\" + repr(den)\n+    else:\n+        return repr(element)\n+\n+\n def unpack_qubit(qubit):\n     \"\"\"\n     Get a qubit from an object.\n", "test_patch": "diff --git a/pyquil/tests/test_quil.py b/pyquil/tests/test_quil.py\n--- a/pyquil/tests/test_quil.py\n+++ b/pyquil/tests/test_quil.py\n@@ -40,7 +40,7 @@ def test_gate():\n def test_defgate():\n     dg = DefGate(\"TEST\", np.array([[1., 0.],\n                                    [0., 1.]]))\n-    assert dg.out() == \"DEFGATE TEST:\\n    1.0, 0.0\\n    0.0, 1.0\\n\"\n+    assert dg.out() == \"DEFGATE TEST:\\n    1.0, 0\\n    0, 1.0\\n\"\n     test = dg.get_constructor()\n     tg = test(Qubit(1), Qubit(2))\n     assert tg.out() == \"TEST 1 2\"\n@@ -64,7 +64,7 @@ def test_defgate_non_unitary_should_throw_error():\n \n def test_defgate_param():\n     dgp = DefGate(\"TEST\", [[1., 0.], [0., 1.]])\n-    assert dgp.out() == \"DEFGATE TEST:\\n    1.0, 0.0\\n    0.0, 1.0\\n\"\n+    assert dgp.out() == \"DEFGATE TEST:\\n    1.0, 0\\n    0, 1.0\\n\"\n     test = dgp.get_constructor()\n     tg = test(Qubit(1))\n     assert tg.out() == \"TEST 1\"\n@@ -236,21 +236,21 @@ def test_dagger():\n                        RZ(pi, 0), CPHASE(pi, 0, 1),\n                        CPHASE00(pi, 0, 1), CPHASE01(pi, 0, 1),\n                        CPHASE10(pi, 0, 1), PSWAP(pi, 0, 1))\n-    assert p.dagger().out() == 'PSWAP(-3.141592653589793) 0 1\\n' \\\n-                               'CPHASE10(-3.141592653589793) 0 1\\n' \\\n-                               'CPHASE01(-3.141592653589793) 0 1\\n' \\\n-                               'CPHASE00(-3.141592653589793) 0 1\\n' \\\n-                               'CPHASE(-3.141592653589793) 0 1\\n' \\\n-                               'RZ(-3.141592653589793) 0\\n' \\\n-                               'RY(-3.141592653589793) 0\\n' \\\n-                               'RX(-3.141592653589793) 0\\n' \\\n-                               'PHASE(-3.141592653589793) 0\\n'\n+    assert p.dagger().out() == 'PSWAP(-pi) 0 1\\n' \\\n+                               'CPHASE10(-pi) 0 1\\n' \\\n+                               'CPHASE01(-pi) 0 1\\n' \\\n+                               'CPHASE00(-pi) 0 1\\n' \\\n+                               'CPHASE(-pi) 0 1\\n' \\\n+                               'RZ(-pi) 0\\n' \\\n+                               'RY(-pi) 0\\n' \\\n+                               'RX(-pi) 0\\n' \\\n+                               'PHASE(-pi) 0\\n'\n \n     # these gates are special cases\n     p = Program().inst(S(0), T(0), ISWAP(0, 1))\n-    assert p.dagger().out() == 'PSWAP(1.5707963267948966) 0 1\\n' \\\n-                               'RZ(0.7853981633974483) 0\\n' \\\n-                               'PHASE(-1.5707963267948966) 0\\n'\n+    assert p.dagger().out() == 'PSWAP(pi/2) 0 1\\n' \\\n+                               'RZ(pi/4) 0\\n' \\\n+                               'PHASE(-pi/2) 0\\n'\n \n     # must invert defined gates\n     G = np.array([[0, 1], [0 + 1j, 0]])\n@@ -294,14 +294,14 @@ def test_phases():\n     p = Program(PHASE(np.pi)(1), CPHASE00(np.pi)(0, 1), CPHASE01(np.pi)(0, 1),\n                 CPHASE10(np.pi)(0, 1),\n                 CPHASE(np.pi)(0, 1))\n-    assert p.out() == 'PHASE(3.141592653589793) 1\\nCPHASE00(3.141592653589793) 0 1\\n' \\\n-                      'CPHASE01(3.141592653589793) 0 1\\nCPHASE10(3.141592653589793) 0 1\\n' \\\n-                      'CPHASE(3.141592653589793) 0 1\\n'\n+    assert p.out() == 'PHASE(pi) 1\\nCPHASE00(pi) 0 1\\n' \\\n+                      'CPHASE01(pi) 0 1\\nCPHASE10(pi) 0 1\\n' \\\n+                      'CPHASE(pi) 0 1\\n'\n \n \n def test_swaps():\n     p = Program(SWAP(0, 1), CSWAP(0, 1, 2), ISWAP(0, 1), PSWAP(np.pi)(0, 1))\n-    assert p.out() == 'SWAP 0 1\\nCSWAP 0 1 2\\nISWAP 0 1\\nPSWAP(3.141592653589793) 0 1\\n'\n+    assert p.out() == 'SWAP 0 1\\nCSWAP 0 1 2\\nISWAP 0 1\\nPSWAP(pi) 0 1\\n'\n \n \n def test_def_gate():\n@@ -350,8 +350,8 @@ def qft3(q0, q1, q2):\n \n     prog = state_prep + qft3(0, 1, 2)\n     output = prog.out()\n-    assert output == 'X 0\\nH 2\\nCPHASE(1.5707963267948966) 1 2\\nH 1\\nCPHASE(0.7853981633974483) 0 ' \\\n-                     '2\\nCPHASE(1.5707963267948966) 0 1\\nH 0\\nSWAP 0 2\\n'\n+    assert output == 'X 0\\nH 2\\nCPHASE(pi/2) 1 2\\nH 1\\nCPHASE(pi/4) 0 ' \\\n+                     '2\\nCPHASE(pi/2) 0 1\\nH 0\\nSWAP 0 2\\n'\n \n \n def test_control_flows():\n@@ -574,3 +574,14 @@ def test_inline_alloc():\n     p = Program()\n     p += H(p.alloc())\n     assert p.out() == \"H 0\\n\"\n+\n+\n+# https://github.com/rigetticomputing/pyquil/issues/184\n+def test_pretty_print_pi():\n+    p = Program()\n+    p += [RZ(0., 0), RZ(pi, 1), RZ(-pi, 2)]\n+    p += [RZ(2 * pi / 3., 3), RZ(pi / 9., 4), RZ(pi / 8., 5)]\n+    p += CPHASE00(-90 * pi / 2., 0, 1)\n+    assert p.out() == 'RZ(0) 0\\nRZ(pi) 1\\nRZ(-pi) 2\\nRZ(2*pi/3) 3\\n' \\\n+                      'RZ(0.3490658503988659) 4\\n' \\\n+                      'RZ(pi/8) 5\\nCPHASE00(-45*pi) 0 1\\n'\n", "problem_statement": "Parameters to gates that are nearly pi, pi/2, pi/4 etc should be printed using pi\nInstead of this:\r\n`RZ(-3.141592653589793) 0`\r\nlet's print this:\r\n`RZ(-pi) 0` which is valid quil.\r\n\r\nThis will aid in program understanding.\n", "hints_text": "Hint to implementers: look at the format_parameter function in quilbase\nHello,\r\n\r\nI implemented this last night using np.float32 and fractions.Fraction.  I wanted to verify the expected behavior before making a pull request.  Here are some printed results, which after obvious adjustments to the test cases pass tests for python2 and python3.  \r\n```\r\ninput\r\n=========\r\n\r\nfor i in range(12):\r\n    p = Program()\r\n    p += RZ(i*pi/91.,0)\r\n    print(p)\r\n\r\noutput\r\n=========\r\nRZ(0) 0\r\nRZ(pi/91) 0\r\nRZ(2*pi/91) 0\r\nRZ(3*pi/91) 0\r\nRZ(4*pi/91) 0\r\nRZ(5*pi/91) 0\r\nRZ(6*pi/91) 0\r\nRZ(pi/13) 0\r\nRZ(8*pi/91) 0\r\nRZ(9*pi/91) 0\r\nRZ(10*pi/91) 0\r\nRZ(11*pi/91) 0\r\n```\r\nThe main idea is to use fractions.Fraction to see if np.float32(element/np.pi) == np.float32(p/q) for some fraction p/q with q <= 140 (arbitrary cutoff).  One important edge case to think about is \r\n```\r\n52*pi/91.  \r\n```\r\nIn python2 and python3, \r\n```\r\n52*pi/91. != 4*pi/7.  \r\n```\r\nThis is the main need for considering these subtleties.  \r\nWas this the sort of solution you had in mind?\r\n\r\n\r\n\r\n\r\n\r\n\nYou could use np.isclose instead of comparing floats directly to deal with your second issue.\r\n\r\nThis looks good, the only thing I'd change is just reducing q to be much smaller, maybe 8. We only want to pretty print in the simplest of common cases like 3pi/4, pi/8, etc. Anything beyond that doesn't come up very often.\r\n\r\nLooking forward to checking out your PR!", "created_at": 1510, "language": "python", "label": "Hard"}
{"repo": "marcelotduarte/cx_Freeze", "pull_number": 642, "instance_id": "marcelotduarte__cx_Freeze-642", "issue_numbers": ["566"], "base_commit": "485eb0330de934a6418afa42b2eb82f1948cf2d7", "patch": "diff --git a/cx_Freeze/hooks.py b/cx_Freeze/hooks.py\n--- a/cx_Freeze/hooks.py\n+++ b/cx_Freeze/hooks.py\n@@ -5,6 +5,9 @@\n \n from cx_Freeze.common import rebuild_code_object\n \n+MINGW = sysconfig.get_platform() == \"mingw\"\n+WIN32 = sys.platform == \"win32\"\n+\n def initialize(finder):\n     \"\"\"upon initialization of the finder, this routine is called to set up some\n        automatic exclusions for various platforms.\"\"\"\n@@ -219,9 +222,9 @@ def load_cryptography_hazmat_bindings__padding(finder, module):\n \n \n def load__ctypes(finder, module):\n-    \"\"\"In Windows, the _ctypes module in Python >= 3.8 requires an additional dll\n+    \"\"\"In Windows, the _ctypes module in Python 3.8+ requires an additional dll\n        libffi-7.dll to be present in the build directory.\"\"\"\n-    if sys.platform == \"win32\" and sys.version_info >= (3, 8) and sysconfig.get_platform() != \"mingw\":\n+    if WIN32 and sys.version_info >= (3, 8) and not MINGW:\n         dll_name = \"libffi-7.dll\"\n         dll_path = os.path.join(sys.base_prefix, \"DLLs\", dll_name)\n         finder.IncludeFiles(dll_path, os.path.join(\"lib\", dll_name))\n@@ -683,7 +686,7 @@ def load_PyQt4_phonon(finder, module):\n     \"\"\"In Windows, phonon4.dll requires an additional dll phonon_ds94.dll to\n        be present in the build directory inside a folder phonon_backend.\"\"\"\n     name, QtCore = _qt_implementation(module)\n-    if sys.platform == \"win32\":\n+    if WIN32:\n         copy_qt_plugins(\"phonon_backend\", finder, QtCore)\n \n load_PySide_phonon = load_PyQt5_phonon = load_PyQt4_phonon\n@@ -837,9 +840,9 @@ def load_site(finder, module):\n \n \n def load_ssl(finder, module):\n-    \"\"\"In Windows, the SSL module in Python >= 3.7 requires additional dlls to\n+    \"\"\"In Windows, the SSL module in Python 3.7+ requires additional dlls to\n        be present in the build directory.\"\"\"\n-    if sys.platform == \"win32\" and sys.version_info >= (3, 7):\n+    if WIN32 and sys.version_info >= (3, 7) and not MINGW:\n         for dll_search in [\"libcrypto-*.dll\", \"libssl-*.dll\"]:\n             for dll_path in glob.glob(os.path.join(sys.base_prefix, \"DLLs\", dll_search)):\n                 dll_name = os.path.basename(dll_path)\n@@ -850,24 +853,28 @@ def load_tkinter(finder, module):\n     \"\"\"the tkinter module has data files that are required to be loaded so\n        ensure that they are copied into the directory that is expected at\n        runtime.\"\"\"\n-    if sys.platform == \"win32\":\n+    if WIN32:\n         import tkinter\n         root_names = \"tcl\", \"tk\"\n         environ_names = \"TCL_LIBRARY\", \"TK_LIBRARY\"\n         version_vars = tkinter.TclVersion, tkinter.TkVersion\n         zipped = zip(environ_names, version_vars, root_names)\n         for env_name, ver_var, mod_name in zipped:\n+            dir_name = mod_name + str(ver_var)\n             try:\n                 lib_texts = os.environ[env_name]\n             except KeyError:\n-                lib_texts = os.path.join(sys.base_prefix, \"tcl\",\n-                        mod_name + str(ver_var))\n-            targetPath = os.path.join(\"lib\", \"tkinter\", mod_name)\n+                if MINGW:\n+                    lib_texts = os.path.join(sys.base_prefix, \"lib\", dir_name)\n+                else:\n+                    lib_texts = os.path.join(sys.base_prefix, \"tcl\", dir_name)\n+            targetPath = os.path.join(\"lib\", \"tkinter\", dir_name)\n             finder.AddConstant(env_name, targetPath)\n             finder.IncludeFiles(lib_texts, targetPath)\n-            dll_name = mod_name + str(ver_var).replace(\".\", \"\") + \"t.dll\"\n-            dll_path = os.path.join(sys.base_prefix, \"DLLs\", dll_name)\n-            finder.IncludeFiles(dll_path, os.path.join(\"lib\", dll_name))\n+            if not MINGW:\n+                dll_name = dir_name.replace(\".\", \"\") + \"t.dll\"\n+                dll_path = os.path.join(sys.base_prefix, \"DLLs\", dll_name)\n+                finder.IncludeFiles(dll_path, os.path.join(\"lib\", dll_name))\n \n \n def load_tempfile(finder, module):\n@@ -1006,7 +1013,7 @@ def missing_readline(finder, caller):\n     \"\"\"the readline module is not normally present on Windows but it also may\n        be so instead of excluding it completely, ignore it if it can't be\n        found\"\"\"\n-    if sys.platform == \"win32\":\n+    if WIN32:\n         caller.IgnoreName(\"readline\")\n \n \n@@ -1014,7 +1021,7 @@ def load_zmq(finder, module):\n     \"\"\"the zmq package loads zmq.backend.cython dynamically and links\n     dynamically to zmq.libzmq.\"\"\"\n     finder.IncludePackage(\"zmq.backend.cython\")\n-    if sys.platform == \"win32\":\n+    if WIN32:\n         # Not sure yet if this is cross platform\n         # Include the bundled libzmq library, if it exists\n         try:\n@@ -1038,11 +1045,13 @@ def load_clr(finder, module):\n def load_sqlite3(finder, module):\n     \"\"\"In Windows, the sqlite3 module requires an additional dll sqlite3.dll to\n        be present in the build directory.\"\"\"\n-    if sys.platform == \"win32\":\n+    if WIN32 and not MINGW:\n         dll_name = \"sqlite3.dll\"\n         dll_path = os.path.join(sys.base_prefix, \"DLLs\", dll_name)\n+        if not os.path.exists(dll_path):\n+            dll_path = os.path.join(sys.base_prefix, \"Library\", \"bin\", dll_name)\n         finder.IncludeFiles(dll_path, os.path.join(\"lib\", dll_name))\n-    finder.IncludePackage('sqlite3')\n+    finder.IncludePackage(\"sqlite3\")\n \n def load_pytest(finder, module):\n     import pytest\ndiff --git a/cx_Freeze/samples/bcrypt/setup.py b/cx_Freeze/samples/bcrypt/setup.py\n--- a/cx_Freeze/samples/bcrypt/setup.py\n+++ b/cx_Freeze/samples/bcrypt/setup.py\n@@ -1,4 +1,4 @@\n-'''A setup script to demonstrate build using bcrypt'''\n+\"\"\"A setup script to demonstrate build using bcrypt\"\"\"\n #\n # Run the build process by running the command 'python setup.py build'\n #\n@@ -7,13 +7,10 @@\n \n from cx_Freeze import setup, Executable\n \n-setup(name='test_bcrypt',\n-      version='0.1',\n-      description='cx_Freeze script to test bcrypt',\n+setup(name=\"test_bcrypt\",\n+      version=\"0.2\",\n+      description=\"cx_Freeze script to test bcrypt\",\n       executables=[Executable(\"test_bcrypt.py\")],\n-      options={\n-          'build_exe': {'zip_include_packages': [\"*\"],\n-                        'zip_exclude_packages': [],\n-                        #'includes': ['_cffi_backend']\n-                        }\n-          })\n+      options={\"build_exe\": {\"excludes\": [\"tkinter\"],\n+                             \"zip_include_packages\": [\"*\"],\n+                             \"zip_exclude_packages\": []}})\ndiff --git a/cx_Freeze/samples/cryptography/setup.py b/cx_Freeze/samples/cryptography/setup.py\n--- a/cx_Freeze/samples/cryptography/setup.py\n+++ b/cx_Freeze/samples/cryptography/setup.py\n@@ -1,4 +1,4 @@\n-# A setup script to demonstrate build using cffi (inside a cryptography pkg)\n+\"\"\"A setup script to demonstrate build using cffi (used by cryptography)\"\"\"\n #\n # Run the build process by running the command 'python setup.py build'\n #\n@@ -7,11 +7,10 @@\n \n from cx_Freeze import setup, Executable\n \n-buildOptions = dict(zip_include_packages=[\"*\"], zip_exclude_packages=[])\n-executables = [Executable(\"test_crypt.py\")]\n-\n-setup(name='test_crypt',\n-      version='0.1',\n-      description='cx_Freeze script to test cryptography',\n-      executables=executables,\n-      options=dict(build_exe=buildOptions))\n+setup(name=\"test_crypt\",\n+      version=\"0.2\",\n+      description=\"cx_Freeze script to test cryptography\",\n+      executables=[Executable(\"test_crypt.py\")],\n+      options={\"build_exe\": {\"excludes\": [\"tkinter\"],\n+                             \"zip_include_packages\": [\"*\"],\n+                             \"zip_exclude_packages\": []}})\ndiff --git a/cx_Freeze/samples/sqlite/setup.py b/cx_Freeze/samples/sqlite/setup.py\n--- a/cx_Freeze/samples/sqlite/setup.py\n+++ b/cx_Freeze/samples/sqlite/setup.py\n@@ -1,4 +1,4 @@\n-# A setup script to demonstrate the use of sqlite3\n+\"\"\"A setup script to demonstrate the use of sqlite3\"\"\"\n #\n # Run the build process by running the command 'python setup.py build'\n #\n@@ -7,11 +7,11 @@\n \n from cx_Freeze import setup, Executable\n \n-buildOptions = {\"replace_paths\": [(\"*\", \"\")]}\n-executables = [Executable(\"test_sqlite3.py\")]\n-\n-setup(name='test_sqlite3',\n-      version='0.2',\n-      description='cx_Freeze script to test sqlite3',\n-      executables=executables,\n-      options=dict(build_exe=buildOptions))\n+setup(name=\"test_sqlite3\",\n+      version=\"0.3\",\n+      description=\"cx_Freeze script to test sqlite3\",\n+      executables=[Executable(\"test_sqlite3.py\")],\n+      options={\"build_exe\": {\"excludes\": [\"tkinter\"],\n+                             \"replace_paths\": [(\"*\", \"\")],\n+                             \"zip_include_packages\": [\"*\"],\n+                             \"zip_exclude_packages\": []}})\n", "test_patch": "diff --git a/cx_Freeze/samples/cryptography/test_crypt.py b/cx_Freeze/samples/cryptography/test_crypt.py\n--- a/cx_Freeze/samples/cryptography/test_crypt.py\n+++ b/cx_Freeze/samples/cryptography/test_crypt.py\n@@ -1,3 +1,3 @@\n from cryptography.fernet import Fernet\n \n-print('Hello cryptography', Fernet)\n+print(\"Hello cryptography\", Fernet)\ndiff --git a/cx_Freeze/samples/sqlite/test_sqlite3.py b/cx_Freeze/samples/sqlite/test_sqlite3.py\n--- a/cx_Freeze/samples/sqlite/test_sqlite3.py\n+++ b/cx_Freeze/samples/sqlite/test_sqlite3.py\n@@ -29,4 +29,4 @@\n         f.write('%s\\n' % line)\n \n print('dump.sql created')\n-con.close()\n\\ No newline at end of file\n+con.close()\n", "problem_statement": "tkinter path error\nHi,\r\nGot a problem with version  mingw-w64-x86_64-python-cx_Freeze-6.0-1\r\nCan't find path to tkinter (error: [Errno 2] No such file or directory: 'C:/msys64/mingw64/tcl/tcl8.6')\r\nI try to add path in setup-freeze.py:\r\n...\r\ninclude_files = [\r\n    r\"C:\\msys64\\mingw64\\bin\\tcl86.dll\",\r\n    r\"C:\\msys64\\mingw64\\bin\\tk86.dll\",]\r\n\r\nos.environ['TCL_LIBRARY'] = r'C:\\msys64\\mingw64\\lib\\tcl8.6'\r\nos.environ['TK_LIBRARY'] = r'C:\\msys64\\mingw64\\lib\\tk8.6'\r\n....\r\nGot this error: error: [Errno 2] No such file or directory: 'C:/msys64/mingw64/Dlls/tcl86t.dll'\r\ntcl86t.dll doesn't exist, my file is tcl86.dll\r\n\r\nThanks for help!\n", "hints_text": "I try the sample:\r\nhttps://github.com/anthony-tuininga/cx_Freeze/tree/master/cx_Freeze/samples/Tkinter\r\nGot:\r\n...\r\ncopying C:/msys64/mingw64/tcl/tcl8.6 -> build/exe.mingw-3.8/tcl\r\nerror: [Errno 2] No such file or directory: 'C:/msys64/mingw64/tcl/tcl8.6'\r\n\nCan bypass error doing this:\r\n\r\n- Create Ð¡:\\msys64\\mingw64\\tcl directory and copy into it these directories:\r\n    C:\\msys64\\mingw64\\lib\\tcl8.6\r\n    C:\\msys64\\mingw64\\lib\\tk8.6\r\n- Create Ð¡:\\msys64\\mingw64\\Dlls directory and copy into it these files:\r\n    C:\\msys64\\mingw64\\bin\\tcl86.dll\r\n    C:\\msys64\\mingw64\\bin\\tk86.dll\r\n- Rename these files in Ð¡:\\msys64\\mingw64\\Dlls directory:\r\n    tcl86.dll -> tcl86t.dll\r\n    tk86.dll -> tk86t.dll\nSame here, any basic MSYS2 installation triggers this bug.\r\nEdit: I can exclude tcl and tk by spelling them correctly (case sensitive under mingw): [xpra changeset 25138](http://xpra.org/trac/changeset/25138/xpra)", "created_at": 1587, "language": "python", "label": "Easy"}
{"repo": "rigetti/pyquil", "pull_number": 1795, "instance_id": "rigetti__pyquil-1795", "issue_numbers": ["1719"], "base_commit": "ba4aaf50e788ee1aa2980e810fab60d2ce78348e", "patch": "diff --git a/pyquil/api/__init__.py b/pyquil/api/__init__.py\n--- a/pyquil/api/__init__.py\n+++ b/pyquil/api/__init__.py\n@@ -30,7 +30,7 @@\n     QVMCompiler,\n )\n from pyquil.api._qam import QAM, MemoryMap, QAMExecutionResult\n-from pyquil.api._qpu import QPU\n+from pyquil.api._qpu import QPU, QPUExecuteResponse\n from pyquil.api._quantum_computer import (\n     QuantumComputer,\n     get_qc,\n@@ -59,6 +59,7 @@\n     \"MemoryMap\",\n     \"QAMExecutionResult\",\n     \"QPU\",\n+    \"QPUExecuteResponse\",\n     \"QuantumComputer\",\n     \"get_qc\",\n     \"list_quantum_computers\",\ndiff --git a/pyquil/control_flow_graph.py b/pyquil/control_flow_graph.py\n--- a/pyquil/control_flow_graph.py\n+++ b/pyquil/control_flow_graph.py\n@@ -5,7 +5,11 @@\n from quil import program as quil_rs\n from typing_extensions import Self, override\n \n-from pyquil.quilbase import AbstractInstruction, _convert_to_py_instruction, _convert_to_py_instructions\n+from pyquil.quilbase import (\n+    AbstractInstruction,\n+    _convert_to_py_instruction,\n+    _convert_to_py_instructions,\n+)\n \n \n class BasicBlock(quil_rs.BasicBlock):\ndiff --git a/pyquil/quilbase.py b/pyquil/quilbase.py\n--- a/pyquil/quilbase.py\n+++ b/pyquil/quilbase.py\n@@ -1068,12 +1068,13 @@ class LogicalBinaryOp(quil_rs.BinaryLogic, AbstractInstruction):\n \n     def __new__(cls, left: MemoryReference, right: Union[MemoryReference, int]) -> Self:\n         \"\"\"Initialize the operands of the binary logical instruction.\"\"\"\n-        operands = cls._to_rs_binary_operands(left, right)\n-        return super().__new__(cls, cls.op, operands)\n+        destination = left._to_rs_memory_reference()\n+        source = cls._to_rs_binary_operand(right)\n+        return super().__new__(cls, cls.op, destination, source)\n \n     @classmethod\n     def _from_rs_binary_logic(cls, binary_logic: quil_rs.BinaryLogic) -> \"LogicalBinaryOp\":\n-        return super().__new__(cls, binary_logic.operator, binary_logic.operands)\n+        return super().__new__(cls, binary_logic.operator, binary_logic.destination, binary_logic.source)\n \n     @staticmethod\n     def _to_rs_binary_operand(operand: Union[MemoryReference, int]) -> quil_rs.BinaryOperand:\n@@ -1081,12 +1082,6 @@ def _to_rs_binary_operand(operand: Union[MemoryReference, int]) -> quil_rs.Binar\n             return quil_rs.BinaryOperand.from_memory_reference(operand._to_rs_memory_reference())\n         return quil_rs.BinaryOperand.from_literal_integer(operand)\n \n-    @staticmethod\n-    def _to_rs_binary_operands(left: MemoryReference, right: Union[MemoryReference, int]) -> quil_rs.BinaryOperands:\n-        left_operand = left._to_rs_memory_reference()\n-        right_operand = LogicalBinaryOp._to_rs_binary_operand(right)\n-        return quil_rs.BinaryOperands(left_operand, right_operand)\n-\n     @staticmethod\n     def _to_py_binary_operand(operand: quil_rs.BinaryOperand) -> Union[MemoryReference, int]:\n         if operand.is_literal_integer():\n@@ -1096,24 +1091,22 @@ def _to_py_binary_operand(operand: quil_rs.BinaryOperand) -> Union[MemoryReferen\n     @property\n     def left(self) -> MemoryReference:\n         \"\"\"The left hand side of the binary expression.\"\"\"\n-        return MemoryReference._from_rs_memory_reference(super().operands.memory_reference)\n+        return MemoryReference._from_rs_memory_reference(super().destination)\n \n     @left.setter\n     def left(self, left: MemoryReference) -> None:\n-        operands = super().operands\n-        operands.memory_reference = left._to_rs_memory_reference()\n-        quil_rs.BinaryLogic.operands.__set__(self, operands)  # type: ignore[attr-defined]\n+        destination = left._to_rs_memory_reference()\n+        quil_rs.BinaryLogic.destination.__set__(self, destination)  # type: ignore[attr-defined]\n \n     @property\n     def right(self) -> Union[MemoryReference, int]:\n         \"\"\"The right hand side of the binary expression.\"\"\"\n-        return self._to_py_binary_operand(super().operands.operand)\n+        return self._to_py_binary_operand(super().source)\n \n     @right.setter\n     def right(self, right: Union[MemoryReference, int]) -> None:\n-        operands = super().operands\n-        operands.operand = self._to_rs_binary_operand(right)\n-        quil_rs.BinaryLogic.operands.__set__(self, operands)  # type: ignore[attr-defined]\n+        source = self._to_rs_binary_operand(right)\n+        quil_rs.BinaryLogic.source.__set__(self, source)  # type: ignore[attr-defined]\n \n     def out(self) -> str:\n         \"\"\"Return the instruction as a valid Quil string. Raises an error if the instruction contains placeholders.\"\"\"\n@@ -1156,9 +1149,8 @@ class ArithmeticBinaryOp(quil_rs.Arithmetic, AbstractInstruction):\n \n     def __new__(cls, left: MemoryReference, right: Union[MemoryReference, int, float]) -> Self:\n         \"\"\"Initialize the operands of the binary arithmetic instruction.\"\"\"\n-        left_operand = quil_rs.ArithmeticOperand.from_memory_reference(left._to_rs_memory_reference())\n         right_operand = _to_rs_arithmetic_operand(right)\n-        return super().__new__(cls, cls.op, left_operand, right_operand)\n+        return super().__new__(cls, cls.op, left._to_rs_memory_reference(), right_operand)\n \n     @classmethod\n     def _from_rs_arithmetic(cls, arithmetic: quil_rs.Arithmetic) -> \"ArithmeticBinaryOp\":\n@@ -1167,12 +1159,12 @@ def _from_rs_arithmetic(cls, arithmetic: quil_rs.Arithmetic) -> \"ArithmeticBinar\n     @property\n     def left(self) -> MemoryReference:\n         \"\"\"The left hand side of the binary expression.\"\"\"\n-        return MemoryReference._from_rs_memory_reference(super().destination.to_memory_reference())\n+        return MemoryReference._from_rs_memory_reference(super().destination)\n \n     @left.setter\n     def left(self, left: MemoryReference) -> None:\n         quil_rs.Arithmetic.destination.__set__(  # type: ignore[attr-defined]\n-            self, quil_rs.ArithmeticOperand.from_memory_reference(left._to_rs_memory_reference())\n+            self, left._to_rs_memory_reference()\n         )\n \n     @property\n@@ -1493,12 +1485,16 @@ def __new__(\n         right: Union[MemoryReference, int, float],\n     ) -> \"ClassicalComparison\":\n         \"\"\"Initialize a new comparison instruction.\"\"\"\n-        operands = (target._to_rs_memory_reference(), left._to_rs_memory_reference(), cls._to_comparison_operand(right))\n-        return super().__new__(cls, cls.op, operands)\n+        rs_target, rs_left, rs_right = (\n+            target._to_rs_memory_reference(),\n+            left._to_rs_memory_reference(),\n+            cls._to_comparison_operand(right),\n+        )\n+        return super().__new__(cls, cls.op, rs_target, rs_left, rs_right)\n \n     @classmethod\n     def _from_rs_comparison(cls, comparison: quil_rs.Comparison) -> Self:\n-        return super().__new__(cls, comparison.operator, comparison.operands)\n+        return super().__new__(cls, comparison.operator, comparison.destination, comparison.lhs, comparison.rhs)\n \n     @staticmethod\n     def _to_comparison_operand(operand: Union[MemoryReference, int, float]) -> quil_rs.ComparisonOperand:\n@@ -1522,35 +1518,29 @@ def _to_py_operand(operand: quil_rs.ComparisonOperand) -> Union[MemoryReference,\n     @property\n     def target(self) -> MemoryReference:\n         \"\"\"The target of the comparison.\"\"\"\n-        return MemoryReference._from_rs_memory_reference(super().operands[0])\n+        return MemoryReference._from_rs_memory_reference(super().destination)\n \n     @target.setter\n     def target(self, target: MemoryReference) -> None:\n-        operands = list(super().operands)\n-        operands[0] = target._to_rs_memory_reference()\n-        quil_rs.Comparison.operands.__set__(self, tuple(operands))  # type: ignore\n+        quil_rs.Comparison.destination.__set__(self, target._to_rs_memory_reference())  # type: ignore\n \n     @property\n     def left(self) -> MemoryReference:\n         \"\"\"The left hand side of the comparison.\"\"\"\n-        return MemoryReference._from_rs_memory_reference(super().operands[1])\n+        return MemoryReference._from_rs_memory_reference(super().lhs)\n \n     @left.setter\n     def left(self, left: MemoryReference) -> None:\n-        operands = list(super().operands)\n-        operands[1] = left._to_rs_memory_reference()\n-        quil_rs.Comparison.operands.__set__(self, tuple(operands))  # type: ignore\n+        quil_rs.Comparison.lhs.__set__(self, left._to_rs_memory_reference())  # type: ignore\n \n     @property\n     def right(self) -> Union[MemoryReference, int, float]:\n         \"\"\"The right hand side of the comparison.\"\"\"\n-        return self._to_py_operand(super().operands[2])\n+        return self._to_py_operand(super().rhs)\n \n     @right.setter\n     def right(self, right: MemoryReference) -> None:\n-        operands = list(super().operands)\n-        operands[2] = self._to_comparison_operand(right)\n-        quil_rs.Comparison.operands.__set__(self, tuple(operands))  # type: ignore\n+        quil_rs.Comparison.rhs.__set__(self, quil_rs.ComparisonOperand(right._to_rs_memory_reference()))  # type: ignore\n \n     def out(self) -> str:\n         \"\"\"Return the instruction as a valid Quil string.\"\"\"\n", "test_patch": "diff --git a/test/unit/__snapshots__/test_quilbase.ambr b/test/unit/__snapshots__/test_quilbase.ambr\n--- a/test/unit/__snapshots__/test_quilbase.ambr\n+++ b/test/unit/__snapshots__/test_quilbase.ambr\n@@ -11,6 +11,18 @@\n # name: TestArithmeticBinaryOp.test_out[SUB-left1-1]\n   'SUB b[1] 1'\n # ---\n+# name: TestArithmeticBinaryOp.test_pickle[ADD-left0-right0]\n+  Arithmetic { operator: Add, destination: MemoryReference { name: \"a\", index: 0 }, source: MemoryReference(MemoryReference { name: \"b\", index: 0 }) }\n+# ---\n+# name: TestArithmeticBinaryOp.test_pickle[DIV-left3-4.2]\n+  Arithmetic { operator: Divide, destination: MemoryReference { name: \"c\", index: 2 }, source: LiteralReal(4.2) }\n+# ---\n+# name: TestArithmeticBinaryOp.test_pickle[MUL-left2-1.0]\n+  Arithmetic { operator: Multiply, destination: MemoryReference { name: \"c\", index: 2 }, source: LiteralInteger(1) }\n+# ---\n+# name: TestArithmeticBinaryOp.test_pickle[SUB-left1-1]\n+  Arithmetic { operator: Subtract, destination: MemoryReference { name: \"b\", index: 1 }, source: LiteralInteger(1) }\n+# ---\n # name: TestCapture.test_out[Blocking]\n   'CAPTURE 123 q \"FRAMEX\" WAVEFORMY ro[0]'\n # ---\n@@ -20,6 +32,15 @@\n # name: TestCapture.test_out[TemplateWaveform]\n   'NONBLOCKING CAPTURE 123 q \"FRAMEX\" flat(duration: 2.5, iq: 1+2.0i) ro[0]'\n # ---\n+# name: TestCapture.test_pickle[Blocking]\n+  Capture { blocking: true, frame: FrameIdentifier { name: \"FRAMEX\", qubits: [Fixed(123), Variable(\"q\")] }, memory_reference: MemoryReference { name: \"ro\", index: 0 }, waveform: WaveformInvocation { name: \"WAVEFORMY\", parameters: {} } }\n+# ---\n+# name: TestCapture.test_pickle[NonBlocking]\n+  Capture { blocking: false, frame: FrameIdentifier { name: \"FRAMEX\", qubits: [Fixed(123), Variable(\"q\")] }, memory_reference: MemoryReference { name: \"ro\", index: 0 }, waveform: WaveformInvocation { name: \"WAVEFORMY\", parameters: {} } }\n+# ---\n+# name: TestCapture.test_pickle[TemplateWaveform]\n+  Capture { blocking: false, frame: FrameIdentifier { name: \"FRAMEX\", qubits: [Fixed(123), Variable(\"q\")] }, memory_reference: MemoryReference { name: \"ro\", index: 0 }, waveform: WaveformInvocation { name: \"flat\", parameters: {\"duration\": Number(Complex { re: 2.5, im: 0.0 }), \"iq\": Infix(InfixExpression { left: Number(Complex { re: 1.0, im: 0.0 }), operator: Plus, right: Number(Complex { re: 0.0, im: 2.0 }) })} } }\n+# ---\n # name: TestClassicalComparison.test_out[EQ-target0-left0-right0]\n   'EQ t[0] y[0] z[0]'\n # ---\n@@ -175,12 +196,6 @@\n   DEFCIRCUIT NiftyCircuit(%theta) a:\n   \tDECLARE ro BIT[1]\n   \tMEASURE a ro[0]\n-  \tDEFGATE ParameterizedGate(%theta) AS MATRIX:\n-  \t\t%theta, 0, 0, 0\n-  \t\t0, %theta, 0, 0\n-  \t\t0, 0, %theta, 0\n-  \t\t0, 0, 0, %theta\n-  \t\n   \n   '''\n # ---\n@@ -189,6 +204,8 @@\n # ---\n # name: TestDefFrame.test_out[Frame-Only].1\n   set({\n+    '\\tDIRECTION: \"direction\"',\n+    '\\tINITIAL-FREQUENCY: 0',\n   })\n # ---\n # name: TestDefFrame.test_out[With-Optionals]\n@@ -209,6 +226,8 @@\n # ---\n # name: TestDefFrame.test_str[Frame-Only].1\n   set({\n+    '\\tDIRECTION: \"direction\"',\n+    '\\tINITIAL-FREQUENCY: 0',\n   })\n # ---\n # name: TestDefFrame.test_str[With-Optionals]\n@@ -272,6 +291,18 @@\n   \n   '''\n # ---\n+# name: TestDefGate.test_pickle[MixedTypes]\n+  GateDefinition { name: \"MixedTypes\", parameters: [\"X\"], specification: Matrix([[Number(Complex { re: 0.0, im: 0.0 }), FunctionCall(FunctionCallExpression { function: Sine, expression: Variable(\"X\") })], [Number(Complex { re: 0.0, im: 0.0 }), Number(Complex { re: 0.0, im: 0.0 })]]) }\n+# ---\n+# name: TestDefGate.test_pickle[No-Params]\n+  GateDefinition { name: \"NoParamGate\", parameters: [], specification: Matrix([[Number(Complex { re: 1.0, im: 0.0 }), Number(Complex { re: 0.0, im: 0.0 }), Number(Complex { re: 0.0, im: 0.0 }), Number(Complex { re: 0.0, im: 0.0 })], [Number(Complex { re: 0.0, im: 0.0 }), Number(Complex { re: 1.0, im: 0.0 }), Number(Complex { re: 0.0, im: 0.0 }), Number(Complex { re: 0.0, im: 0.0 })], [Number(Complex { re: 0.0, im: 0.0 }), Number(Complex { re: 0.0, im: 0.0 }), Number(Complex { re: 1.0, im: 0.0 }), Number(Complex { re: 0.0, im: 0.0 })], [Number(Complex { re: 0.0, im: 0.0 }), Number(Complex { re: 0.0, im: 0.0 }), Number(Complex { re: 0.0, im: 0.0 }), Number(Complex { re: 1.0, im: 0.0 })]]) }\n+# ---\n+# name: TestDefGate.test_pickle[ParameterlessExpression]\n+  GateDefinition { name: \"ParameterlessExpressions\", parameters: [], specification: Matrix([[Number(Complex { re: 1.0, im: 0.0 }), Number(Complex { re: 1.2246467991473532e-16, im: 0.0 })], [Number(Complex { re: 1.2246467991473532e-16, im: 0.0 }), Prefix(PrefixExpression { operator: Minus, expression: Number(Complex { re: 1.0, im: 0.0 }) })]]) }\n+# ---\n+# name: TestDefGate.test_pickle[Params]\n+  GateDefinition { name: \"ParameterizedGate\", parameters: [\"X\"], specification: Matrix([[FunctionCall(FunctionCallExpression { function: Cosine, expression: Variable(\"X\") }), Number(Complex { re: 0.0, im: 0.0 }), Number(Complex { re: 0.0, im: 0.0 }), Number(Complex { re: 0.0, im: 0.0 })], [Number(Complex { re: 0.0, im: 0.0 }), FunctionCall(FunctionCallExpression { function: Cosine, expression: Variable(\"X\") }), Number(Complex { re: 0.0, im: 0.0 }), Number(Complex { re: 0.0, im: 0.0 })], [Number(Complex { re: 0.0, im: 0.0 }), Number(Complex { re: 0.0, im: 0.0 }), FunctionCall(FunctionCallExpression { function: Cosine, expression: Variable(\"X\") }), Number(Complex { re: 0.0, im: 0.0 })], [Number(Complex { re: 0.0, im: 0.0 }), Number(Complex { re: 0.0, im: 0.0 }), Number(Complex { re: 0.0, im: 0.0 }), FunctionCall(FunctionCallExpression { function: Cosine, expression: Variable(\"X\") })]]) }\n+# ---\n # name: TestDefGate.test_str[MixedTypes]\n   '''\n   DEFGATE MixedTypes(%X) AS MATRIX:\n@@ -406,12 +437,6 @@\n   \n   '''\n # ---\n-# name: TestDefWaveform.test_out[No-Params-Entries]\n-  '''\n-  DEFWAVEFORM Wavey:\n-  \t\n-  '''\n-# ---\n # name: TestDefWaveform.test_out[With-Param]\n   '''\n   DEFWAVEFORM Wavey(%x):\n@@ -424,6 +449,12 @@\n   \t1+2.0i, %x, 3*%y\n   '''\n # ---\n+# name: TestDefWaveform.test_pickle[With-Param]\n+  WaveformDefinition { name: \"Wavey\", definition: Waveform { matrix: [Variable(\"x\")], parameters: [\"x\"] } }\n+# ---\n+# name: TestDefWaveform.test_pickle[With-Params-Complex]\n+  WaveformDefinition { name: \"Wavey\", definition: Waveform { matrix: [Infix(InfixExpression { left: Number(Complex { re: 1.0, im: 0.0 }), operator: Plus, right: Number(Complex { re: 0.0, im: 2.0 }) }), Variable(\"x\"), Infix(InfixExpression { left: Number(Complex { re: 3.0, im: 0.0 }), operator: Star, right: Variable(\"y\") })], parameters: [\"x\", \"y\"] } }\n+# ---\n # name: TestDelayFrames.test_out[frames0-5.0]\n   'DELAY 0 \"frame\" 5'\n # ---\n@@ -598,6 +629,30 @@\n # name: TestPulse.test_out[NonBlocking]\n   'NONBLOCKING PULSE 123 q \"FRAMEX\" WAVEFORMY'\n # ---\n+# name: TestPulse.test_pickle[Blocking]\n+  Pulse { blocking: true, frame: FrameIdentifier { name: \"FRAMEX\", qubits: [Fixed(123), Variable(\"q\")] }, waveform: WaveformInvocation { name: \"WAVEFORMY\", parameters: {} } }\n+# ---\n+# name: TestPulse.test_pickle[BoxcarAveragerKernel]\n+  Pulse { blocking: false, frame: FrameIdentifier { name: \"FRAMEX\", qubits: [Fixed(123), Variable(\"q\")] }, waveform: WaveformInvocation { name: \"boxcar_kernel\", parameters: {\"duration\": Number(Complex { re: 2.5, im: 0.0 }), \"scale\": Number(Complex { re: 1.0, im: 0.0 })} } }\n+# ---\n+# name: TestPulse.test_pickle[DragGaussianWaveform]\n+  Pulse { blocking: false, frame: FrameIdentifier { name: \"FRAMEX\", qubits: [Fixed(123), Variable(\"q\")] }, waveform: WaveformInvocation { name: \"drag_gaussian\", parameters: {\"alpha\": Number(Complex { re: 1.0, im: 0.0 }), \"anh\": Number(Complex { re: 0.1, im: 0.0 }), \"duration\": Number(Complex { re: 2.5, im: 0.0 }), \"fwhm\": Number(Complex { re: 1.0, im: 0.0 }), \"t0\": Number(Complex { re: 1.0, im: 0.0 })} } }\n+# ---\n+# name: TestPulse.test_pickle[ErfSquareWaveform]\n+  Pulse { blocking: false, frame: FrameIdentifier { name: \"FRAMEX\", qubits: [Fixed(123), Variable(\"q\")] }, waveform: WaveformInvocation { name: \"erf_square\", parameters: {\"duration\": Number(Complex { re: 2.5, im: 0.0 }), \"pad_left\": Number(Complex { re: 1.0, im: 0.0 }), \"pad_right\": Number(Complex { re: 0.1, im: 0.0 }), \"risetime\": Number(Complex { re: 1.0, im: 0.0 }), \"scale\": Number(Complex { re: 1.0, im: 0.0 })} } }\n+# ---\n+# name: TestPulse.test_pickle[FlatWaveform]\n+  Pulse { blocking: false, frame: FrameIdentifier { name: \"FRAMEX\", qubits: [Fixed(123), Variable(\"q\")] }, waveform: WaveformInvocation { name: \"flat\", parameters: {\"duration\": Number(Complex { re: 2.5, im: 0.0 }), \"iq\": Infix(InfixExpression { left: Number(Complex { re: 1.0, im: 0.0 }), operator: Plus, right: Number(Complex { re: 0.0, im: 2.0 }) })} } }\n+# ---\n+# name: TestPulse.test_pickle[GaussianWaveform]\n+  Pulse { blocking: false, frame: FrameIdentifier { name: \"FRAMEX\", qubits: [Fixed(123), Variable(\"q\")] }, waveform: WaveformInvocation { name: \"gaussian\", parameters: {\"duration\": Number(Complex { re: 2.5, im: 0.0 }), \"fwhm\": Number(Complex { re: 1.0, im: 0.0 }), \"phase\": Number(Complex { re: 0.1, im: 0.0 }), \"t0\": Number(Complex { re: 1.0, im: 0.0 })} } }\n+# ---\n+# name: TestPulse.test_pickle[HrmGaussianWaveform]\n+  Pulse { blocking: false, frame: FrameIdentifier { name: \"FRAMEX\", qubits: [Fixed(123), Variable(\"q\")] }, waveform: WaveformInvocation { name: \"hrm_gaussian\", parameters: {\"alpha\": Number(Complex { re: 1.0, im: 0.0 }), \"anh\": Number(Complex { re: 0.1, im: 0.0 }), \"duration\": Number(Complex { re: 2.5, im: 0.0 }), \"fwhm\": Number(Complex { re: 1.0, im: 0.0 }), \"second_order_hrm_coeff\": Number(Complex { re: 0.5, im: 0.0 }), \"t0\": Number(Complex { re: 1.0, im: 0.0 })} } }\n+# ---\n+# name: TestPulse.test_pickle[NonBlocking]\n+  Pulse { blocking: false, frame: FrameIdentifier { name: \"FRAMEX\", qubits: [Fixed(123), Variable(\"q\")] }, waveform: WaveformInvocation { name: \"WAVEFORMY\", parameters: {} } }\n+# ---\n # name: TestRawCapture.test_out[Blocking]\n   'RAW-CAPTURE 123 q \"FRAMEX\" 0.5 ro[0]'\n # ---\ndiff --git a/test/unit/test_qpu.py b/test/unit/test_qpu.py\n--- a/test/unit/test_qpu.py\n+++ b/test/unit/test_qpu.py\n@@ -1,12 +1,22 @@\n+import pickle\n+from typing import Any\n from unittest.mock import MagicMock, patch\n \n import numpy as np\n import pytest\n-from qcs_sdk.qpu import MemoryValues\n+from qcs_sdk import ExecutionData, ResultData\n+from qcs_sdk.qpu import MemoryValues, QPUResultData, ReadoutValues\n from qcs_sdk.qpu.api import ExecutionResult, ExecutionResults, Register\n from rpcq.messages import ParameterSpec\n \n-from pyquil.api import ConnectionStrategy, ExecutionOptions, ExecutionOptionsBuilder, RegisterMatrixConversionError\n+from pyquil.api import (\n+    ConnectionStrategy,\n+    ExecutionOptions,\n+    ExecutionOptionsBuilder,\n+    QAMExecutionResult,\n+    QPUExecuteResponse,\n+    RegisterMatrixConversionError,\n+)\n from pyquil.api._abstract_compiler import EncryptedProgram\n from pyquil.api._qpu import QPU\n from pyquil.quil import Program\n@@ -198,3 +208,37 @@ def test_submit_with_options(\n             client=qpu._client_configuration,\n             execution_options=execution_options,\n         )\n+\n+\n+@pytest.mark.parametrize(\n+    \"input\",\n+    [\n+        (\n+            QAMExecutionResult(\n+                executable=mock_encrypted_program,\n+                data=ExecutionData(\n+                    result_data=ResultData.from_qpu(\n+                        QPUResultData(\n+                            mappings={\"ro[0]\": \"q0\", \"ro[1]\": \"q1\"},\n+                            readout_values={\n+                                \"q0\": ReadoutValues.from_integer([1, 1]),\n+                                \"q1\": ReadoutValues.from_real([1.1, 1.2]),\n+                                \"q2\": ReadoutValues.from_complex([complex(3, 4), complex(2.35, 4.21)]),\n+                            },\n+                            memory_values={\"int\": MemoryValues([2, 3, 4]), \"real\": MemoryValues([5.0, 6.0, 7.0])},\n+                        )\n+                    )\n+                ),\n+            )\n+        ),\n+        (\n+            QPUExecuteResponse(\n+                job_id=\"some-job-id\", _executable=mock_encrypted_program, execution_options=ExecutionOptions.default()\n+            )\n+        ),\n+    ],\n+)\n+def test_pickle_execute_responses(input: Any):\n+    pickled_response = pickle.dumps(input)\n+    unpickled_response = pickle.loads(pickled_response)\n+    assert unpickled_response == input\ndiff --git a/test/unit/test_quilbase.py b/test/unit/test_quilbase.py\n--- a/test/unit/test_quilbase.py\n+++ b/test/unit/test_quilbase.py\n@@ -1,4 +1,5 @@\n import copy\n+import pickle\n from collections.abc import Iterable\n from math import pi\n from numbers import Complex, Number\n@@ -187,6 +188,11 @@ def test_compile(self, program: Program, compiler: QPUCompiler):\n         except Exception as e:\n             raise AssertionError(f\"Failed to compile the program: \\n{program}\") from e\n \n+    def test_pickle(self, gate: Gate):\n+        pickled = pickle.dumps(gate)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == gate\n+\n \n @pytest.mark.parametrize(\n     (\"name\", \"matrix\", \"parameters\"),\n@@ -261,6 +267,11 @@ def test_copy(self, def_gate: DefGate):\n         assert isinstance(copy.copy(def_gate), DefGate)\n         assert isinstance(copy.deepcopy(def_gate), DefGate)\n \n+    def test_pickle(self, def_gate: DefGate, snapshot: SnapshotAssertion):\n+        pickled = pickle.dumps(def_gate)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == snapshot\n+\n \n @pytest.mark.parametrize(\n     (\"name\", \"permutation\"),\n@@ -430,6 +441,11 @@ def test_convert(self, calibration: DefCalibration):\n         rs_calibration = _convert_to_rs_instruction(calibration)\n         assert calibration == _convert_to_py_instruction(rs_calibration)\n \n+    def test_pickle(self, calibration: DefCalibration):\n+        pickled = pickle.dumps(calibration)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == calibration\n+\n \n @pytest.mark.parametrize(\n     (\"qubit\", \"memory_reference\", \"instrs\"),\n@@ -468,6 +484,11 @@ def test_convert(self, measure_calibration: DefMeasureCalibration):\n         rs_measure_calibration = _convert_to_rs_instruction(measure_calibration)\n         assert measure_calibration == _convert_to_py_instruction(rs_measure_calibration)\n \n+    def test_pickle(self, measure_calibration: DefMeasureCalibration):\n+        pickled = pickle.dumps(measure_calibration)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == measure_calibration\n+\n \n @pytest.mark.parametrize(\n     (\"qubit\", \"classical_reg\"),\n@@ -511,11 +532,16 @@ def test_convert(self, measurement: Measurement):\n         rs_measurement = _convert_to_rs_instruction(measurement)\n         assert measurement == _convert_to_py_instruction(rs_measurement)\n \n+    def test_pickle(self, measurement: Measurement):\n+        pickled = pickle.dumps(measurement)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == measurement\n+\n \n @pytest.mark.parametrize(\n     (\"frame\", \"direction\", \"initial_frequency\", \"hardware_object\", \"sample_rate\", \"center_frequency\", \"channel_delay\"),\n     [\n-        (Frame([Qubit(0)], \"frame\"), None, None, None, None, None, None),\n+        (Frame([Qubit(0)], \"frame\"), \"direction\", 0.0, None, None, None, None),\n         (Frame([Qubit(1)], \"frame\"), \"direction\", 1.39, \"hardware_object\", 44.1, 440.0, 0.0),\n     ],\n     ids=(\"Frame-Only\", \"With-Optionals\"),\n@@ -603,6 +629,12 @@ def test_convert(self, def_frame: DefFrame):\n         rs_def_frame = _convert_to_rs_instruction(def_frame)\n         assert def_frame == _convert_to_py_instruction(rs_def_frame)\n \n+    def test_pickle(self, def_frame: DefFrame):\n+        print(def_frame.to_quil())\n+        pickled = pickle.dumps(def_frame)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == def_frame\n+\n \n @pytest.mark.parametrize(\n     (\"name\", \"memory_type\", \"memory_size\", \"shared_region\", \"offsets\"),\n@@ -673,6 +705,11 @@ def test_convert(self, declare: Declare):\n         rs_declare = _convert_to_rs_instruction(declare)\n         assert declare == _convert_to_py_instruction(rs_declare)\n \n+    def test_pickle(self, declare: Declare):\n+        pickled = pickle.dumps(declare)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == declare\n+\n \n @pytest.mark.parametrize(\n     (\"command\", \"args\", \"freeform_string\"),\n@@ -718,6 +755,11 @@ def test_convert(self, pragma: Pragma):\n         rs_pragma = _convert_to_rs_instruction(pragma)\n         assert pragma == _convert_to_py_instruction(rs_pragma)\n \n+    def test_pickle(self, pragma: Pragma):\n+        pickled = pickle.dumps(pragma)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == pragma\n+\n \n @pytest.mark.parametrize(\n     (\"qubit\"),\n@@ -765,6 +807,11 @@ def test_convert(self, reset_qubit: Reset):\n         rs_reset_qubit = _convert_to_rs_instruction(reset_qubit)\n         assert reset_qubit == _convert_to_py_instruction(rs_reset_qubit)\n \n+    def test_pickle(self, reset_qubit: Reset):\n+        pickled = pickle.dumps(reset_qubit)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == reset_qubit\n+\n \n @pytest.mark.parametrize(\n     (\"frames\", \"duration\"),\n@@ -798,6 +845,11 @@ def test_convert(self, delay_frames: DelayFrames):\n         rs_delay_frames = _convert_to_rs_instruction(delay_frames)\n         assert delay_frames == _convert_to_py_instruction(rs_delay_frames)\n \n+    def test_pickle(self, delay_frames: DelayFrames):\n+        pickled = pickle.dumps(delay_frames)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == delay_frames\n+\n \n @pytest.mark.parametrize(\n     (\"qubits\", \"duration\"),\n@@ -833,6 +885,11 @@ def test_convert(self, delay_qubits: DelayQubits):\n         rs_delay_qubits = _convert_to_rs_instruction(delay_qubits)\n         assert delay_qubits == _convert_to_py_instruction(rs_delay_qubits)\n \n+    def test_pickle(self, delay_qubits: DelayQubits):\n+        pickled = pickle.dumps(delay_qubits)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == delay_qubits\n+\n \n @pytest.mark.parametrize(\n     (\"qubits\"),\n@@ -863,6 +920,11 @@ def test_convert(self, fence: Fence):\n         rs_fence = _convert_to_rs_instruction(fence)\n         assert fence == _convert_to_py_instruction(rs_fence)\n \n+    def test_pickle(self, fence: Fence):\n+        pickled = pickle.dumps(fence)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == fence\n+\n \n def test_fence_all():\n     fa = FenceAll()\n@@ -873,7 +935,6 @@ def test_fence_all():\n @pytest.mark.parametrize(\n     (\"name\", \"parameters\", \"entries\"),\n     [\n-        (\"Wavey\", [], []),\n         (\"Wavey\", [Parameter(\"x\")], [Parameter(\"x\")]),\n         (\n             \"Wavey\",\n@@ -881,7 +942,7 @@ def test_fence_all():\n             [complex(1.0, 2.0), Parameter(\"x\"), Mul(complex(3.0, 0.0), Parameter(\"y\"))],\n         ),\n     ],\n-    ids=(\"No-Params-Entries\", \"With-Param\", \"With-Params-Complex\"),\n+    ids=(\"With-Param\", \"With-Params-Complex\"),\n )\n class TestDefWaveform:\n     @pytest.fixture\n@@ -914,6 +975,12 @@ def test_convert(self, def_waveform: DefWaveform):\n         rs_def_waveform = _convert_to_rs_instruction(def_waveform)\n         assert def_waveform == _convert_to_py_instruction(rs_def_waveform)\n \n+    def test_pickle(self, def_waveform: DefWaveform, snapshot: SnapshotAssertion):\n+        print(def_waveform.to_quil())\n+        pickled = pickle.dumps(def_waveform)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == snapshot\n+\n \n @pytest.mark.parametrize(\n     (\"name\", \"parameters\", \"qubit_variables\", \"instructions\"),\n@@ -926,7 +993,6 @@ def test_convert(self, def_waveform: DefWaveform):\n             [\n                 Declare(\"ro\", \"BIT\", 1),\n                 Measurement(FormalArgument(\"a\"), MemoryReference(\"ro\")),\n-                DefGate(\"ParameterizedGate\", np.diag([Parameter(\"theta\")] * 4), [Parameter(\"theta\")]),\n             ],\n         ),\n     ],\n@@ -974,6 +1040,12 @@ def test_convert(self, def_circuit: DefCircuit):\n         rs_def_circuit = _convert_to_rs_instruction(def_circuit)\n         assert def_circuit == _convert_to_py_instruction(rs_def_circuit)\n \n+    def test_pickle(self, def_circuit: DefCircuit):\n+        print(def_circuit.to_quil())\n+        pickled = pickle.dumps(def_circuit)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == def_circuit\n+\n \n @pytest.mark.parametrize(\n     (\"frame\", \"kernel\", \"memory_region\", \"nonblocking\"),\n@@ -1035,6 +1107,11 @@ def test_convert(self, capture: Capture):\n         rs_capture = _convert_to_rs_instruction(capture)\n         assert capture == _convert_to_py_instruction(rs_capture)\n \n+    def test_pickle(self, capture: Capture, snapshot: SnapshotAssertion):\n+        pickled = pickle.dumps(capture)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == snapshot\n+\n \n @pytest.mark.parametrize(\n     (\"frame\", \"waveform\", \"nonblocking\"),\n@@ -1125,6 +1202,11 @@ def test_convert(self, pulse: Pulse):\n         rs_pulse = _convert_to_rs_instruction(pulse)\n         assert pulse == _convert_to_py_instruction(rs_pulse)\n \n+    def test_pickle(self, pulse: Pulse, snapshot: SnapshotAssertion):\n+        pickled = pickle.dumps(pulse)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == snapshot\n+\n \n @pytest.mark.parametrize(\n     (\"frame\", \"duration\", \"memory_region\", \"nonblocking\"),\n@@ -1186,6 +1268,11 @@ def test_convert(self, raw_capture: RawCapture):\n         rs_raw_capture = _convert_to_rs_instruction(raw_capture)\n         assert raw_capture == _convert_to_py_instruction(rs_raw_capture)\n \n+    def test_pickle(self, raw_capture: RawCapture):\n+        pickled = pickle.dumps(raw_capture)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == raw_capture\n+\n \n @pytest.mark.parametrize(\n     (\"frame\", \"expression\"),\n@@ -1260,32 +1347,37 @@ def test_convert(self, frame_mutation_instructions):\n )\n class TestSwapPhases:\n     @pytest.fixture\n-    def swap_phase(self, frame_a, frame_b):\n+    def swap_phases(self, frame_a, frame_b):\n         return SwapPhases(frame_a, frame_b)\n \n-    def test_out(self, swap_phase: SwapPhases, snapshot: SnapshotAssertion):\n-        assert swap_phase.out() == snapshot\n+    def test_out(self, swap_phases: SwapPhases, snapshot: SnapshotAssertion):\n+        assert swap_phases.out() == snapshot\n \n-    def test_frames(self, swap_phase: SwapPhases, frame_a: Frame, frame_b: Frame):\n-        assert swap_phase.frameA == frame_a\n-        assert swap_phase.frameB == frame_b\n-        swap_phase.frameA = Frame([Qubit(123)], \"NEW-FRAME\")\n-        swap_phase.frameB = Frame([Qubit(123)], \"NEW-FRAME\")\n-        assert swap_phase.frameA == Frame([Qubit(123)], \"NEW-FRAME\")\n-        assert swap_phase.frameB == Frame([Qubit(123)], \"NEW-FRAME\")\n+    def test_frames(self, swap_phases: SwapPhases, frame_a: Frame, frame_b: Frame):\n+        assert swap_phases.frameA == frame_a\n+        assert swap_phases.frameB == frame_b\n+        swap_phases.frameA = Frame([Qubit(123)], \"NEW-FRAME\")\n+        swap_phases.frameB = Frame([Qubit(123)], \"NEW-FRAME\")\n+        assert swap_phases.frameA == Frame([Qubit(123)], \"NEW-FRAME\")\n+        assert swap_phases.frameB == Frame([Qubit(123)], \"NEW-FRAME\")\n \n-    def test_get_qubits(self, swap_phase: SwapPhases, frame_a: Frame, frame_b: Frame):\n+    def test_get_qubits(self, swap_phases: SwapPhases, frame_a: Frame, frame_b: Frame):\n         expected_qubits = set(frame_a.qubits + frame_b.qubits)\n-        assert swap_phase.get_qubits() == set([q.index for q in expected_qubits if isinstance(q, Qubit)])\n-        assert swap_phase.get_qubits(False) == expected_qubits\n+        assert swap_phases.get_qubits() == set([q.index for q in expected_qubits if isinstance(q, Qubit)])\n+        assert swap_phases.get_qubits(False) == expected_qubits\n+\n+    def test_copy(self, swap_phases: SwapPhases):\n+        assert isinstance(copy.copy(swap_phases), SwapPhases)\n+        assert isinstance(copy.deepcopy(swap_phases), SwapPhases)\n \n-    def test_copy(self, swap_phase: SwapPhases):\n-        assert isinstance(copy.copy(swap_phase), SwapPhases)\n-        assert isinstance(copy.deepcopy(swap_phase), SwapPhases)\n+    def test_convert(self, swap_phases: SwapPhases):\n+        rs_swap_phase = _convert_to_rs_instruction(swap_phases)\n+        assert swap_phases == _convert_to_py_instruction(rs_swap_phase)\n \n-    def test_convert(self, swap_phase: SwapPhases):\n-        rs_swap_phase = _convert_to_rs_instruction(swap_phase)\n-        assert swap_phase == _convert_to_py_instruction(rs_swap_phase)\n+    def test_pickle(self, swap_phases: SwapPhases):\n+        pickled = pickle.dumps(swap_phases)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == swap_phases\n \n \n @pytest.mark.parametrize(\n@@ -1322,6 +1414,11 @@ def test_convert(self, move: ClassicalMove):\n         rs_classical_move = _convert_to_rs_instruction(move)\n         assert move == _convert_to_py_instruction(rs_classical_move)\n \n+    def test_pickle(self, move: ClassicalMove):\n+        pickled = pickle.dumps(move)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == move\n+\n \n @pytest.mark.parametrize(\n     (\"left\", \"right\"),\n@@ -1353,6 +1450,11 @@ def test_convert(self, exchange: ClassicalExchange):\n         rs_classical_exchange = _convert_to_rs_instruction(exchange)\n         assert exchange == _convert_to_py_instruction(rs_classical_exchange)\n \n+    def test_pickle(self, exchange: ClassicalExchange):\n+        pickled = pickle.dumps(exchange)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == exchange\n+\n \n @pytest.mark.parametrize(\n     (\"left\", \"right\"),\n@@ -1384,6 +1486,11 @@ def test_convert(self, convert: ClassicalConvert):\n         rs_classical_convert = _convert_to_rs_instruction(convert)\n         assert convert == _convert_to_py_instruction(rs_classical_convert)\n \n+    def test_pickle(self, convert: ClassicalConvert):\n+        pickled = pickle.dumps(convert)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == convert\n+\n \n @pytest.mark.parametrize(\n     (\"target\", \"left\", \"right\"),\n@@ -1420,6 +1527,11 @@ def test_convert(self, load: ClassicalLoad):\n         rs_classical_load = _convert_to_rs_instruction(load)\n         assert load == _convert_to_py_instruction(rs_classical_load)\n \n+    def test_pickle(self, load: ClassicalLoad):\n+        pickled = pickle.dumps(load)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == load\n+\n \n @pytest.mark.parametrize(\n     (\"target\", \"left\", \"right\"),\n@@ -1460,6 +1572,11 @@ def test_convert(self, store: ClassicalStore):\n         rs_classical_store = _convert_to_rs_instruction(store)\n         assert store == _convert_to_py_instruction(rs_classical_store)\n \n+    def test_pickle(self, store: ClassicalStore):\n+        pickled = pickle.dumps(store)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == store\n+\n \n @pytest.mark.parametrize(\n     (\"op\", \"target\", \"left\", \"right\"),\n@@ -1512,6 +1629,11 @@ def test_convert(self, comparison: ClassicalComparison):\n         rs_classical_comparison = _convert_to_rs_instruction(comparison)\n         assert comparison == _convert_to_py_instruction(rs_classical_comparison)\n \n+    def test_pickle(self, comparison: ClassicalComparison):\n+        pickled = pickle.dumps(comparison)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == comparison\n+\n \n @pytest.mark.parametrize(\n     (\"op\", \"target\"),\n@@ -1544,6 +1666,11 @@ def test_convert(self, unary: UnaryClassicalInstruction):\n         rs_classical_unary = _convert_to_rs_instruction(unary)\n         assert unary == _convert_to_py_instruction(rs_classical_unary)\n \n+    def test_pickle(self, unary: UnaryClassicalInstruction):\n+        pickled = pickle.dumps(unary)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == unary\n+\n \n @pytest.mark.parametrize(\n     (\"op\", \"left\", \"right\"),\n@@ -1595,6 +1722,11 @@ def test_convert(self, arithmetic: UnaryClassicalInstruction):\n         rs_classical_arithmetic = _convert_to_rs_instruction(arithmetic)\n         assert arithmetic == _convert_to_py_instruction(rs_classical_arithmetic)\n \n+    def test_pickle(self, arithmetic: UnaryClassicalInstruction, snapshot: SnapshotAssertion):\n+        pickled = pickle.dumps(arithmetic)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == snapshot\n+\n \n @pytest.mark.parametrize(\n     (\"op\", \"left\", \"right\"),\n@@ -1634,6 +1766,11 @@ def test_convert(self, logical: LogicalBinaryOp):\n         rs_classical_logical = _convert_to_rs_instruction(logical)\n         assert logical == _convert_to_py_instruction(rs_classical_logical)\n \n+    def test_pickle(self, logical: LogicalBinaryOp):\n+        pickled = pickle.dumps(logical)\n+        unpickled = pickle.loads(pickled)\n+        assert unpickled == logical\n+\n \n def test_include():\n     include = Include(\"my-cool-file.quil\")\n", "problem_statement": "Make `QAMExecutionResult` serializable\nDue to using non-picklable members from `qcs-sdk-python`, `QAMExecutionResult` is not itself serializable. We should add a way to pickle it, either by supporting pickling upstream or implementing it for `QAMExecutionResult` specifically. \n", "hints_text": "This would also be useful for `pyquil.api._qpu.QPUExecuteResponse` so that programs can be submitted and retrieved in separate programs.\nYes this would be great. Also, instead of the program data/results disappearing after it's been retrieved by the user (as happens now, from what i understand), it would be great, if it stays available for some (even short) time after, say a day or two. That would allow users to handle potential intermittent retrieval/network/whatever issues (e.g. users tries to retrieve job data, rigetti server sends it over and marks as retrieved, removing relevant data, then something happens along the way and users does not see it... they then can't try to retrieve again, as server thinks that's been done and potentially got rid of it).", "created_at": 1722, "language": "python", "label": "Hard"}
{"repo": "marcelotduarte/cx_Freeze", "pull_number": 2443, "instance_id": "marcelotduarte__cx_Freeze-2443", "issue_numbers": ["2382", "2433"], "base_commit": "c3b273e3246b5026808f91c315daaf980406a1da", "patch": "diff --git a/cx_Freeze/hooks/multiprocessing.py b/cx_Freeze/hooks/multiprocessing.py\n--- a/cx_Freeze/hooks/multiprocessing.py\n+++ b/cx_Freeze/hooks/multiprocessing.py\n@@ -43,16 +43,71 @@ def load_multiprocessing(finder: ModuleFinder, module: Module) -> None:\n             sys.exit()\n     # workaround: inject freeze_support call to avoid an infinite loop\n     from multiprocessing.spawn import freeze_support as _spawn_freeze_support\n-    from multiprocessing.context import BaseContext\n-    BaseContext._get_context = BaseContext.get_context\n-    def _get_freeze_context(self, method=None):\n-        ctx = self._get_context(method)\n-        _spawn_freeze_support()\n-        return ctx\n-    BaseContext.get_context = \\\n-        lambda self, method=None: _get_freeze_context(self, method)\n-    # disable freeze_support, because it cannot be run twice\n-    BaseContext.freeze_support = lambda self: None\n+    from multiprocessing.spawn import is_forking as _spawn_is_forking\n+    from multiprocessing.context import BaseContext, DefaultContext\n+    BaseContext.freeze_support = lambda self: _spawn_freeze_support()\n+    DefaultContext.freeze_support = lambda self: _spawn_freeze_support()\n+    if _spawn_is_forking(sys.argv):\n+        main_module = sys.modules[\"__main__\"]\n+        main_spec = main_module.__spec__\n+        main_code = main_spec.loader.get_code(main_spec.name)\n+        _names = main_code.co_names\n+        del main_module, main_spec, main_code\n+        if \"freeze_support\" not in _names:\n+            import BUILD_CONSTANTS as _contants\n+            _ignore = getattr(_contants, \"ignore_freeze_support_message\", 0)\n+            if not _ignore:\n+                print(\n+    '''\n+        An attempt has been made to start a new process before the\n+        current process has finished its bootstrapping phase.\n+\n+        This probably means that you are not using fork to start your\n+        child processes and you have forgotten to use the proper idiom\n+        in the main module:\n+\n+            if __name__ == \"__main__\":\n+                freeze_support()\n+                ...\n+\n+        To fix this issue, or to hide this message, refer to the documentation:\n+            \\\n+    https://cx-freeze.readthedocs.io/en/stable/faq.html#multiprocessing-support\n+    ''', file=sys.stderr)\n+            #import os, signal\n+            #os.kill(os.getppid(), signal.SIGHUP)\n+            #sys.exit(os.EX_SOFTWARE)\n+            _spawn_freeze_support()\n+    # cx_Freeze patch end\n+    \"\"\"\n+    code_string = module.file.read_text(encoding=\"utf_8\") + dedent(source)\n+    module.code = compile(\n+        code_string,\n+        module.file.as_posix(),\n+        \"exec\",\n+        dont_inherit=True,\n+        optimize=finder.optimize,\n+    )\n+\n+\n+def load_multiprocessing_context(finder: ModuleFinder, module: Module) -> None:\n+    \"\"\"Monkeypath get_context to do automatic freeze_support.\"\"\"\n+    if IS_MINGW or IS_WINDOWS:\n+        return\n+    if module.file.suffix == \".pyc\":  # source unavailable\n+        return\n+    source = r\"\"\"\n+    # cx_Freeze patch start\n+    BaseContext._get_base_context = BaseContext.get_context\n+    def _get_base_context(self, method=None):\n+        self.freeze_support()\n+        return self._get_base_context(method)\n+    BaseContext.get_context = _get_base_context\n+    DefaultContext._get_default_context = DefaultContext.get_context\n+    def _get_default_context(self, method=None):\n+        self.freeze_support()\n+        return self._get_default_context(method)\n+    DefaultContext.get_context = _get_default_context\n     # cx_Freeze patch end\n     \"\"\"\n     code_string = module.file.read_text(encoding=\"utf_8\") + dedent(source)\n", "test_patch": "diff --git a/tests/test_multiprocessing.py b/tests/test_multiprocessing.py\n--- a/tests/test_multiprocessing.py\n+++ b/tests/test_multiprocessing.py\n@@ -21,14 +21,13 @@\n \n SOURCE = \"\"\"\\\n sample1.py\n-    import multiprocessing, sys\n+    import multiprocessing\n \n     def foo(q):\n-        q.put('hello')\n+        q.put(\"Hello from cx_Freeze\")\n \n-    if __name__ == '__main__':\n-        if sys.platform == 'win32':  # the conditional is unecessary\n-            multiprocessing.freeze_support()\n+    if __name__ == \"__main__\":\n+        multiprocessing.freeze_support()\n         multiprocessing.set_start_method('spawn')\n         q = multiprocessing.SimpleQueue()\n         p = multiprocessing.Process(target=foo, args=(q,))\n@@ -36,25 +35,23 @@ def foo(q):\n         print(q.get())\n         p.join()\n sample2.py\n-    import multiprocessing, sys\n+    import multiprocessing\n \n     def foo(q):\n-        q.put('hello')\n+        q.put(\"Hello from cx_Freeze\")\n \n-    if __name__ == '__main__':\n+    if __name__ == \"__main__\":\n         ctx = multiprocessing.get_context('spawn')\n-        if sys.platform == 'win32':  # the conditional is unecessary\n-            ctx.freeze_support()\n+        ctx.freeze_support()\n         q = ctx.Queue()\n         p = ctx.Process(target=foo, args=(q,))\n         p.start()\n         print(q.get())\n         p.join()\n sample3.py\n-    if __name__ ==  \"__main__\":\n+    if __name__ == \"__main__\":\n         import multiprocessing, sys\n-        if sys.platform == 'win32':  # the conditional is unecessary\n-            multiprocessing.freeze_support()\n+        multiprocessing.freeze_support()\n         multiprocessing.set_start_method('spawn')\n         mgr = multiprocessing.Manager()\n         var = [1] * 10000000\n@@ -80,18 +77,22 @@ def foo(q):\n         }\n     )\n \"\"\"\n-EXPECTED_OUTPUT = [\"hello\", \"hello\", \"creating dict...done!\"]\n+EXPECTED_OUTPUT = [\n+    \"Hello from cx_Freeze\",\n+    \"Hello from cx_Freeze\",\n+    \"creating dict...done!\",\n+]\n \n \n def _parameters_data() -> Iterator:\n     methods = mp.get_all_start_methods()\n     for method in methods:\n         source = SOURCE.replace(\"('spawn')\", f\"('{method}')\")\n-        for i, expected in enumerate(EXPECTED_OUTPUT):\n+        for i, expected in enumerate(EXPECTED_OUTPUT, 1):\n             if method == \"forkserver\" and i != 3:\n                 continue  # only sample3 works with forkserver method\n-            sample = f\"sample{i+1}\"\n-            test_id = f\"{sample},{method}\"\n+            sample = f\"sample{i}\"\n+            test_id = f\"{sample}-{method}\"\n             yield pytest.param(source, sample, expected, id=test_id)\n \n \n", "problem_statement": "hooks: improve multiprocessing hook to work with pytorch\nFixes #2376 \r\n\nVersion 7.1.0 (and 7.1.0.post0) break FastAPI/hypercorn\n**Describe the bug**\r\nWhen running a program built with cx_freeze starting version 7.1.0, it adds additional arguments, which hypercorn does not accept. These arguments seem to be related to multiprocessing integration.\r\n\r\nThis causes programs built with 7.1.0 or up, to no longer be functional.\r\n\r\nA temporary workaround is to downgrade back to 7.0.0.\r\n\r\n**To Reproduce**\r\nAll that is required is to run a hypercorn/FastAPI server (or it seems anything that uses multiprocessing) built with cx_Freeze on version 7.0.0 or 7.1.0.post0 (and also 7.1.0 was affected).\r\n\r\nI added a full example to a reproduction repository:\r\nhttps://github.com/Daniel-I-Am/cx_freeze-fastapi-repro\r\n\r\n**Expected behavior**\r\nI would expect programs that can be built with 7.0.0 to also be able to be built with 7.1.0.\r\n\r\n**Desktop (please complete the following information):**\r\n - Platform information: Docker `python:3.12-alpine` on linux\r\n - OS architecture: amd64\r\n - cx_Freeze version: 7.1.0.post0\r\n - Python version: 3.12\r\n\n", "hints_text": "## [Codecov](https://app.codecov.io/gh/marcelotduarte/cx_Freeze/pull/2382?dropdown=coverage&src=pr&el=h1&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=Marcelo+Duarte) Report\nAll modified and coverable lines are covered by tests :white_check_mark:\n> Project coverage is 83.29%. Comparing base [(`cde0912`)](https://app.codecov.io/gh/marcelotduarte/cx_Freeze/commit/cde09120951af0c22f68ff81d1b8124127f920b7?dropdown=coverage&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=Marcelo+Duarte) to head [(`6e97ef6`)](https://app.codecov.io/gh/marcelotduarte/cx_Freeze/pull/2382?dropdown=coverage&src=pr&el=desc&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=Marcelo+Duarte).\n\n\n<details><summary>Additional details and impacted files</summary>\n\n\n```diff\n@@           Coverage Diff           @@\n##             main    #2382   +/-   ##\n=======================================\n  Coverage   83.29%   83.29%           \n=======================================\n  Files          27       27           \n  Lines        4058     4058           \n=======================================\n  Hits         3380     3380           \n  Misses        678      678           \n```\n\n\n\n</details>\n\n[:umbrella: View full report in Codecov by Sentry](https://app.codecov.io/gh/marcelotduarte/cx_Freeze/pull/2382?dropdown=coverage&src=pr&el=continue&utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=Marcelo+Duarte).   \n:loudspeaker: Have feedback on the report? [Share it here](https://about.codecov.io/codecov-pr-comment-feedback/?utm_medium=referral&utm_source=github&utm_content=comment&utm_campaign=pr+comments&utm_term=Marcelo+Duarte).\n\n```python\r\nfrom multiprocessing import Process, freeze_support\r\n\r\n\r\ndef f():\r\n    print(\"Hello from cx_Freeze\")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    freeze_support()\r\n    Process(target=f).start()\r\n```\r\n\r\nPotentially related broken case on macos without fastapi\n@Daniel-I-Am I confirm the bug. I'll work on it.\r\n@ntindle Can you check if #2435 is more related to your use case?\nI think you're right that the issue you linked is more related", "created_at": 1717, "language": "python", "label": "Easy"}
{"repo": "rigetti/pyquil", "pull_number": 1714, "instance_id": "rigetti__pyquil-1714", "issue_numbers": ["1710"], "base_commit": "40739442d53c913f989728dd681926ca2aa11fe5", "patch": "diff --git a/pyquil/quilbase.py b/pyquil/quilbase.py\n--- a/pyquil/quilbase.py\n+++ b/pyquil/quilbase.py\n@@ -2750,12 +2750,12 @@ def frame(self) -> Frame:\n     def frame(self, frame: Frame) -> None:\n         quil_rs.FrameDefinition.identifier.__set__(self, frame)  # type: ignore[attr-defined]\n \n-    def _set_attribute(self, name: str, value: Union[str, float]) -> None:\n+    def set_attribute(self, name: str, value: Union[str, float]) -> None:\n         updated = super().attributes\n         updated.update({name: DefFrame._to_attribute_value(value)})\n         quil_rs.FrameDefinition.attributes.__set__(self, updated)  # type: ignore[attr-defined]\n \n-    def _get_attribute(self, name: str) -> Optional[Union[str, float]]:\n+    def get_attribute(self, name: str) -> Optional[Union[str, float]]:\n         value = super().attributes.get(name, None)\n         if value is None:\n             return None\n@@ -2763,46 +2763,98 @@ def _get_attribute(self, name: str) -> Optional[Union[str, float]]:\n             return value.to_string()\n         return value.to_expression().to_number().real\n \n+    def __getitem__(self, name: str) -> Union[str, float]:\n+        if not isinstance(name, str):\n+            raise TypeError(\"Frame attribute keys must be strings\")\n+        value = self.get_attribute(name)\n+        if value is None:\n+            raise AttributeError(f\"Attribute {name} not found\")\n+        return value\n+\n+    def __setitem__(self, name: str, value: Union[str, float]) -> None:\n+        if not isinstance(name, str):\n+            raise TypeError(\"Frame attribute keys must be strings\")\n+        self.set_attribute(name, value)\n+\n     @property\n+    @deprecated(\n+        version=\"4.0\",\n+        reason=\"Quil now supports generic key/value pairs in DEFFRAMEs. Use get_attribute('DIRECTION') instead.\",\n+    )\n     def direction(self) -> Optional[str]:\n-        return self._get_attribute(\"DIRECTION\")  # type: ignore\n+        return self.get_attribute(\"DIRECTION\")  # type: ignore\n \n     @direction.setter\n+    @deprecated(\n+        version=\"4.0\",\n+        reason=\"Quil now supports generic key/value pairs in DEFFRAMEs. Use set_attribute('DIRECTION') instead.\",\n+    )\n     def direction(self, direction: str) -> None:\n-        self._set_attribute(\"DIRECTION\", direction)\n+        self.set_attribute(\"DIRECTION\", direction)\n \n     @property\n+    @deprecated(\n+        version=\"4.0\",\n+        reason=\"Quil now supports generic key/value pairs in DEFFRAMEs. Use set_attribute('INITIAL-FREQUENCY') instead.\",  # noqa: E501\n+    )\n     def initial_frequency(self) -> Optional[float]:\n-        return self._get_attribute(\"INITIAL-FREQUENCY\")  # type: ignore\n+        return self.get_attribute(\"INITIAL-FREQUENCY\")  # type: ignore\n \n     @initial_frequency.setter\n+    @deprecated(\n+        version=\"4.0\",\n+        reason=\"Quil now supports generic key/value pairs in DEFFRAMEs. Use set_attribute('INITIAL-FREQUENCY') instead.\",  # noqa: E501\n+    )\n     def initial_frequency(self, initial_frequency: float) -> None:\n-        self._set_attribute(\"INITIAL-FREQUENCY\", initial_frequency)\n+        self.set_attribute(\"INITIAL-FREQUENCY\", initial_frequency)\n \n     @property\n+    @deprecated(\n+        version=\"4.0\",\n+        reason=\"Quil now supports generic key/value pairs in DEFFRAMEs. Use get_attribute('HARDWARE-OBJECT') instead.\",\n+    )\n     def hardware_object(self) -> Optional[str]:\n-        return self._get_attribute(\"HARDWARE-OBJECT\")  # type: ignore\n+        return self.get_attribute(\"HARDWARE-OBJECT\")  # type: ignore\n \n     @hardware_object.setter\n+    @deprecated(\n+        version=\"4.0\",\n+        reason=\"Quil now supports generic key/value pairs in DEFFRAMEs. Use set_attribute('HARDWARE-OBJECT') instead.\",\n+    )\n     def hardware_object(self, hardware_object: str) -> None:\n-        self._set_attribute(\"HARDWARE-OBJECT\", hardware_object)\n+        self.set_attribute(\"HARDWARE-OBJECT\", hardware_object)\n \n     @property\n+    @deprecated(\n+        version=\"4.0\",\n+        reason=\"Quil now supports generic key/value pairs in DEFFRAMEs. Use get_attribute('SAMPLE-RATE') instead.\",\n+    )\n     def sample_rate(self) -> Frame:\n-        return self._get_attribute(\"SAMPLE-RATE\")  # type: ignore\n+        return self.get_attribute(\"SAMPLE-RATE\")  # type: ignore\n \n     @sample_rate.setter\n+    @deprecated(\n+        version=\"4.0\",\n+        reason=\"Quil now supports generic key/value pairs in DEFFRAMEs. Use set_attribute('SAMPLE-RATE') instead.\",\n+    )\n     def sample_rate(self, sample_rate: float) -> None:\n-        self._set_attribute(\"SAMPLE-RATE\", sample_rate)\n+        self.set_attribute(\"SAMPLE-RATE\", sample_rate)\n \n     @property\n+    @deprecated(\n+        version=\"4.0\",\n+        reason=\"Quil now supports generic key/value pairs in DEFFRAMEs. Use get_attribute('CENTER-FREQUENCY') instead.\",\n+    )\n     def center_frequency(self) -> Frame:\n-        return self._get_attribute(\"CENTER-FREQUENCY\")  # type: ignore\n+        return self.get_attribute(\"CENTER-FREQUENCY\")  # type: ignore\n \n     @center_frequency.setter\n+    @deprecated(\n+        version=\"4.0\",\n+        reason=\"Quil now supports generic key/value pairs in DEFFRAMEs. Use set_attribute('CENTER-FREQUENCY') instead.\",\n+    )\n     def center_frequency(self, center_frequency: float) -> None:\n-        self._set_attribute(\"CENTER-FREQUENCY\", center_frequency)\n-        self._set_attribute(\"CENTER-FREQUENCY\", center_frequency)\n+        self.set_attribute(\"CENTER-FREQUENCY\", center_frequency)\n \n     def __copy__(self) -> Self:\n         return self\n", "test_patch": "diff --git a/test/unit/test_quilbase.py b/test/unit/test_quilbase.py\n--- a/test/unit/test_quilbase.py\n+++ b/test/unit/test_quilbase.py\n@@ -518,32 +518,48 @@ def test_frame(self, def_frame: DefFrame, frame: Frame):\n         assert def_frame.frame == Frame([Qubit(123)], \"new_frame\")\n \n     def test_direction(self, def_frame: DefFrame, direction: Optional[str]):\n-        assert def_frame.direction == direction\n+        assert def_frame.direction == direction is None if not direction else def_frame[\"DIRECTION\"]\n         def_frame.direction = \"tx\"\n         assert def_frame.direction == \"tx\"\n \n     def test_initial_frequency(self, def_frame: DefFrame, initial_frequency: Optional[float]):\n-        assert def_frame.initial_frequency == initial_frequency\n+        assert (\n+            def_frame.initial_frequency == initial_frequency is None\n+            if not initial_frequency\n+            else def_frame[\"INITIAL-FREQUENCY\"]\n+        )\n         def_frame.initial_frequency = 3.14\n         assert def_frame.initial_frequency == 3.14\n \n     def test_hardware_object(self, def_frame: DefFrame, hardware_object: Optional[str]):\n-        assert def_frame.hardware_object == hardware_object\n+        assert (\n+            def_frame.hardware_object == hardware_object is None\n+            if not hardware_object\n+            else def_frame[\"HARDWARE-OBJECT\"]\n+        )\n         def_frame.hardware_object = \"bfg\"\n         assert def_frame.hardware_object == \"bfg\"\n \n-    def test_hardware_object(self, def_frame: DefFrame, hardware_object: Optional[str]):\n-        assert def_frame.hardware_object == hardware_object\n+    def test_hardware_object_json(self, def_frame: DefFrame, hardware_object: Optional[str]):\n+        assert (\n+            def_frame.hardware_object == hardware_object is None\n+            if not hardware_object\n+            else def_frame[\"HARDWARE-OBJECT\"]\n+        )\n         def_frame.hardware_object = '{\"string\": \"str\", \"int\": 1, \"float\": 3.14}'\n         assert def_frame.hardware_object == '{\"string\": \"str\", \"int\": 1, \"float\": 3.14}'\n \n     def test_sample_rate(self, def_frame: DefFrame, sample_rate: Optional[float]):\n-        assert def_frame.sample_rate == sample_rate\n+        assert def_frame.sample_rate == sample_rate is None if not sample_rate else def_frame[\"SAMPLE-RATE\"]\n         def_frame.sample_rate = 96.0\n         assert def_frame.sample_rate == 96.0\n \n     def test_center_frequency(self, def_frame: DefFrame, center_frequency: Optional[float]):\n-        assert def_frame.center_frequency == center_frequency\n+        assert (\n+            def_frame.center_frequency == center_frequency is None\n+            if not center_frequency\n+            else def_frame.center_frequency\n+        )\n         def_frame.center_frequency = 432.0\n         assert def_frame.center_frequency == 432.0\n \n", "problem_statement": "Make the `get_attribute` and `set_attribute` methods on `DefFrame` public.\n`DefFrame` supports generic attributes but there is not a direct way to access any that aren't defined as a `@property` in the public API. One example is `channel_delay`. It was added to the constructor parameters in `V4`, but doesn't have an associated property and requires going through the underlying `quil` API to access it. We should make the current `_get_attribute` and `_set_attribute` methods public so any key/value pairs can be fetched or modified.\r\n\r\n~The `DefFrame` `channel_delay` property wasn't carried over from V3. We should add a special `@property` definition for it so it works as it used to.~\n", "hints_text": "Historical note: it wasn't carried over because it didn't exist, right? This is a new feature of the v2 translation backend.\r\n\r\nAnd simultaneously, frames changed in the Quil spec to have dynamic key-value pairs. So I don't think the right answer here is to add more properties, but rather to allow looking them up by string key, and deprecating the property-based lookups.\nAh, yeah, that is correct, `channel_delay` is new to V4. We should make the current get/set attribute methods public, and point users to it instead. ", "created_at": 1702, "language": "python", "label": "Hard"}
{"repo": "pytest-dev/pytest-django", "pull_number": 910, "instance_id": "pytest-dev__pytest-django-910", "issue_numbers": ["909"], "base_commit": "762cfc2f2cea6eeb859c3ddba3ac06d1799d0842", "patch": "diff --git a/pytest_django/fixtures.py b/pytest_django/fixtures.py\n--- a/pytest_django/fixtures.py\n+++ b/pytest_django/fixtures.py\n@@ -147,6 +147,12 @@ class ResetSequenceTestCase(django_case):\n             django_case = ResetSequenceTestCase\n     else:\n         from django.test import TestCase as django_case\n+        from django.db import transaction\n+        transaction.Atomic._ensure_durability = False\n+\n+        def reset_durability():\n+            transaction.Atomic._ensure_durability = True\n+        request.addfinalizer(reset_durability)\n \n     test_case = django_case(methodName=\"__init__\")\n     test_case._pre_setup()\n", "test_patch": "diff --git a/tests/test_database.py b/tests/test_database.py\n--- a/tests/test_database.py\n+++ b/tests/test_database.py\n@@ -1,7 +1,8 @@\n import pytest\n-from django.db import connection\n+from django.db import connection, transaction\n from django.test.testcases import connections_support_transactions\n \n+from pytest_django.lazy_django import get_django_version\n from pytest_django_test.app.models import Item\n \n \n@@ -138,6 +139,12 @@ def test_fin(self, fin):\n         # Check finalizer has db access (teardown will fail if not)\n         pass\n \n+    @pytest.mark.skipif(get_django_version() < (3, 2), reason=\"Django >= 3.2 required\")\n+    def test_durable_transactions(self, all_dbs):\n+        with transaction.atomic(durable=True):\n+            item = Item.objects.create(name=\"foo\")\n+        assert Item.objects.get() == item\n+\n \n class TestDatabaseFixturesAllOrder:\n     @pytest.fixture\n", "problem_statement": "Handle transaction.atomic(durable=True)\nThis argument will be introduced in Django 3.2: https://docs.djangoproject.com/en/3.2/topics/db/transactions/#controlling-transactions-explicitly\r\n\r\nIt's used to make sure that atomic blocks aren't nested and naturally this fails when running the test suite. The django `TestCase`-class handles this by setting `transaction.Atomic._ensure_durability = False` in `setUpClass` and setting it back to `True` on `tearDownClass`.\r\n\r\nI'm not that familiar with the codebase but I wonder if it would make sense to adjust the non-transactional block in `_django_db_fixture_helper` with something like:\r\n```python\r\ntransaction.Atomic._ensure_durability = False\r\ndef reset_durability():\r\n    transaction.Atomic._ensure_durability = True\r\nrequest.addfinalizer(reset_durability)\r\n```\n", "hints_text": "", "created_at": 1614, "language": "python", "label": "Easy"}
{"repo": "getlogbook/logbook", "pull_number": 284, "instance_id": "getlogbook__logbook-284", "issue_numbers": ["283"], "base_commit": "b1532c4ca83b75efc5a09c02aa58642571ff0a41", "patch": "diff --git a/logbook/queues.py b/logbook/queues.py\n--- a/logbook/queues.py\n+++ b/logbook/queues.py\n@@ -604,7 +604,10 @@ class TWHThreadController(object):\n     queue and sends it to a handler.  Both queue and handler are\n     taken from the passed :class:`ThreadedWrapperHandler`.\n     \"\"\"\n-    _sentinel = object()\n+    class Command(object):\n+        stop = object()\n+        emit = object()\n+        emit_batch = object()\n \n     def __init__(self, wrapper_handler):\n         self.wrapper_handler = wrapper_handler\n@@ -621,17 +624,23 @@ def start(self):\n     def stop(self):\n         \"\"\"Stops the task thread.\"\"\"\n         if self.running:\n-            self.wrapper_handler.queue.put_nowait(self._sentinel)\n+            self.wrapper_handler.queue.put_nowait((self.Command.stop, ))\n             self._thread.join()\n             self._thread = None\n \n     def _target(self):\n         while 1:\n-            record = self.wrapper_handler.queue.get()\n-            if record is self._sentinel:\n+            item = self.wrapper_handler.queue.get()\n+            command, data = item[0], item[1:]\n+            if command is self.Command.stop:\n                 self.running = False\n                 break\n-            self.wrapper_handler.handler.handle(record)\n+            elif command is self.Command.emit:\n+                (record, ) = data\n+                self.wrapper_handler.handler.emit(record)\n+            elif command is self.Command.emit_batch:\n+                record, reason = data\n+                self.wrapper_handler.handler.emit_batch(record, reason)\n \n \n class ThreadedWrapperHandler(WrapperHandler):\n@@ -663,8 +672,17 @@ def close(self):\n         self.handler.close()\n \n     def emit(self, record):\n+        item = (TWHThreadController.Command.emit, record)\n         try:\n-            self.queue.put_nowait(record)\n+            self.queue.put_nowait(item)\n+        except Full:\n+            # silently drop\n+            pass\n+\n+    def emit_batch(self, records, reason):\n+        item = (TWHThreadController.Command.emit_batch, records, reason)\n+        try:\n+            self.queue.put_nowait(item)\n         except Full:\n             # silently drop\n             pass\n", "test_patch": "diff --git a/tests/test_queues.py b/tests/test_queues.py\n--- a/tests/test_queues.py\n+++ b/tests/test_queues.py\n@@ -89,9 +89,24 @@ def test_multi_processing_handler():\n         assert test_handler.has_warning('Hello World')\n \n \n+class BatchTestHandler(logbook.TestHandler):\n+    def __init__(self, *args, **kwargs):\n+        super(BatchTestHandler, self).__init__(*args, **kwargs)\n+        self.batches = []\n+\n+    def emit(self, record):\n+        super(BatchTestHandler, self).emit(record)\n+        self.batches.append([record])\n+\n+    def emit_batch(self, records, reason):\n+        for record in records:\n+            super(BatchTestHandler, self).emit(record)\n+        self.batches.append(records)\n+\n+\n def test_threaded_wrapper_handler(logger):\n     from logbook.queues import ThreadedWrapperHandler\n-    test_handler = logbook.TestHandler()\n+    test_handler = BatchTestHandler()\n     with ThreadedWrapperHandler(test_handler) as handler:\n         logger.warn('Just testing')\n         logger.error('More testing')\n@@ -100,6 +115,50 @@ def test_threaded_wrapper_handler(logger):\n     handler.close()\n \n     assert (not handler.controller.running)\n+    assert len(test_handler.records) == 2\n+    assert len(test_handler.batches) == 2\n+    assert all((len(records) == 1 for records in test_handler.batches))\n+    assert test_handler.has_warning('Just testing')\n+    assert test_handler.has_error('More testing')\n+\n+\n+def test_threaded_wrapper_handler_emit():\n+    from logbook.queues import ThreadedWrapperHandler\n+    test_handler = BatchTestHandler()\n+    with ThreadedWrapperHandler(test_handler) as handler:\n+        lr = logbook.LogRecord('Test Logger', logbook.WARNING, 'Just testing')\n+        test_handler.emit(lr)\n+        lr = logbook.LogRecord('Test Logger', logbook.ERROR, 'More testing')\n+        test_handler.emit(lr)\n+\n+    # give it some time to sync up\n+    handler.close()\n+\n+    assert (not handler.controller.running)\n+    assert len(test_handler.records) == 2\n+    assert len(test_handler.batches) == 2\n+    assert all((len(records) == 1 for records in test_handler.batches))\n+    assert test_handler.has_warning('Just testing')\n+    assert test_handler.has_error('More testing')\n+\n+\n+def test_threaded_wrapper_handler_emit_batched():\n+    from logbook.queues import ThreadedWrapperHandler\n+    test_handler = BatchTestHandler()\n+    with ThreadedWrapperHandler(test_handler) as handler:\n+        test_handler.emit_batch([\n+            logbook.LogRecord('Test Logger', logbook.WARNING, 'Just testing'),\n+            logbook.LogRecord('Test Logger', logbook.ERROR, 'More testing'),\n+        ], 'group')\n+\n+    # give it some time to sync up\n+    handler.close()\n+\n+    assert (not handler.controller.running)\n+    assert len(test_handler.records) == 2\n+    assert len(test_handler.batches) == 1\n+    (records, ) = test_handler.batches\n+    assert len(records) == 2\n     assert test_handler.has_warning('Just testing')\n     assert test_handler.has_error('More testing')\n \n", "problem_statement": "ThreadedWrapperHandler does not forward batched emits as expected\nI noticed that the `ThreadedWrapperHandler` does not forward batch emits in *batch form*. Thus, if a `ThreadedWrapperHandler` wraps a `MailHandler`, a mail is sent for each logging entry instead of one summarising mail.\r\n\r\nI may be able to provide a PR but let me ask first: Is this something you would like to get addressed or is the current behaviour considered *working as intended*?\r\n\r\n---\r\n\r\nAlso, many thanks for this logging package! I use it for pretty much everything I write in Python. :+1:\n", "hints_text": "@lgrahl Thanks for the feedback!\r\n\r\nI think this is a reasonable change to implement. At the most naive approach this will be equivalent to a for loop with `emit`, and at the more complex scenarios this will enable all sorts of optimizations. Sounds like a good idea!", "created_at": 1546, "language": "python", "label": "Hard"}
{"repo": "pytest-dev/pytest-django", "pull_number": 888, "instance_id": "pytest-dev__pytest-django-888", "issue_numbers": ["846"], "base_commit": "c0d10af86eb737f5ac4ba42b1f4361b66d3c6c18", "patch": "diff --git a/pytest_django/plugin.py b/pytest_django/plugin.py\n--- a/pytest_django/plugin.py\n+++ b/pytest_django/plugin.py\n@@ -118,6 +118,12 @@ def pytest_addoption(parser):\n         type=\"bool\",\n         default=True,\n     )\n+    parser.addini(\n+        \"django_debug_mode\",\n+        \"How to set the Django DEBUG setting (default `False`). \"\n+        \"Use `keep` to not override.\",\n+        default=\"False\",\n+    )\n     group.addoption(\n         \"--fail-on-template-vars\",\n         action=\"store_true\",\n@@ -445,11 +451,15 @@ def django_test_environment(request):\n     \"\"\"\n     if django_settings_is_configured():\n         _setup_django()\n-        from django.conf import settings as dj_settings\n         from django.test.utils import setup_test_environment, teardown_test_environment\n \n-        dj_settings.DEBUG = False\n-        setup_test_environment()\n+        debug_ini = request.config.getini(\"django_debug_mode\")\n+        if debug_ini == \"keep\":\n+            debug = None\n+        else:\n+            debug = _get_boolean_value(debug_ini, False)\n+\n+        setup_test_environment(debug=debug)\n         request.addfinalizer(teardown_test_environment)\n \n \n", "test_patch": "diff --git a/tests/test_django_settings_module.py b/tests/test_django_settings_module.py\n--- a/tests/test_django_settings_module.py\n+++ b/tests/test_django_settings_module.py\n@@ -278,7 +278,7 @@ def test_settings():\n     assert result.ret == 0\n \n \n-def test_debug_false(testdir, monkeypatch):\n+def test_debug_false_by_default(testdir, monkeypatch):\n     monkeypatch.delenv(\"DJANGO_SETTINGS_MODULE\")\n     testdir.makeconftest(\n         \"\"\"\n@@ -307,6 +307,78 @@ def test_debug_is_false():\n     assert r.ret == 0\n \n \n+@pytest.mark.parametrize('django_debug_mode', (False, True))\n+def test_django_debug_mode_true_false(testdir, monkeypatch, django_debug_mode):\n+    monkeypatch.delenv(\"DJANGO_SETTINGS_MODULE\")\n+    testdir.makeini(\n+        \"\"\"\n+       [pytest]\n+       django_debug_mode = {}\n+    \"\"\".format(django_debug_mode)\n+    )\n+    testdir.makeconftest(\n+        \"\"\"\n+        from django.conf import settings\n+\n+        def pytest_configure():\n+            settings.configure(SECRET_KEY='set from pytest_configure',\n+                               DEBUG=%s,\n+                               DATABASES={'default': {\n+                                   'ENGINE': 'django.db.backends.sqlite3',\n+                                   'NAME': ':memory:'}},\n+                               INSTALLED_APPS=['django.contrib.auth',\n+                                               'django.contrib.contenttypes',])\n+    \"\"\" % (not django_debug_mode)\n+    )\n+\n+    testdir.makepyfile(\n+        \"\"\"\n+        from django.conf import settings\n+        def test_debug_is_false():\n+            assert settings.DEBUG is {}\n+    \"\"\".format(django_debug_mode)\n+    )\n+\n+    r = testdir.runpytest_subprocess()\n+    assert r.ret == 0\n+\n+\n+@pytest.mark.parametrize('settings_debug', (False, True))\n+def test_django_debug_mode_keep(testdir, monkeypatch, settings_debug):\n+    monkeypatch.delenv(\"DJANGO_SETTINGS_MODULE\")\n+    testdir.makeini(\n+        \"\"\"\n+       [pytest]\n+       django_debug_mode = keep\n+    \"\"\"\n+    )\n+    testdir.makeconftest(\n+        \"\"\"\n+        from django.conf import settings\n+\n+        def pytest_configure():\n+            settings.configure(SECRET_KEY='set from pytest_configure',\n+                               DEBUG=%s,\n+                               DATABASES={'default': {\n+                                   'ENGINE': 'django.db.backends.sqlite3',\n+                                   'NAME': ':memory:'}},\n+                               INSTALLED_APPS=['django.contrib.auth',\n+                                               'django.contrib.contenttypes',])\n+    \"\"\" % settings_debug\n+    )\n+\n+    testdir.makepyfile(\n+        \"\"\"\n+        from django.conf import settings\n+        def test_debug_is_false():\n+            assert settings.DEBUG is {}\n+    \"\"\".format(settings_debug)\n+    )\n+\n+    r = testdir.runpytest_subprocess()\n+    assert r.ret == 0\n+\n+\n @pytest.mark.django_project(\n     extra_settings=\"\"\"\n     INSTALLED_APPS = [\n", "problem_statement": "Django debug should be optional\nhttps://github.com/pytest-dev/pytest-django/blob/162263f338d863fddc14b0659f506d63799f78e1/pytest_django/plugin.py#L473\r\n\r\nCurrently django is hard codded to not allow debug.  This means that static files are not served, even when debug is set as true.  So in my tests when loading from staticfiles_storage the files are not found without a collect static.  What is the expected way to deal with this?\n", "hints_text": "I get having a default flag for DEBUG = False. But if in user's settings they explicitly specify DEBUG = True. I don't think the library should override it.\nI prefer to run tests with ``DEBUG`` set to ``True``, and I can't seem to do that with pytest-django.\r\n\r\nAm I missing something, or if I'm not, is there a workaround?\r\n\r\nThe benefit of doing this is that when a test fails because of an unhandled exception, the resulting screenshot contains debugging information.\nDuplicate of #180.\r\n\r\nThis is done to match Django's behavior: https://docs.djangoproject.com/en/dev/topics/testing/overview/#other-test-conditions\r\n\r\nBut seems like Django has since added a [`--debug-mode` flag](https://docs.djangoproject.com/en/3.1/ref/django-admin/#test) to enable DEBUG. So we can probably do the same. I'll look into it now.", "created_at": 1602, "language": "python", "label": "Easy"}
{"repo": "marcelotduarte/cx_Freeze", "pull_number": 2857, "instance_id": "marcelotduarte__cx_Freeze-2857", "issue_numbers": ["2856"], "base_commit": "0be89ba63a67cfefcd73ee8520848c2bb9d1f17c", "patch": "diff --git a/cx_Freeze/hooks/__init__.py b/cx_Freeze/hooks/__init__.py\n--- a/cx_Freeze/hooks/__init__.py\n+++ b/cx_Freeze/hooks/__init__.py\n@@ -34,6 +34,15 @@ def load_aiofiles(finder: ModuleFinder, module: Module) -> None:\n     finder.include_package(\"aiofiles\")\n \n \n+def load_argon2(finder: ModuleFinder, module: Module) -> None:\n+    \"\"\"The argon2-cffi package requires the _cffi_backend module\n+    (loaded implicitly).\n+    \"\"\"\n+    if module.distribution is None:\n+        module.update_distribution(\"argon2-cffi\")\n+        finder.include_module(\"_cffi_backend\")\n+\n+\n def load_babel(finder: ModuleFinder, module: Module) -> None:\n     \"\"\"The babel must be loaded as a package, and has pickeable data.\"\"\"\n     finder.include_package(\"babel\")\n", "test_patch": "diff --git a/tests/test_hooks_argon2.py b/tests/test_hooks_argon2.py\nnew file mode 100644\n--- /dev/null\n+++ b/tests/test_hooks_argon2.py\n@@ -0,0 +1,37 @@\n+\"\"\"Tests for some cx_Freeze.hooks.\"\"\"\n+\n+from __future__ import annotations\n+\n+from typing import TYPE_CHECKING\n+\n+import pytest\n+from generate_samples import create_package, run_command\n+\n+from cx_Freeze._compat import BUILD_EXE_DIR, EXE_SUFFIX\n+\n+if TYPE_CHECKING:\n+    from pathlib import Path\n+\n+pytest.importorskip(\"argon2\", reason=\"Depends on extra package: argon2-cffi\")\n+\n+SOURCE = \"\"\"\n+test_argon2.py\n+    import argon2\n+    from importlib.metadata import distribution, version\n+\n+    print(\"Hello from cx_Freeze\")\n+    print(argon2.__name__, version(\"argon2-cffi\"))\n+command\n+    cxfreeze --script test_argon2.py build_exe\n+\"\"\"\n+\n+\n+def test_argon2(tmp_path: Path) -> None:\n+    \"\"\"Test if argon2-cffi is working correctly.\"\"\"\n+    create_package(tmp_path, SOURCE)\n+    output = run_command(tmp_path)\n+    executable = tmp_path / BUILD_EXE_DIR / f\"test_argon2{EXE_SUFFIX}\"\n+    assert executable.is_file()\n+    output = run_command(tmp_path, executable, timeout=10)\n+    assert output.splitlines()[0] == \"Hello from cx_Freeze\"\n+    assert output.splitlines()[1].startswith(\"argon2\")\n", "problem_statement": "argon2-cffi metadata is missing on 7.2.4+\n**Describe the bug**\nargon2-cffi metadata is missing\n\n```\n  File \"permissions.py\", line 104, in authenticate\n  File \"passlib\\context.py\", line 2347, in verify\n  File \"passlib\\handlers\\argon2.py\", line 669, in verify\n  File \"passlib\\utils\\handlers.py\", line 2254, in _stub_requires_backend\n  File \"passlib\\utils\\handlers.py\", line 2156, in set_backend\n  File \"passlib\\utils\\handlers.py\", line 2163, in set_backend\n  File \"passlib\\utils\\handlers.py\", line 2188, in set_backend\n  File \"passlib\\utils\\handlers.py\", line 2311, in _set_backend\n  File \"passlib\\utils\\handlers.py\", line 2224, in _set_backend\n  File \"passlib\\handlers\\argon2.py\", line 716, in _load_backend_mixin\n  File \"argon2\\__init__.py\", line 75, in __getattr__\n  File \"importlib\\metadata\\__init__.py\", line 998, in metadata\n  File \"importlib\\metadata\\__init__.py\", line 565, in from_name\nimportlib.metadata.PackageNotFoundError: No package metadata was found for argon2-cffi\n\n```\nLine 104 in permissions is effectively this:\n```\nfrom passlib.context import CryptContext\nCryptContext(schemes=[\"argon2\"]).verify(string1, string2)\n```\n\n\n**To Reproduce**\nHopefully the above is enough, this is a closed source application so I'd like to keep it to what's necessary.\n\n**Expected behavior**\nFor the indirect import of argon2 via passlib to not fail when frozen.\n\n**Screenshots**\nDon't think that helps.\n\n**Desktop (please complete the following information):**\n - Platform information: Win10 and Win11\n - OS architecture (e.g. amd64): amd64\n - cx_Freeze version [e.g. 6.11]: 7.2.4 onwards. It works on 7.2.3. Still broken on 8.0.0\n - Python version [e.g. 3.10]: 3.11\n\n**Additional context**\nPinned cx-Freeze to 7.2.3 for now, tried some typical troubleshooting like putting argon2 into always include, as well as zip-exclude, to no success.\n\n", "hints_text": "", "created_at": 1742, "language": "python", "label": "Easy"}
{"repo": "rigetti/pyquil", "pull_number": 1133, "instance_id": "rigetti__pyquil-1133", "issue_numbers": ["1109"], "base_commit": "7210fbe56290121c44da97b9ec6eea032fcdb612", "patch": "diff --git a/examples/1.3_vqe_demo.py b/examples/1.3_vqe_demo.py\n--- a/examples/1.3_vqe_demo.py\n+++ b/examples/1.3_vqe_demo.py\n@@ -2,7 +2,6 @@\n This is a demo of VQE through the forest stack. We will do the H2 binding from the Google paper\n using OpenFermion to generate Hamiltonians and Forest to simulate the system\n \"\"\"\n-import sys\n import numpy as np\n import matplotlib.pyplot as plt\n \n@@ -18,12 +17,14 @@\n \n from pyquil.quil import Program\n from pyquil.paulis import sX, sY, exponentiate, PauliSum\n-from pyquil.gates import X, I\n+from pyquil.gates import X\n from pyquil.api import QVMConnection\n from pyquil.unitary_tools import tensor_up\n \n from grove.measurements.estimation import estimate_locally_commuting_operator\n \n+QVM_CONNECTION = QVMConnection(endpoint=\"http://localhost:5000\")\n+\n \n def get_h2_dimer(bond_length):\n     # Set molecule parameters.\n@@ -60,7 +61,7 @@ def ucc_circuit(theta):\n \n \n def objective_fun(\n-    theta, hamiltonian=None, quantum_resource=QVMConnection(endpoint=\"http://localhost:5000\")\n+    theta, hamiltonian=None, quantum_resource=QVM_CONNECTION\n ):\n     \"\"\"\n     Evaluate the Hamiltonian bny operator averaging\ndiff --git a/examples/qaoa_ansatz.py b/examples/qaoa_ansatz.py\n--- a/examples/qaoa_ansatz.py\n+++ b/examples/qaoa_ansatz.py\n@@ -26,7 +26,6 @@\n from pyquil.quil import Program\n from pyquil.gates import H\n from pyquil.paulis import sI, sX, sZ, exponentiate_commuting_pauli_sum\n-from pyquil.api import QVMConnection\n \n # Create a 4-node array graph: 0-1-2-3.\n graph = [(0, 1), (1, 2), (2, 3)]\ndiff --git a/examples/website-script.py b/examples/website-script.py\n--- a/examples/website-script.py\n+++ b/examples/website-script.py\n@@ -10,7 +10,7 @@\n \"\"\"\n \n from pyquil import Program, get_qc\n-from pyquil.gates import *\n+from pyquil.gates import H, CNOT\n \n # construct a Bell State program\n p = Program(H(0), CNOT(0, 1))\ndiff --git a/pyquil/api/_base_connection.py b/pyquil/api/_base_connection.py\n--- a/pyquil/api/_base_connection.py\n+++ b/pyquil/api/_base_connection.py\n@@ -30,7 +30,6 @@\n from pyquil.api._error_reporting import _record_call\n from pyquil.api._errors import error_mapping, UserMessageError, UnknownApiError, TooManyQubitsError\n from pyquil.api._logger import logger\n-from pyquil.device import Specs, ISA\n from pyquil.wavefunction import Wavefunction\n \n TYPE_EXPECTATION = \"expectation\"\ndiff --git a/pyquil/api/_compiler.py b/pyquil/api/_compiler.py\n--- a/pyquil/api/_compiler.py\n+++ b/pyquil/api/_compiler.py\n@@ -34,7 +34,7 @@\n from urllib.parse import urljoin\n \n from pyquil import __version__\n-from pyquil.api._base_connection import ForestSession, get_session\n+from pyquil.api._base_connection import ForestSession\n from pyquil.api._qac import AbstractCompiler\n from pyquil.api._error_reporting import _record_call\n from pyquil.api._errors import UserMessageError\ndiff --git a/pyquil/api/_qpu.py b/pyquil/api/_qpu.py\n--- a/pyquil/api/_qpu.py\n+++ b/pyquil/api/_qpu.py\n@@ -24,7 +24,7 @@\n \n from pyquil import Program\n from pyquil.parser import parse\n-from pyquil.api._base_connection import ForestSession, get_session\n+from pyquil.api._base_connection import ForestSession\n from pyquil.api._error_reporting import _record_call\n from pyquil.api._errors import UserMessageError\n from pyquil.api._logger import logger\ndiff --git a/pyquil/api/_quantum_computer.py b/pyquil/api/_quantum_computer.py\n--- a/pyquil/api/_quantum_computer.py\n+++ b/pyquil/api/_quantum_computer.py\n@@ -1199,7 +1199,7 @@ def hadamard(n, dtype=int):\n     H = np.array([[1]], dtype=dtype)\n \n     # Sylvester's construction\n-    for i in range(0, lg2):\n+    for _ in range(0, lg2):\n         H = np.vstack((np.hstack((H, H)), np.hstack((H, -H))))\n \n     return H\ndiff --git a/pyquil/api/_qvm.py b/pyquil/api/_qvm.py\n--- a/pyquil/api/_qvm.py\n+++ b/pyquil/api/_qvm.py\n@@ -34,7 +34,6 @@\n from pyquil.api._config import PyquilConfig\n from pyquil.api._error_reporting import _record_call\n from pyquil.api._qam import QAM\n-from pyquil.device import Device\n from pyquil.gates import MOVE, MemoryReference\n from pyquil.noise import apply_noise_model\n from pyquil.paulis import PauliSum\ndiff --git a/pyquil/experiment/_memory.py b/pyquil/experiment/_memory.py\n--- a/pyquil/experiment/_memory.py\n+++ b/pyquil/experiment/_memory.py\n@@ -20,7 +20,6 @@\n import numpy as np\n \n from pyquil.paulis import PauliTerm\n-from pyquil.experiment._symmetrization import SymmetrizationLevel\n \n \n def euler_angles_RX(theta: float) -> Tuple[float, float, float]:\ndiff --git a/pyquil/experiment/_setting.py b/pyquil/experiment/_setting.py\n--- a/pyquil/experiment/_setting.py\n+++ b/pyquil/experiment/_setting.py\n@@ -24,10 +24,6 @@\n from typing import Iterable, Tuple\n \n from pyquil.paulis import PauliTerm, sI, is_identity\n-from pyquil.experiment._memory import (\n-    pauli_term_to_measurement_memory_map,\n-    pauli_term_to_preparation_memory_map,\n-)\n \n if sys.version_info < (3, 7):\n     from pyquil.external.dataclasses import dataclass\ndiff --git a/pyquil/gates.py b/pyquil/gates.py\n--- a/pyquil/gates.py\n+++ b/pyquil/gates.py\n@@ -14,18 +14,17 @@\n #    limitations under the License.\n ##############################################################################\n from warnings import warn\n-from typing import Any, Callable, Mapping, Optional, Tuple, Union, overload\n+from typing import Callable, Mapping, Optional, Tuple, Union\n+\n+import numpy as np\n \n from pyquil.quilatom import (\n     Addr,\n     Expression,\n     MemoryReference,\n     MemoryReferenceDesignator,\n-    Parameter,\n     ParameterDesignator,\n-    Qubit,\n     QubitDesignator,\n-    QubitPlaceholder,\n     unpack_classical_reg,\n     unpack_qubit,\n )\n@@ -382,7 +381,15 @@ def CPHASE10(angle: ParameterDesignator, control: QubitDesignator, target: Qubit\n     return Gate(name=\"CPHASE10\", params=[angle], qubits=qubits)\n \n \n-def CPHASE(angle: ParameterDesignator, control: QubitDesignator, target: QubitDesignator) -> Gate:\n+# NOTE: We don't use ParameterDesignator here because of the following Sphinx error. This error\n+# can be resolved by importing Expression, but then flake8 complains about an unused import:\n+#   Cannot resolve forward reference in type annotations of \"pyquil.gates.CPHASE\":\n+#   name 'Expression' is not defined\n+def CPHASE(\n+    angle: Union[Expression, MemoryReference, np.int_, int, float, complex],\n+    control: QubitDesignator,\n+    target: QubitDesignator,\n+) -> Gate:\n     \"\"\"Produces a controlled-phase instruction::\n \n         CPHASE(phi) = diag([1, 1, 1, exp(1j * phi)])\ndiff --git a/pyquil/latex/_diagram.py b/pyquil/latex/_diagram.py\n--- a/pyquil/latex/_diagram.py\n+++ b/pyquil/latex/_diagram.py\n@@ -23,7 +23,6 @@\n from pyquil.quilbase import (\n     AbstractInstruction,\n     Wait,\n-    Reset,\n     ResetQubit,\n     JumpConditional,\n     JumpWhen,\n@@ -404,7 +403,7 @@ def build(self):\n         self.index = 0\n         self.working_instructions = measures\n \n-        for instr in self.working_instructions:\n+        for _ in self.working_instructions:\n             self._build_measure()\n \n         offset = max(self.settings.qubit_line_open_wire_length, 0)\ndiff --git a/pyquil/noise.py b/pyquil/noise.py\n--- a/pyquil/noise.py\n+++ b/pyquil/noise.py\n@@ -468,7 +468,6 @@ def _decoherence_noise_model(\n     kraus_maps = []\n     for g in gates:\n         targets = tuple(t.index for t in g.qubits)\n-        key = (g.name, tuple(g.params))\n         if g.name in NO_NOISE:\n             continue\n         matrix, _ = get_noisy_gate(g.name, g.params)\ndiff --git a/pyquil/numpy_simulator.py b/pyquil/numpy_simulator.py\n--- a/pyquil/numpy_simulator.py\n+++ b/pyquil/numpy_simulator.py\n@@ -18,7 +18,6 @@\n import numpy as np\n from numpy.random.mtrand import RandomState\n \n-from pyquil import Program\n from pyquil.gate_matrices import QUANTUM_GATES\n from pyquil.paulis import PauliTerm, PauliSum\n from pyquil.quilbase import Gate\ndiff --git a/pyquil/pyqvm.py b/pyquil/pyqvm.py\n--- a/pyquil/pyqvm.py\n+++ b/pyquil/pyqvm.py\n@@ -15,8 +15,7 @@\n ##############################################################################\n import warnings\n from abc import ABC, abstractmethod\n-from collections import defaultdict\n-from typing import Type, Dict, Tuple, Union, List, Sequence\n+from typing import Dict, List, Sequence, Type, Union\n \n import numpy as np\n from numpy.random.mtrand import RandomState\n@@ -52,15 +51,6 @@\n     ClassicalDiv,\n     ClassicalMove,\n     ClassicalExchange,\n-    ClassicalConvert,\n-    ClassicalLoad,\n-    ClassicalStore,\n-    ClassicalComparison,\n-    ClassicalEqual,\n-    ClassicalLessThan,\n-    ClassicalLessEqual,\n-    ClassicalGreaterThan,\n-    ClassicalGreaterEqual,\n     Jump,\n     Pragma,\n     Declare,\ndiff --git a/pyquil/quil.py b/pyquil/quil.py\n--- a/pyquil/quil.py\n+++ b/pyquil/quil.py\n@@ -39,7 +39,7 @@\n     unpack_classical_reg,\n     unpack_qubit,\n )\n-from pyquil.gates import MEASURE, H, RESET\n+from pyquil.gates import MEASURE, RESET\n from pyquil.quilbase import (\n     DefGate,\n     Gate,\n@@ -65,7 +65,7 @@ class Program(object):\n     \"\"\"A list of pyQuil instructions that comprise a quantum program.\n \n     >>> from pyquil import Program\n-    >>> from pyquil.gates import *\n+    >>> from pyquil.gates import H, CNOT\n     >>> p = Program()\n     >>> p += H(0)\n     >>> p += CNOT(0, 1)\ndiff --git a/pyquil/quilatom.py b/pyquil/quilatom.py\n--- a/pyquil/quilatom.py\n+++ b/pyquil/quilatom.py\n@@ -289,7 +289,7 @@ def format_parameter(element: ParameterDesignator) -> str:\n         return str(element)\n     elif isinstance(element, Expression):\n         return _expression_to_string(element)\n-    assert False, \"Invalid parameter: %r\" % element\n+    raise AssertionError(\"Invalid parameter: %r\" % element)\n \n \n ExpressionValueDesignator = Union[int, float, complex]\n", "test_patch": "diff --git a/pyquil/api/tests/test_config.py b/pyquil/api/tests/test_config.py\n--- a/pyquil/api/tests/test_config.py\n+++ b/pyquil/api/tests/test_config.py\n@@ -1,5 +1,4 @@\n import pytest\n-import os\n \n from pyquil.api._config import PyquilConfig\n from pyquil.api._errors import UserMessageError\ndiff --git a/pyquil/latex/tests/test_latex.py b/pyquil/latex/tests/test_latex.py\n--- a/pyquil/latex/tests/test_latex.py\n+++ b/pyquil/latex/tests/test_latex.py\n@@ -3,7 +3,7 @@\n from pyquil.quil import Program, Pragma\n from pyquil.quilbase import Declare, Measurement, JumpTarget, Jump\n from pyquil.quilatom import MemoryReference, Label\n-from pyquil.gates import H, X, Y, RX, CZ, SWAP, MEASURE, CNOT, RESET, WAIT, MOVE\n+from pyquil.gates import H, X, Y, RX, CZ, SWAP, MEASURE, CNOT, WAIT, MOVE\n from pyquil.latex import to_latex, DiagramSettings\n from pyquil.latex._diagram import split_on_terminal_measures\n \ndiff --git a/pyquil/tests/test_gate_matrices.py b/pyquil/tests/test_gate_matrices.py\n--- a/pyquil/tests/test_gate_matrices.py\n+++ b/pyquil/tests/test_gate_matrices.py\n@@ -11,21 +11,16 @@\n \n \n def test_singleq():\n-    I = QUANTUM_GATES[\"I\"]\n-    assert np.isclose(I, np.eye(2)).all()\n-    X = QUANTUM_GATES[\"X\"]\n-    assert np.isclose(X, np.array([[0, 1], [1, 0]])).all()\n-    Y = QUANTUM_GATES[\"Y\"]\n-    assert np.isclose(Y, np.array([[0, -1j], [1j, 0]])).all()\n-    Z = QUANTUM_GATES[\"Z\"]\n-    assert np.isclose(Z, np.array([[1, 0], [0, -1]])).all()\n-\n-    H = QUANTUM_GATES[\"H\"]\n-    assert np.isclose(H, (1.0 / np.sqrt(2)) * np.array([[1, 1], [1, -1]])).all()\n-    S = QUANTUM_GATES[\"S\"]\n-    assert np.isclose(S, np.array([[1.0, 0], [0, 1j]])).all()\n-    T = QUANTUM_GATES[\"T\"]\n-    assert np.isclose(T, np.array([[1.0, 0.0], [0.0, np.exp(1.0j * np.pi / 4.0)]])).all()\n+    assert np.isclose(QUANTUM_GATES[\"I\"], np.eye(2)).all()\n+    assert np.isclose(QUANTUM_GATES[\"X\"], np.array([[0, 1], [1, 0]])).all()\n+    assert np.isclose(QUANTUM_GATES[\"Y\"], np.array([[0, -1j], [1j, 0]])).all()\n+    assert np.isclose(QUANTUM_GATES[\"Z\"], np.array([[1, 0], [0, -1]])).all()\n+\n+    assert np.isclose(QUANTUM_GATES[\"H\"], (1.0 / np.sqrt(2)) * np.array([[1, 1], [1, -1]])).all()\n+    assert np.isclose(QUANTUM_GATES[\"S\"], np.array([[1.0, 0], [0, 1j]])).all()\n+    assert np.isclose(\n+        QUANTUM_GATES[\"T\"], np.array([[1.0, 0.0], [0.0, np.exp(1.0j * np.pi / 4.0)]])\n+    ).all()\n \n \n def test_parametric():\ndiff --git a/pyquil/tests/test_magic.py b/pyquil/tests/test_magic.py\n--- a/pyquil/tests/test_magic.py\n+++ b/pyquil/tests/test_magic.py\n@@ -1,4 +1,12 @@\n-from pyquil.magic import *\n+from pyquil.magic import (\n+    CNOT,\n+    H,\n+    I,\n+    MEASURE,\n+    X,\n+    Program,\n+    magicquil,\n+)\n \n \n @magicquil\ndiff --git a/pyquil/tests/test_noise.py b/pyquil/tests/test_noise.py\n--- a/pyquil/tests/test_noise.py\n+++ b/pyquil/tests/test_noise.py\n@@ -3,7 +3,7 @@\n import numpy as np\n from unittest.mock import Mock\n \n-from pyquil.gates import CZ, RZ, RX, I, H\n+from pyquil.gates import CZ, I, RX, RZ\n from pyquil.noise import (\n     pauli_kraus_map,\n     damping_kraus_map,\n@@ -134,7 +134,6 @@ def test_decoherence_noise():\n \n     # verify that gate names are translated\n     new_prog = apply_noise_model(prog, m3)\n-    new_gates = _get_program_gates(new_prog)\n \n     # check that headers have been embedded\n     headers = _noise_model_program_header(m3)\ndiff --git a/pyquil/tests/test_numpy_simulator.py b/pyquil/tests/test_numpy_simulator.py\n--- a/pyquil/tests/test_numpy_simulator.py\n+++ b/pyquil/tests/test_numpy_simulator.py\n@@ -5,7 +5,7 @@\n \n from pyquil import Program\n from pyquil.gate_matrices import QUANTUM_GATES as GATES\n-from pyquil.gates import *\n+from pyquil.gates import CCNOT, CNOT, H, MEASURE, RX, X\n from pyquil.numpy_simulator import (\n     targeted_einsum,\n     NumpyWavefunctionSimulator,\n@@ -195,7 +195,7 @@ def test_expectation():\n \n \n def test_expectation_vs_ref_qvm(qvm, n_qubits):\n-    for repeat_i in range(20):\n+    for _ in range(20):\n         prog = _generate_random_program(n_qubits=n_qubits, length=10)\n         operator = _generate_random_pauli(n_qubits=n_qubits, n_terms=5)\n         print(prog)\ndiff --git a/pyquil/tests/test_operator_estimation.py b/pyquil/tests/test_operator_estimation.py\n--- a/pyquil/tests/test_operator_estimation.py\n+++ b/pyquil/tests/test_operator_estimation.py\n@@ -162,7 +162,7 @@ def test_no_complex_coeffs(forest):\n         [ExperimentSetting(TensorProductState(), 1.0j * sY(0))], program=Program(X(0))\n     )\n     with pytest.raises(ValueError):\n-        res = list(measure_observables(qc, suite, n_shots=2000))\n+        list(measure_observables(qc, suite, n_shots=2000))\n \n \n def test_max_weight_operator_1():\n@@ -415,7 +415,7 @@ def test_measure_observables_no_symm_calibr_raises_error(forest):\n     exptsetting = ExperimentSetting(plusZ(0), sX(0))\n     suite = TomographyExperiment([exptsetting], program=Program(I(0)), symmetrization=0)\n     with pytest.raises(ValueError):\n-        result = list(measure_observables(qc, suite, calibrate_readout=\"plus-eig\"))\n+        list(measure_observables(qc, suite, calibrate_readout=\"plus-eig\"))\n \n \n def test_ops_bool_to_prog():\ndiff --git a/pyquil/tests/test_parameters.py b/pyquil/tests/test_parameters.py\n--- a/pyquil/tests/test_parameters.py\n+++ b/pyquil/tests/test_parameters.py\n@@ -8,7 +8,6 @@\n     quil_cos,\n     quil_sqrt,\n     quil_exp,\n-    quil_cis,\n     _contained_parameters,\n     format_parameter,\n     quil_cis,\ndiff --git a/pyquil/tests/test_parser.py b/pyquil/tests/test_parser.py\n--- a/pyquil/tests/test_parser.py\n+++ b/pyquil/tests/test_parser.py\n@@ -16,7 +16,37 @@\n import numpy as np\n import pytest\n \n-from pyquil.gates import *\n+from pyquil.gates import (\n+    ADD,\n+    AND,\n+    CNOT,\n+    CONVERT,\n+    CPHASE00,\n+    DIV,\n+    EQ,\n+    EXCHANGE,\n+    Gate,\n+    GE,\n+    GT,\n+    H,\n+    IOR,\n+    LE,\n+    LOAD,\n+    LT,\n+    MEASURE,\n+    MOVE,\n+    MUL,\n+    NOP,\n+    NOT,\n+    RESET,\n+    RX,\n+    STORE,\n+    SUB,\n+    SWAP,\n+    WAIT,\n+    X,\n+    XOR,\n+)\n from pyquil.parser import parse\n from pyquil.quilatom import MemoryReference, Parameter, quil_cos, quil_sin\n from pyquil.quilbase import Declare, Reset, ResetQubit\ndiff --git a/pyquil/tests/test_paulis.py b/pyquil/tests/test_paulis.py\n--- a/pyquil/tests/test_paulis.py\n+++ b/pyquil/tests/test_paulis.py\n@@ -776,7 +776,7 @@ def test_identity_no_qubit():\n \n def test_qubit_validation():\n     with pytest.raises(ValueError):\n-        op = sX(None)\n+        sX(None)\n \n \n def test_pauli_term_from_str():\ndiff --git a/pyquil/tests/test_paulis_with_placeholders.py b/pyquil/tests/test_paulis_with_placeholders.py\n--- a/pyquil/tests/test_paulis_with_placeholders.py\n+++ b/pyquil/tests/test_paulis_with_placeholders.py\n@@ -172,7 +172,7 @@ def test_ids():\n     # Not sortable\n     with pytest.raises(TypeError):\n         with pytest.warns(FutureWarning):\n-            t = term_1.id() == term_2.id()\n+            term_1.id() == term_2.id()\n \n \n def test_ids_no_sort():\n@@ -669,7 +669,7 @@ def test_from_list():\n \n     with pytest.raises(ValueError):\n         # terms are not on disjoint qubits\n-        pterm = PauliTerm.from_list([(\"X\", q[0]), (\"Y\", q[0])])\n+        PauliTerm.from_list([(\"X\", q[0]), (\"Y\", q[0])])\n \n \n def test_ordered():\ndiff --git a/pyquil/tests/test_qpu.py b/pyquil/tests/test_qpu.py\n--- a/pyquil/tests/test_qpu.py\n+++ b/pyquil/tests/test_qpu.py\n@@ -10,7 +10,6 @@\n from pyquil.api._base_connection import Engagement, get_session\n from pyquil.api._compiler import _collect_classical_memory_write_locations\n from pyquil.api._config import PyquilConfig\n-from pyquil.api._errors import UserMessageError\n from pyquil.api._qpu import _extract_bitstrings\n from pyquil.device import NxDevice\n from pyquil.gates import I, X\n@@ -246,12 +245,12 @@ def test_run_expects_executable(qvm, qpu_compiler):\n \n     p = Program(X(0))\n     with pytest.raises(TypeError):\n-        result = qc.run(p)\n+        qc.run(p)\n \n \n def test_qpu_not_engaged_error():\n     with pytest.raises(ValueError):\n-        qpu = QPU()\n+        QPU()\n \n \n def test_qpu_does_not_engage_without_session():\ndiff --git a/pyquil/tests/test_quantum_computer.py b/pyquil/tests/test_quantum_computer.py\n--- a/pyquil/tests/test_quantum_computer.py\n+++ b/pyquil/tests/test_quantum_computer.py\n@@ -7,7 +7,6 @@\n \n from pyquil import Program, get_qc, list_quantum_computers\n from pyquil.api import QVM, QuantumComputer, local_forest_runtime\n-from pyquil.tests.utils import DummyCompiler\n from pyquil.api._quantum_computer import (\n     _symmetrization,\n     _flip_array_to_prog,\n@@ -21,7 +20,7 @@\n     _check_min_num_trials_for_symmetrized_readout,\n )\n from pyquil.device import NxDevice, gates_in_isa\n-from pyquil.gates import *\n+from pyquil.gates import CNOT, H, I, MEASURE, RX, X\n from pyquil.quilbase import Declare, MemoryReference\n from pyquil.noise import decoherence_noise_with_asymmetric_ro\n from pyquil.pyqvm import PyQVM\n@@ -422,7 +421,7 @@ def test_qc_run(qvm, compiler):\n     qc = get_qc(\"9q-square-noisy-qvm\")\n     bs = qc.run_and_measure(Program(X(0)), trials=3)\n     assert len(bs) == 9\n-    for q, bits in bs.items():\n+    for _, bits in bs.items():\n         assert bits.shape == (3,)\n \n \ndiff --git a/pyquil/tests/test_quil.py b/pyquil/tests/test_quil.py\n--- a/pyquil/tests/test_quil.py\n+++ b/pyquil/tests/test_quil.py\n@@ -406,7 +406,7 @@ def test_dagger():\n     assert p.dagger().out() == \"DAGGER H 0\\nDAGGER X 0\\n\"\n \n     p = Program(X(0), MEASURE(0, MemoryReference(\"ro\", 0)))\n-    with pytest.raises(ValueError) as e:\n+    with pytest.raises(ValueError):\n         p.dagger().out()\n \n     # ensure that modifiers are preserved https://github.com/rigetti/pyquil/pull/914\n@@ -1376,7 +1376,7 @@ def test_placeholders_preserves_modifiers():\n \n \n def _eval_as_np_pi(exp):\n-    eval(exp.replace(\"pi\", repr(np.pi)).replace(\"theta[0]\", \"1\"))\n+    return eval(exp.replace(\"pi\", repr(np.pi)).replace(\"theta[0]\", \"1\"))\n \n \n def test_params_pi_and_precedence():\n@@ -1386,11 +1386,11 @@ def test_params_pi_and_precedence():\n     assert _eval_as_np_pi(trivial_pi) == _eval_as_np_pi(exp)\n \n     less_trivial_pi = \"3 * theta[0] * 2 / (pi)\"\n-    prog = Program(f\"RX({trivial_pi}) 0\")\n+    prog = Program(f\"RX({less_trivial_pi}) 0\")\n     exp = str(prog[0].params[0])\n-    assert _eval_as_np_pi(trivial_pi) == _eval_as_np_pi(exp)\n+    assert _eval_as_np_pi(less_trivial_pi) == _eval_as_np_pi(exp)\n \n     more_less_trivial_pi = \"3 / (theta[0] / (pi + 1)) / pi\"\n-    prog = Program(f\"RX({trivial_pi}) 0\")\n+    prog = Program(f\"RX({more_less_trivial_pi}) 0\")\n     exp = str(prog[0].params[0])\n-    assert _eval_as_np_pi(trivial_pi) == _eval_as_np_pi(exp)\n+    assert _eval_as_np_pi(more_less_trivial_pi) == _eval_as_np_pi(exp)\ndiff --git a/pyquil/tests/test_qvm.py b/pyquil/tests/test_qvm.py\n--- a/pyquil/tests/test_qvm.py\n+++ b/pyquil/tests/test_qvm.py\n@@ -1,13 +1,11 @@\n-import networkx as nx\n import numpy as np\n import pytest\n \n from rpcq.messages import PyQuilExecutableResponse\n \n from pyquil import Program\n-from pyquil.api import QVM, ForestConnection, QVMCompiler\n+from pyquil.api import ForestConnection, QVM\n from pyquil.api._compiler import _extract_program_from_pyquil_executable_response\n-from pyquil.device import NxDevice\n from pyquil.gates import MEASURE, X, CNOT, H\n from pyquil.quilbase import Declare, MemoryReference\n \ndiff --git a/pyquil/tests/test_reference_density_simulator.py b/pyquil/tests/test_reference_density_simulator.py\n--- a/pyquil/tests/test_reference_density_simulator.py\n+++ b/pyquil/tests/test_reference_density_simulator.py\n@@ -4,7 +4,7 @@\n \n import pyquil.gate_matrices as qmats\n from pyquil import Program\n-from pyquil.gates import *\n+from pyquil.gates import CNOT, H, I, MEASURE, PHASE, RX, RY, RZ, X\n from pyquil.pyqvm import PyQVM\n from pyquil.reference_simulator import ReferenceDensitySimulator, _is_valid_quantum_state\n from pyquil.unitary_tools import lifted_gate_matrix\ndiff --git a/pyquil/tests/test_reference_wavefunction_simulator.py b/pyquil/tests/test_reference_wavefunction_simulator.py\n--- a/pyquil/tests/test_reference_wavefunction_simulator.py\n+++ b/pyquil/tests/test_reference_wavefunction_simulator.py\n@@ -922,7 +922,7 @@ def include_measures(request):\n \n \n def test_vs_lisp_qvm(qvm, n_qubits, prog_length):\n-    for repeat_i in range(10):\n+    for _ in range(10):\n         prog = _generate_random_program(n_qubits=n_qubits, length=prog_length)\n         lisp_wf = WavefunctionSimulator()\n         # force lisp wfs to allocate all qubits\n@@ -960,7 +960,7 @@ def _generate_random_pauli(n_qubits, n_terms):\n \n \n def test_expectation_vs_lisp_qvm(qvm, n_qubits):\n-    for repeat_i in range(20):\n+    for _ in range(20):\n         prog = _generate_random_program(n_qubits=n_qubits, length=10)\n         operator = _generate_random_pauli(n_qubits=n_qubits, n_terms=5)\n         lisp_wf = WavefunctionSimulator()\ndiff --git a/pyquil/tests/test_unitary_tools.py b/pyquil/tests/test_unitary_tools.py\n--- a/pyquil/tests/test_unitary_tools.py\n+++ b/pyquil/tests/test_unitary_tools.py\n@@ -3,7 +3,7 @@\n \n from pyquil import Program\n from pyquil import gate_matrices as mat\n-from pyquil.gates import *\n+from pyquil.gates import CCNOT, CNOT, CZ, H, MEASURE, PHASE, RX, RY, RZ, X, Y, Z\n from pyquil.experiment import plusX, minusZ\n from pyquil.paulis import sX, sY, sZ\n from pyquil.unitary_tools import (\n", "problem_statement": "Ignore fewer flake8 style rules\nIf I remove everything other than `E501` (line length) and `F401` (unused imports), and run `flake8 pyquil`, I get 319 errors. At some point we should try to get rid of these, rather than ignoring them. I'll paste the output as a comment.\r\n\r\n\n", "hints_text": "```\r\npyquil/magic.py:43:5: E743 ambiguous function definition 'I'\r\npyquil/gates.py:75:5: E743 ambiguous function definition 'I'\r\npyquil/gates.py:514:14: W503 line break before binary operator\r\npyquil/gates.py:900:11: E126 continuation line over-indented for hanging indent\r\npyquil/gate_matrices.py:90:1: E741 ambiguous variable name 'I'\r\npyquil/paulis.py:66:13: W503 line break before binary operator\r\npyquil/paulis.py:140:21: W503 line break before binary operator\r\npyquil/paulis.py:510:17: W503 line break before binary operator\r\npyquil/noise.py:464:9: F841 local variable 'key' is assigned to but never used\r\npyquil/noise.py:684:23: W503 line break before binary operator\r\npyquil/quilatom.py:387:17: W503 line break before binary operator\r\npyquil/quilatom.py:388:17: W503 line break before binary operator\r\npyquil/quilatom.py:437:17: W503 line break before binary operator\r\npyquil/quilatom.py:438:17: W503 line break before binary operator\r\npyquil/quilatom.py:521:17: W503 line break before binary operator\r\npyquil/quilatom.py:522:17: W503 line break before binary operator\r\npyquil/quilatom.py:528:17: W503 line break before binary operator\r\npyquil/quilatom.py:529:17: W503 line break before binary operator\r\npyquil/quilatom.py:627:17: W503 line break before binary operator\r\npyquil/quilatom.py:628:17: W503 line break before binary operator\r\npyquil/quilbase.py:751:17: W503 line break before binary operator\r\npyquil/quilbase.py:774:17: W503 line break before binary operator\r\npyquil/quilbase.py:858:21: W503 line break before binary operator\r\npyquil/quilbase.py:859:21: W503 line break before binary operator\r\npyquil/quilbase.py:860:21: W503 line break before binary operator\r\npyquil/latex/_ipython.py:79:34: E127 continuation line over-indented for visual indent\r\npyquil/tests/test_parser.py:19:1: F403 'from pyquil.gates import *' used; unable to detect undefined names\r\npyquil/tests/test_parser.py:29:25: F405 'Gate' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:30:32: F405 'Gate' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:34:25: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:35:30: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:36:30: F405 'SWAP' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:114:31: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:115:37: F405 'CPHASE00' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:116:30: F405 'Gate' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:117:31: F405 'Gate' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:123:50: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:184:31: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:185:37: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:196:27: F405 'RESET' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:197:26: F405 'WAIT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:198:25: F405 'NOP' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:204:43: F405 'STORE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:205:39: F405 'STORE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:206:43: F405 'LOAD' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:207:41: F405 'CONVERT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:208:42: F405 'EXCHANGE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:209:35: F405 'MOVE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:210:36: F405 'MOVE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:211:38: F405 'MOVE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:215:34: F405 'MOVE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:216:34: F405 'MOVE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:217:31: F405 'NOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:218:33: F405 'AND' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:219:33: F405 'IOR' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:220:34: F405 'MOVE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:221:33: F405 'XOR' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:222:36: F405 'ADD' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:223:36: F405 'SUB' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:224:36: F405 'MUL' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:225:36: F405 'DIV' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:226:37: F405 'ADD' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:227:37: F405 'SUB' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:228:37: F405 'MUL' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:229:37: F405 'DIV' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:231:18: F405 'EQ' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:233:18: F405 'LT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:235:18: F405 'LE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:237:18: F405 'GT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:239:18: F405 'GE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:241:18: F405 'EQ' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:243:18: F405 'LT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:245:18: F405 'LE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:247:18: F405 'GT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:249:18: F405 'GE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:251:18: F405 'EQ' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:253:18: F405 'LT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:255:18: F405 'LE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:257:18: F405 'GT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:259:18: F405 'GE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:337:21: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:339:21: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:344:21: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:349:21: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parser.py:355:18: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:8:1: F403 'from pyquil.gates import *' used; unable to detect undefined names\r\npyquil/tests/test_numpy_simulator.py:53:20: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:61:20: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:61:26: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:69:20: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:69:26: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:77:20: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:77:26: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:77:32: F405 'CCNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:87:20: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:89:17: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:103:9: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:104:9: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:105:9: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:165:20: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:165:26: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:220:10: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:236:10: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_numpy_simulator.py:237:10: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_noise.py:123:5: F841 local variable 'new_gates' is assigned to but never used\r\npyquil/tests/test_noise.py:128:16: W503 line break before binary operator\r\npyquil/tests/test_reference_density_simulator.py:7:1: F403 'from pyquil.gates import *' used; unable to detect undefined names\r\npyquil/tests/test_reference_density_simulator.py:25:16: F405 'RY' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:25:34: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:26:16: F405 'RY' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:26:34: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:27:16: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:27:28: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:27:47: F405 'RY' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:28:16: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:28:34: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:29:16: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:29:43: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:39:9: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:39:15: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:39:21: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:39:27: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:40:9: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:41:9: F405 'PHASE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:42:9: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:43:9: F405 'PHASE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:44:9: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:45:9: F405 'RZ' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:46:9: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:47:9: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:48:9: F405 'PHASE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:49:9: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:50:9: F405 'PHASE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:51:9: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:52:9: F405 'RZ' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:53:9: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:54:9: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:55:9: F405 'PHASE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:56:9: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:57:9: F405 'PHASE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:58:9: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:59:9: F405 'RZ' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:60:9: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:61:9: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:62:9: F405 'PHASE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:63:9: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:64:9: F405 'PHASE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:65:9: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:66:9: F405 'RZ' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:67:9: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:68:9: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:69:9: F405 'RZ' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:70:9: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:71:9: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:72:9: F405 'RZ' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:73:9: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:74:9: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:75:9: F405 'RZ' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:76:9: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:77:9: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:78:9: F405 'RZ' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:79:9: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:119:25: F405 'I' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:130:25: F405 'I' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:142:25: F405 'I' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:154:25: F405 'I' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:167:25: F405 'I' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:179:25: F405 'I' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:182:48: W503 line break before binary operator\r\npyquil/tests/test_reference_density_simulator.py:183:48: W503 line break before binary operator\r\npyquil/tests/test_reference_density_simulator.py:195:25: F405 'I' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:205:9: F405 'RY' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:206:9: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:270:20: F405 'I' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:310:20: F405 'I' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:312:13: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_reference_density_simulator.py:329:23: F405 'I' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_gate_matrices.py:7:5: E741 ambiguous variable name 'I'\r\npyquil/tests/test_unitary_tools.py:6:1: F403 'from pyquil.gates import *' used; unable to detect undefined names\r\npyquil/tests/test_unitary_tools.py:16:25: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:16:31: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:16:37: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:23:25: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:23:31: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:23:37: F405 'Y' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:23:43: F405 'Z' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:33:17: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:33:23: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:33:35: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:52:21: F405 'RY' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:52:39: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:53:21: F405 'RY' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:53:39: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:54:21: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:54:33: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:54:52: F405 'RY' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:55:21: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:55:39: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:56:21: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:56:48: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:66:42: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:66:48: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:66:54: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:118:20: E127 continuation line over-indented for visual indent\r\npyquil/tests/test_unitary_tools.py:125:20: E127 continuation line over-indented for visual indent\r\npyquil/tests/test_unitary_tools.py:281:32: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:285:32: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:289:32: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:293:32: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:299:32: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:303:32: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:307:32: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:313:32: F405 'RZ' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:317:32: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:318:32: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:323:32: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:324:32: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:327:32: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:328:32: F405 'CCNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:333:32: F405 'RY' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:334:27: F405 'RY' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:342:32: F405 'PHASE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:343:32: F405 'CZ' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:346:32: F405 'PHASE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:347:32: F405 'CZ' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_unitary_tools.py:411:12: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_parameters.py:5:1: F811 redefinition of unused 'quil_cis' from line 5\r\npyquil/tests/test_quil.py:352:39: F841 local variable 'e' is assigned to but never used\r\npyquil/tests/test_quil.py:1313:5: F841 local variable 'less_trivial_pi' is assigned to but never used\r\npyquil/tests/test_quil.py:1318:5: F841 local variable 'more_less_trivial_pi' is assigned to but never used\r\npyquil/tests/test_operator_estimation.py:131:9: F841 local variable 'res' is assigned to but never used\r\npyquil/tests/test_operator_estimation.py:385:9: F841 local variable 'result' is assigned to but never used\r\npyquil/tests/test_paulis_with_placeholders.py:58:13: W503 line break before binary operator\r\npyquil/tests/test_paulis_with_placeholders.py:76:13: W503 line break before binary operator\r\npyquil/tests/test_paulis_with_placeholders.py:86:13: W503 line break before binary operator\r\npyquil/tests/test_paulis_with_placeholders.py:154:13: F841 local variable 't' is assigned to but never used\r\npyquil/tests/test_paulis_with_placeholders.py:302:18: W503 line break before binary operator\r\npyquil/tests/test_paulis_with_placeholders.py:303:18: W503 line break before binary operator\r\npyquil/tests/test_paulis_with_placeholders.py:304:18: W503 line break before binary operator\r\npyquil/tests/test_qpu.py:247:9: F841 local variable 'result' is assigned to but never used\r\npyquil/tests/test_qpu.py:252:9: F841 local variable 'qpu' is assigned to but never used\r\npyquil/tests/test_magic.py:1:1: F403 'from pyquil.magic import *' used; unable to detect undefined names\r\npyquil/tests/test_magic.py:4:2: F405 'magicquil' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:6:5: F405 'H' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:7:5: F405 'CNOT' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:11:32: F405 'Program' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:14:2: F405 'magicquil' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:16:12: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:18:9: F405 'X' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:20:9: F405 'I' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:24:29: F405 'Program' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:24:91: F405 'Program' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:24:107: F405 'Program' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:27:2: F405 'magicquil' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:29:12: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:31:9: F405 'X' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:35:26: F405 'Program' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:35:88: F405 'Program' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:38:2: F405 'magicquil' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:40:12: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:41:12: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:43:9: F405 'X' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:45:9: F405 'X' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:49:31: F405 'Program' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:50:29: F405 'Program' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:50:45: F405 'Program' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:50:74: F405 'Program' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:53:2: F405 'magicquil' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:56:5: F405 'CNOT' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:60:38: F405 'Program' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:63:2: F405 'magicquil' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:66:9: F405 'H' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:68:9: F405 'H' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_magic.py:72:40: F405 'Program' may be undefined, or defined from star imports: pyquil.magic\r\npyquil/tests/test_quantum_computer.py:20:1: F403 'from pyquil.gates import *' used; unable to detect undefined names\r\npyquil/tests/test_quantum_computer.py:24:1: F811 redefinition of unused 'DummyCompiler' from line 10\r\npyquil/tests/test_quantum_computer.py:53:20: F405 'I' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:53:26: F405 'I' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:151:20: F405 'I' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:151:26: F405 'I' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:217:13: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:218:13: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:219:13: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:220:13: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:221:13: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:222:13: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:238:20: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:238:26: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:238:38: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:241:17: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:257:20: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:257:26: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:257:38: F405 'CNOT' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:260:17: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:278:20: F405 'I' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:278:26: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:279:20: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:280:20: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:302:25: F405 'I' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:429:37: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:452:13: F405 'H' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:468:20: F405 'I' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:479:39: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:479:45: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:511:13: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:512:13: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:532:9: F405 'RX' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:533:9: F405 'MEASURE' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:573:42: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_quantum_computer.py:586:17: F405 'X' may be undefined, or defined from star imports: pyquil.gates\r\npyquil/tests/test_paulis.py:98:13: W503 line break before binary operator\r\npyquil/tests/test_paulis.py:348:18: W503 line break before binary operator\r\npyquil/tests/test_paulis.py:349:18: W503 line break before binary operator\r\npyquil/tests/test_paulis.py:350:18: W503 line break before binary operator\r\npyquil/tests/test_paulis.py:679:9: F841 local variable 'op' is assigned to but never used\r\npyquil/_parser/PyQuilListener.py:83:13: W503 line break before binary operator\r\npyquil/api/_quantum_computer.py:133:37: E127 continuation line over-indented for visual indent\r\npyquil/experiment/_main.py:58:26: W503 line break before binary operator\r\npyquil/experiment/_main.py:222:29: W503 line break before binary operator\r\n```", "created_at": 1577, "language": "python", "label": "Hard"}
{"repo": "rigetti/pyquil", "pull_number": 1294, "instance_id": "rigetti__pyquil-1294", "issue_numbers": ["1156"], "base_commit": "b6ad4a9db8e7a6baae3af372bdaa166f725a678d", "patch": "diff --git a/pyquil/api/_base_connection.py b/pyquil/api/_base_connection.py\n--- a/pyquil/api/_base_connection.py\n+++ b/pyquil/api/_base_connection.py\n@@ -600,7 +600,7 @@ def _qvm_run(\n         measurement_noise: Optional[Tuple[float, float, float]],\n         gate_noise: Optional[Tuple[float, float, float]],\n         random_seed: Optional[int],\n-    ) -> np.ndarray:\n+    ) -> Dict[str, np.ndarray]:\n         \"\"\"\n         Run a Forest ``run`` job on a QVM.\n \n@@ -611,7 +611,7 @@ def _qvm_run(\n         )\n         response = post_json(self.session, self.sync_endpoint + \"/qvm\", payload)\n \n-        ram = response.json()\n+        ram: Dict[str, np.ndarray] = {key: np.array(val) for key, val in response.json().items()}\n \n         for k in ram.keys():\n             ram[k] = np.array(ram[k])\ndiff --git a/pyquil/api/_qam.py b/pyquil/api/_qam.py\n--- a/pyquil/api/_qam.py\n+++ b/pyquil/api/_qam.py\n@@ -41,6 +41,8 @@ class QAM(ABC):\n     pretend to be a QPI-compliant quantum computer.\n     \"\"\"\n \n+    _memory_results: Dict[str, np.ndarray]\n+\n     @_record_call\n     def __init__(self) -> None:\n         self.reset()\n@@ -63,7 +65,7 @@ def load(\n         self._executable: Optional[\n             Union[QuiltBinaryExecutableResponse, PyQuilExecutableResponse]\n         ] = executable\n-        self._memory_results: Optional[Dict[str, np.ndarray]] = defaultdict(lambda: None)\n+        self._memory_results = defaultdict(lambda: None)\n         self.status = \"loaded\"\n         return self\n \ndiff --git a/pyquil/api/_qvm.py b/pyquil/api/_qvm.py\n--- a/pyquil/api/_qvm.py\n+++ b/pyquil/api/_qvm.py\n@@ -538,7 +538,10 @@ def load(self, executable: Union[Program, PyQuilExecutableResponse]) -> \"QVM\":\n                     \"`Program`. You provided {}\".format(type(executable))\n                 )\n \n-        return cast(\"QVM\", super().load(executable))\n+        qvm = cast(\"QVM\", super().load(executable))\n+        for region in executable.declarations.keys():\n+            self._memory_results[region] = np.ndarray((executable.num_shots, 0), dtype=np.int64)\n+        return qvm\n \n     @_record_call\n     def run(self) -> \"QVM\":\n@@ -565,7 +568,7 @@ def run(self) -> \"QVM\":\n \n         quil_program = self.augment_program_with_memory_values(quil_program)\n \n-        self._memory_results = self.connection._qvm_run(\n+        results = self.connection._qvm_run(\n             quil_program=quil_program,\n             classical_addresses=classical_addresses,\n             trials=trials,\n@@ -573,9 +576,7 @@ def run(self) -> \"QVM\":\n             gate_noise=self.gate_noise,\n             random_seed=self.random_seed,\n         )\n-\n-        if \"ro\" not in self._memory_results or len(self._memory_results[\"ro\"]) == 0:\n-            self._memory_results[\"ro\"] = np.zeros((trials, 0), dtype=np.int64)\n+        self._memory_results.update(results)\n \n         return self\n \ndiff --git a/pyquil/pyqvm.py b/pyquil/pyqvm.py\n--- a/pyquil/pyqvm.py\n+++ b/pyquil/pyqvm.py\n@@ -211,7 +211,7 @@ def __init__(\n         # private implementation details\n         self._qubit_to_ram: Optional[Dict[int, int]] = None\n         self._ro_size: Optional[int] = None\n-        self._memory_results: Optional[Dict[str, np.ndarray]] = None\n+        self._memory_results = {}\n \n         self.rs = np.random.RandomState(seed=seed)\n         self.wf_simulator = quantum_simulator_type(n_qubits=n_qubits, rs=self.rs)\n@@ -226,7 +226,7 @@ def load(self, executable: Union[Program, PyQuilExecutableResponse]) -> \"PyQVM\":\n         # initialize program counter\n         self.program = program\n         self.program_counter = 0\n-        self._memory_results = None\n+        self._memory_results = {}\n \n         # clear RAM, although it's not strictly clear if this should happen here\n         self.ram = {}\ndiff --git a/pyquil/quil.py b/pyquil/quil.py\n--- a/pyquil/quil.py\n+++ b/pyquil/quil.py\n@@ -40,7 +40,7 @@\n from rpcq.messages import NativeQuilMetadata\n \n from pyquil._parser.parser import run_parser\n-\n+from pyquil.gates import MEASURE, RESET\n from pyquil.noise import _check_kraus_ops, _create_kraus_pragmas, pauli_kraus_map\n from pyquil.quilatom import (\n     Label,\n@@ -58,7 +58,6 @@\n     unpack_classical_reg,\n     unpack_qubit,\n )\n-from pyquil.gates import MEASURE, RESET\n from pyquil.quilbase import (\n     DefGate,\n     Gate,\n@@ -100,7 +99,6 @@\n     match_calibration,\n )\n \n-\n InstructionDesignator = Union[\n     AbstractInstruction,\n     DefGate,\n@@ -140,6 +138,9 @@ def __init__(self, *instructions: InstructionDesignator):\n         # method.  It is marked as None whenever new instructions are added.\n         self._synthesized_instructions: Optional[List[AbstractInstruction]] = None\n \n+        # \"ro\" is always implicitly declared\n+        self._declarations: Dict[str, Declare] = {\"ro\": Declare(\"ro\", \"BIT\")}\n+\n         self.inst(*instructions)\n \n         # Filled in with quil_to_native_quil\n@@ -166,6 +167,11 @@ def frames(self) -> Dict[Frame, DefFrame]:\n         \"\"\" A mapping from Quil-T frames to their definitions. \"\"\"\n         return self._frames\n \n+    @property\n+    def declarations(self) -> Dict[str, Declare]:\n+        \"\"\" A mapping from declared region names to their declarations. \"\"\"\n+        return self._declarations\n+\n     def copy_everything_except_instructions(self) -> \"Program\":\n         \"\"\"\n         Copy all the members that live on a Program object.\n@@ -293,6 +299,9 @@ def inst(self, *instructions: InstructionDesignator) -> \"Program\":\n             elif isinstance(instruction, AbstractInstruction):\n                 self._instructions.append(instruction)\n                 self._synthesized_instructions = None\n+\n+                if isinstance(instruction, Declare):\n+                    self._declarations[instruction.name] = instruction\n             else:\n                 raise TypeError(\"Invalid instruction: {}\".format(instruction))\n \n", "test_patch": "diff --git a/pyquil/tests/test_quil.py b/pyquil/tests/test_quil.py\n--- a/pyquil/tests/test_quil.py\n+++ b/pyquil/tests/test_quil.py\n@@ -243,10 +243,26 @@ def test_prog_init():\n     assert p.out() == (\"DECLARE ro BIT[1]\\nX 0\\nMEASURE 0 ro[0]\\n\")\n \n \n-def test_classical_regs():\n+def test_classical_regs_implicit_ro():\n     p = Program()\n-    p.inst(Declare(\"ro\", \"BIT\", 2), X(0)).measure(0, MemoryReference(\"ro\", 1))\n-    assert p.out() == (\"DECLARE ro BIT[2]\\nX 0\\nMEASURE 0 ro[1]\\n\")\n+    p.inst(Declare(\"reg\", \"BIT\", 2), X(0)).measure(0, MemoryReference(\"reg\", 1))\n+    assert p.out() == \"DECLARE reg BIT[2]\\nX 0\\nMEASURE 0 reg[1]\\n\"\n+    assert p.declarations == {\n+        \"ro\": Declare(\"ro\", \"BIT\", 1),\n+        \"reg\": Declare(\"reg\", \"BIT\", 2),\n+    }\n+\n+\n+def test_classical_regs_explicit_ro():\n+    p = Program()\n+    p.inst(Declare(\"ro\", \"BIT\", 2), Declare(\"reg\", \"BIT\", 2), X(0)).measure(\n+        0, MemoryReference(\"reg\", 1)\n+    )\n+    assert p.out() == \"DECLARE ro BIT[2]\\nDECLARE reg BIT[2]\\nX 0\\nMEASURE 0 reg[1]\\n\"\n+    assert p.declarations == {\n+        \"ro\": Declare(\"ro\", \"BIT\", 2),\n+        \"reg\": Declare(\"reg\", \"BIT\", 2),\n+    }\n \n \n def test_simple_instructions():\ndiff --git a/pyquil/tests/test_qvm.py b/pyquil/tests/test_qvm.py\n--- a/pyquil/tests/test_qvm.py\n+++ b/pyquil/tests/test_qvm.py\n@@ -6,6 +6,7 @@\n from pyquil import Program\n from pyquil.api import ForestConnection, QVM\n from pyquil.api._compiler import _extract_program_from_pyquil_executable_response\n+from pyquil.api._errors import QVMError\n from pyquil.gates import MEASURE, X, CNOT, H\n from pyquil.quilbase import Declare, MemoryReference\n \n@@ -55,7 +56,44 @@ def test_qvm_run_only_pqer(forest: ForestConnection):\n     assert np.mean(bitstrings) > 0.8\n \n \n-def test_qvm_run_no_measure(forest: ForestConnection):\n+def test_qvm_run_region_declared_and_measured(forest: ForestConnection):\n+    qvm = QVM(connection=forest)\n+    p = Program(Declare(\"reg\", \"BIT\"), X(0), MEASURE(0, MemoryReference(\"reg\")))\n+    nq = PyQuilExecutableResponse(program=p.out(), attributes={\"num_shots\": 100})\n+    qvm.load(nq).run().wait()\n+    bitstrings = qvm.read_memory(region_name=\"reg\")\n+    assert bitstrings.shape == (100, 1)\n+\n+\n+def test_qvm_run_region_declared_not_measured(forest: ForestConnection):\n+    qvm = QVM(connection=forest)\n+    p = Program(Declare(\"reg\", \"BIT\"), X(0))\n+    nq = PyQuilExecutableResponse(program=p.out(), attributes={\"num_shots\": 100})\n+    qvm.load(nq).run().wait()\n+    bitstrings = qvm.read_memory(region_name=\"reg\")\n+    assert bitstrings.shape == (100, 0)\n+\n+\n+# For backwards compatibility, we support omitting the declaration for \"ro\" specifically\n+def test_qvm_run_region_not_declared_is_measured_ro(forest: ForestConnection):\n+    qvm = QVM(connection=forest)\n+    p = Program(X(0), MEASURE(0, MemoryReference(\"ro\")))\n+    nq = PyQuilExecutableResponse(program=p.out(), attributes={\"num_shots\": 100})\n+    qvm.load(nq).run().wait()\n+    bitstrings = qvm.read_memory(region_name=\"ro\")\n+    assert bitstrings.shape == (100, 1)\n+\n+\n+def test_qvm_run_region_not_declared_is_measured_non_ro(forest: ForestConnection):\n+    qvm = QVM(connection=forest)\n+    p = Program(X(0), MEASURE(0, MemoryReference(\"reg\")))\n+    nq = PyQuilExecutableResponse(program=p.out(), attributes={\"num_shots\": 100})\n+\n+    with pytest.raises(QVMError, match='Bad memory region name \"reg\" in MEASURE'):\n+        qvm.load(nq).run().wait()\n+\n+\n+def test_qvm_run_region_not_declared_not_measured_ro(forest: ForestConnection):\n     qvm = QVM(connection=forest)\n     p = Program(X(0))\n     nq = PyQuilExecutableResponse(program=p.out(), attributes={\"num_shots\": 100})\n@@ -64,6 +102,14 @@ def test_qvm_run_no_measure(forest: ForestConnection):\n     assert bitstrings.shape == (100, 0)\n \n \n+def test_qvm_run_region_not_declared_not_measured_non_ro(forest: ForestConnection):\n+    qvm = QVM(connection=forest)\n+    p = Program(X(0))\n+    nq = PyQuilExecutableResponse(program=p.out(), attributes={\"num_shots\": 100})\n+    qvm.load(nq).run().wait()\n+    assert qvm.read_memory(region_name=\"reg\") is None\n+\n+\n def test_roundtrip_pyquilexecutableresponse(compiler):\n     p = Program(H(10), CNOT(10, 11))\n     pqer = compiler.native_quil_to_executable(p)\n", "problem_statement": "QVM returns only MEASURE'd memory regions\nIssue Description\r\n-----------------\r\n\r\nIn #873, we attempted to enable the QVM (and, later, the QPU) to let the user do post-execution analysis on all memory regions, rather than just on the contents of `ro`. However, in https://github.com/rigetti/pyquil/blob/master/pyquil/api/_qvm.py#L544 we filter the memory regions that the QVM returns down to only those into which it `MEASURE`s. This is unexpected behavior, and this restriction should be lifted.\r\n\r\nHow to Reproduce\r\n----------------\r\n\r\n### Code Snippet\r\n\r\n```python\r\nfrom pyquil import get_qc, Program\r\n\r\nqc = get_qc('2q-qvm') \r\nqc.run(Program(\"DECLARE ro BIT\\nDECLARE not_ro BIT\\nMOVE ro 1\\nMOVE not_ro 1\\nMEASURE 0 ro[0]\").wrap_in_numshots_loop(10)) \r\nqc.qam.read_memory(region_name=\"not_ro\")\r\n```\r\n\r\n### Error Output\r\n\r\n```\r\nKeyError: 'not_ro'\r\n```\r\n\r\nEnvironment Context\r\n-------------------\r\n\r\nOperating System: \r\n\r\nPython Version (`python -V`): Python 3.7.4\r\n\r\nQuilc Version (`quilc --version`): 1.15.3 [25b95cb]\r\n\r\nQVM Version (`qvm --version`): 1.15.2 [1b3d43a]\r\n\r\nPython Environment Details (`pip freeze` or `conda list`): ðŸ’¤\n", "hints_text": "Even within the 'ro' memory region, it only returns those indices that are written to by measurements:\r\n```\r\nfrom pyquil import Program, get_qc\r\nfrom pyquil.gates import CNOT, X, MEASURE\r\n\r\np = Program()\r\nro = p.declare(\"ro\", \"BIT\", 4)\r\np += CNOT(0, 1)\r\np += X(2)\r\np += CNOT(2, 3)\r\np += MEASURE(0, ro[0])\r\np += MEASURE(3, ro[3])\r\np.wrap_in_numshots_loop(10)\r\n\r\nqc = get_qc('9q-square-qvm')\r\nex = qc.compile(p)\r\nresult = qc.run(ex)\r\nprint(result)\r\n```\r\ngives\r\n```\r\n[[0 1]\r\n [0 1]\r\n [0 1]\r\n [0 1]\r\n [0 1]\r\n [0 1]\r\n [0 1]\r\n [0 1]\r\n [0 1]\r\n [0 1]]\r\n```\r\n(Python 3.7.7, quilc 1.18.0, qvm 1.17.0)\r\nThough it's possible cause of this case might be more linked to #1194", "created_at": 1611, "language": "python", "label": "Hard"}
{"repo": "marcelotduarte/cx_Freeze", "pull_number": 2358, "instance_id": "marcelotduarte__cx_Freeze-2358", "issue_numbers": ["2354"], "base_commit": "de2888d31d344c3d50994c4ecaaeb668bcc9b095", "patch": "diff --git a/cx_Freeze/hooks/numpy.py b/cx_Freeze/hooks/numpy.py\n--- a/cx_Freeze/hooks/numpy.py\n+++ b/cx_Freeze/hooks/numpy.py\n@@ -87,6 +87,20 @@ def load_numpy_core__add_newdocs(\n     finder.include_module(\"numpy.core._multiarray_tests\")\n \n \n+def load_numpy_core_overrides(finder: ModuleFinder, module: Module) -> None:\n+    \"\"\"Recompile the numpy.core.overrides module to limit optimization by\n+    avoiding removing docstrings, which are required for this module.\n+    \"\"\"\n+    code_string = module.file.read_text(encoding=\"utf_8\")\n+    module.code = compile(\n+        code_string.replace(\"dispatcher.__doc__\", \"dispatcher.__doc__ or ''\"),\n+        os.fspath(module.file),\n+        \"exec\",\n+        dont_inherit=True,\n+        optimize=min(finder.optimize, 1),\n+    )\n+\n+\n def load_numpy__distributor_init(finder: ModuleFinder, module: Module) -> None:\n     \"\"\"Fix the location of dependent files in Windows and macOS.\"\"\"\n     if IS_LINUX or IS_MINGW:\n", "test_patch": "diff --git a/tests/test_hooks_pandas.py b/tests/test_hooks_pandas.py\n--- a/tests/test_hooks_pandas.py\n+++ b/tests/test_hooks_pandas.py\n@@ -24,7 +24,7 @@\n @pytest.mark.datafiles(SAMPLES_DIR / \"pandas\")\n def test_pandas(datafiles: Path) -> None:\n     \"\"\"Test that the pandas/numpy is working correctly.\"\"\"\n-    output = run_command(datafiles)\n+    output = run_command(datafiles, \"python setup.py build_exe -O2\")\n     executable = datafiles / BUILD_EXE_DIR / f\"test_pandas{SUFFIX}\"\n     assert executable.is_file()\n \n", "problem_statement": "cx_Freeze 7.0.0 and PyTorch 2.2.2+cu118: TypeError: argument docstring of add_docstring should be a str\n**Describe the bug**\r\nAn error occurs when try to freeze pytorch project with cx-Freeze.\r\n\r\n```\r\ncopying C:\\Project\\_build\\venv\\lib\\site-packages\\torch\\functional.py -> C:\\Project\\_build\\out\\lib\\torch\\functional.py\r\nTraceback (most recent call last):\r\n  File \"C:\\Project\\_build\\venv\\Lib\\site-packages\\cx_Freeze\\initscripts\\__startup__.py\", line 138, in run\r\n    module_init.run(name + \"__main__\")\r\n  File \"C:\\Project\\_build\\venv\\Lib\\site-packages\\cx_Freeze\\initscripts\\console.py\", line 17, in run\r\n    exec(code, module_main.__dict__)\r\n  File \"project.py\", line 1, in <module>\r\n    import torch\r\n  File \"C:/Users/bw7715/OneDrive - Zebra Technologies/Projects/python_projects/cx_freeze_issues/p39_cx70_tf_np/_build/venv/lib/site-packages/torch/__init__.py\", line 1215, in <module>\r\n    from .storage import _StorageBase, TypedStorage, _LegacyStorage, UntypedStorage, _warn_typed_storage_removal\r\n  File \"C:\\Project\\_build\\venv\\lib\\site-packages\\torch\\storage.py\", line 14, in <module>\r\n    import numpy as np\r\n  File \"C:\\Project\\_build\\venv\\lib\\site-packages\\numpy\\__init__.py\", line 173, in <module>\r\n    from . import core\r\n  File \"C:\\Project\\_build\\venv\\lib\\site-packages\\numpy\\core\\__init__.py\", line 24, in <module>\r\n    from . import multiarray\r\n  File \"C:\\Project\\_build\\venv\\lib\\site-packages\\numpy\\core\\multiarray.py\", line 86, in <module>\r\n    def empty_like(prototype, dtype=None, order=None, subok=None, shape=None):\r\n  File \"C:\\Project\\_build\\venv\\lib\\site-packages\\numpy\\core\\overrides.py\", line 178, in decorator\r\n    return array_function_dispatch(\r\n  File \"C:\\Project\\_build\\venv\\lib\\site-packages\\numpy\\core\\overrides.py\", line 158, in decorator\r\n    add_docstring(implementation, dispatcher.__doc__)\r\nTypeError: argument docstring of add_docstring should be a str\r\n```\r\n\r\n**To Reproduce**\r\nrequirements.txt\r\n```\r\n--find-links https://download.pytorch.org/whl/cu118/torch_stable.html\r\n\r\ncx_Freeze==7.0.0\r\ntorch==2.2.2+cu118\r\ntorchvision==0.17.2+cu118\r\n```\r\n\r\nfreeze.bat\r\n```\r\necho off\r\nset WORKSPACE=%~dp0\r\n\r\nset BUILD_DIRPATH=%WORKSPACE%\\_build\r\nset BASE_PYTHON_DIRPATH=C:\\Program Files\\Python39\r\n\r\nset VENV_DIRPATH=%BUILD_DIRPATH%\\venv\r\nset TARGET_DIR=%BUILD_DIRPATH%\\out\r\n\r\nset SCRIPTS_DIRPATH=%VENV_DIRPATH%\\Scripts\r\nset PYTHON_EXE_PATH=\"%SCRIPTS_DIRPATH%\\python.exe\"\r\nset FREEZER_EXE_PATH=\"%SCRIPTS_DIRPATH%\\cxfreeze.exe\"\r\n\r\nset TARGET_NAME=project_out.exe\r\nset PROJECT_SOURCE_PY_PATH=project.py\r\n\r\nset PACKAGES=torch\r\n\r\n\r\n\"%BASE_PYTHON_DIRPATH%\\python\" -m venv \"%VENV_DIRPATH%\"\r\n%PYTHON_EXE_PATH% -m pip install -r requirements.txt\r\n\r\nrem %PYTHON_EXE_PATH% -m pip install --pre --extra-index-url https://marcelotduarte.github.io/packages/ cx_Freeze --upgrade\r\n\r\n%FREEZER_EXE_PATH% build -O1 -O2 --include-msvcr --build-exe=\"%TARGET_DIR%\" --target-name=%TARGET_NAME% --packages=%PACKAGES% --script=%PROJECT_SOURCE_PY_PATH%\r\n\r\n\r\n\"%TARGET_DIR%\\%TARGET_NAME%\"\r\n```\r\n\r\nproject.py\r\n```python\r\nimport torch\r\n\r\nprint(torch.__version__)\r\n```\r\n\r\n\r\n**Desktop (please complete the following information):**\r\n - Platform information: Windows 10  and  Ubuntu Linux 22.04\r\n - OS architecture (e.g. amd64): 64bit\r\n - cx_Freeze version: 7.0.0\r\n - Python version: 3.9\r\n\r\npip list:\r\n```\r\n.\\python.exe -m pip list\r\nPackage           Version\r\n----------------- ------------\r\ncx_Freeze         7.0.0\r\ncx_Logging        3.2.0\r\nfilelock          3.13.4\r\nfsspec            2024.3.1\r\nJinja2            3.1.3\r\nlief              0.14.1\r\nMarkupSafe        2.1.5\r\nmpmath            1.3.0\r\nnetworkx          3.2.1\r\nnumpy             1.26.4\r\npillow            10.3.0\r\npip               22.0.4\r\nsetuptools        69.5.1\r\nsympy             1.12\r\ntorch             2.2.2+cu118\r\ntorchvision       0.17.2+cu118\r\ntyping_extensions 4.11.0\r\nwheel             0.43.0\r\n```\r\n\r\nWith `cx_Freeze==6.15.16` this project works.\n", "hints_text": "When try to use `pip install --force --no-cache --pre --extra-index-url https://marcelotduarte.github.io/packages/ cx_Freeze` with  `cx_Freeze-7.1.0.dev3-cp39-cp39-win_amd64` I get the same error.\nI noticed also that with `cx_Freeze-7.1.0.dev3` there is an error during freezing:\r\n```\r\nLooking in indexes: https://pypi.org/simple, https://marcelotduarte.github.io/packages/\r\nCollecting cx_Freeze\r\n  Downloading https://marcelotduarte.github.io/packages/cx-freeze/cx_Freeze-7.1.0.dev3-cp39-cp39-win_amd64.whl (2.0 MB)\r\n     ---------------------------------------- 2.0/2.0 MB 1.4 MB/s eta 0:00:00\r\nCollecting wheel<=0.43.0,>=0.42.0\r\n  Downloading wheel-0.43.0-py3-none-any.whl (65 kB)\r\n     ---------------------------------------- 65.8/65.8 KB 107.6 kB/s eta 0:00:00\r\nCollecting setuptools<70,>=62.6\r\n  Downloading setuptools-69.5.1-py3-none-any.whl (894 kB)\r\n     ---------------------------------------- 894.6/894.6 KB 1.2 MB/s eta 0:00:00\r\nCollecting lief<=0.15.0,>=0.12.0\r\n  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))': /latest/lief/lief-0.15.0-cp39-cp39-win_amd64.whl\r\n  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))': /latest/lief/lief-0.15.0-cp39-cp39-win_amd64.whl\r\n  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))': /latest/lief/lief-0.15.0-cp39-cp39-win_amd64.whl\r\n  WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))': /latest/lief/lief-0.15.0-cp39-cp39-win_amd64.whl\r\n  WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)'))': /latest/lief/lief-0.15.0-cp39-cp39-win_amd64.whl\r\nERROR: Could not install packages due to an OSError: HTTPSConnectionPool(host='lief.s3-website.fr-par.scw.cloud', port=443): Max retries exceeded with url: /latest/lief/lief-0.15.0-cp39-cp39-win_amd64.whl (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\r\n```\r\n\r\nBut once it has appeared, the process goes on.\r\n\r\n\r\n\r\nIn version 7.0.0 these errors and warnings do not appear \r\n```\r\nLooking in links: https://download.pytorch.org/whl/cu118/torch_stable.html\r\nCollecting cx_Freeze==7.0.0\r\n  Using cached cx_Freeze-7.0.0-cp39-cp39-win_amd64.whl (2.0 MB)\r\nCollecting numpy==1.26.4\r\n  Using cached numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\r\nCollecting torch==2.2.2+cu118\r\n  Using cached https://download.pytorch.org/whl/cu118/torch-2.2.2%2Bcu118-cp39-cp39-win_amd64.whl (2704.2 MB)\r\nCollecting torchvision==0.17.2+cu118\r\n  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.17.2%2Bcu118-cp39-cp39-win_amd64.whl (4.9 MB)\r\nCollecting lief<0.15.0,>=0.12.0\r\n  Using cached lief-0.14.1-cp39-cp39-win_amd64.whl (2.2 MB)\r\nCollecting cx-Logging>=3.1\r\n  Using cached cx_Logging-3.2.0-cp39-cp39-win_amd64.whl (26 kB)\r\n```\n> TypeError: argument docstring of add_docstring should be a str\r\n\r\nI had already commented [here](https://github.com/marcelotduarte/cx_Freeze/issues/2280#issuecomment-1980922796):\r\n\"\"\"\r\nnumpy uses its docstring, so remove the optimization that it works. The optimization works like described [here](https://docs.python.org/3/using/cmdline.html#cmdoption-O).\r\nSee also: https://github.com/numpy/numpy/issues/13248#issuecomment-480412876\r\n\"\"\"\r\nAnd complementing the comment, I can say that in the previous version, when you used -O -OO in reality only -O ended up being used and it gave you the impression of using complete optimization. Therefore with numpy only -O1 can be used. I'll see if there's a way to restrict the optimization to just the numpy module.\r\n\r\n> ERROR: Could not install packages due to an OSError: HTTPSConnectionPool(host='lief.s3-website.fr-par.scw.cloud', ...\r\n\r\nThis is a server error when the protocols, certificates, have nothing to do with cx_Freeze. Alias is a pip command.\r\n", "created_at": 1714, "language": "python", "label": "Easy"}
{"repo": "pytest-dev/pytest-django", "pull_number": 680, "instance_id": "pytest-dev__pytest-django-680", "issue_numbers": ["678"], "base_commit": "c1bdb8d61498f472f27b4233ea50ffa2bce42147", "patch": "diff --git a/pytest_django/fixtures.py b/pytest_django/fixtures.py\n--- a/pytest_django/fixtures.py\n+++ b/pytest_django/fixtures.py\n@@ -33,35 +33,35 @@\n \n \n @pytest.fixture(scope=\"session\")\n-def django_db_modify_db_settings_xdist_suffix(request):\n+def django_db_modify_db_settings_tox_suffix(request):\n     skip_if_no_django()\n \n-    from django.conf import settings\n-\n-    for db_settings in settings.DATABASES.values():\n-\n-        try:\n-            test_name = db_settings[\"TEST\"][\"NAME\"]\n-        except KeyError:\n-            test_name = None\n+    tox_environment = os.getenv(\"TOX_PARALLEL_ENV\")\n+    if tox_environment:\n+        # Put a suffix like _py27-django21 on tox workers\n+        _set_suffix_to_test_databases(suffix=tox_environment)\n \n-        if not test_name:\n-            if db_settings[\"ENGINE\"] == \"django.db.backends.sqlite3\":\n-                continue\n \n-            test_name = \"test_{}\".format(db_settings[\"NAME\"])\n+@pytest.fixture(scope=\"session\")\n+def django_db_modify_db_settings_xdist_suffix(request):\n+    skip_if_no_django()\n \n+    xdist_suffix = getattr(request.config, \"slaveinput\", {}).get(\"slaveid\")\n+    if xdist_suffix:\n         # Put a suffix like _gw0, _gw1 etc on xdist processes\n-        xdist_suffix = getattr(request.config, \"slaveinput\", {}).get(\"slaveid\")\n-        if test_name != \":memory:\" and xdist_suffix is not None:\n-            test_name = \"{}_{}\".format(test_name, xdist_suffix)\n+        _set_suffix_to_test_databases(suffix=xdist_suffix)\n \n-        db_settings.setdefault(\"TEST\", {})\n-        db_settings[\"TEST\"][\"NAME\"] = test_name\n+\n+@pytest.fixture(scope=\"session\")\n+def django_db_modify_db_settings_parallel_suffix(\n+    django_db_modify_db_settings_tox_suffix,\n+    django_db_modify_db_settings_xdist_suffix,\n+):\n+    skip_if_no_django()\n \n \n @pytest.fixture(scope=\"session\")\n-def django_db_modify_db_settings(django_db_modify_db_settings_xdist_suffix):\n+def django_db_modify_db_settings(django_db_modify_db_settings_parallel_suffix):\n     skip_if_no_django()\n \n \n@@ -169,6 +169,24 @@ def handle(self, *args, **kwargs):\n     migrate.Command = MigrateSilentCommand\n \n \n+def _set_suffix_to_test_databases(suffix):\n+    from django.conf import settings\n+\n+    for db_settings in settings.DATABASES.values():\n+        test_name = db_settings.get(\"TEST\", {}).get(\"NAME\")\n+\n+        if not test_name:\n+            if db_settings[\"ENGINE\"] == \"django.db.backends.sqlite3\":\n+                continue\n+            test_name = \"test_{}\".format(db_settings[\"NAME\"])\n+\n+        if test_name == \":memory:\":\n+            continue\n+\n+        db_settings.setdefault(\"TEST\", {})\n+        db_settings[\"TEST\"][\"NAME\"] = \"{}_{}\".format(test_name, suffix)\n+\n+\n # ############### User visible fixtures ################\n \n \ndiff --git a/pytest_django/plugin.py b/pytest_django/plugin.py\n--- a/pytest_django/plugin.py\n+++ b/pytest_django/plugin.py\n@@ -22,6 +22,8 @@\n from .fixtures import django_db_keepdb  # noqa\n from .fixtures import django_db_createdb  # noqa\n from .fixtures import django_db_modify_db_settings  # noqa\n+from .fixtures import django_db_modify_db_settings_parallel_suffix  # noqa\n+from .fixtures import django_db_modify_db_settings_tox_suffix  # noqa\n from .fixtures import django_db_modify_db_settings_xdist_suffix  # noqa\n from .fixtures import _live_server_helper  # noqa\n from .fixtures import admin_client  # noqa\n", "test_patch": "diff --git a/tests/test_db_setup.py b/tests/test_db_setup.py\n--- a/tests/test_db_setup.py\n+++ b/tests/test_db_setup.py\n@@ -288,7 +288,135 @@ def test_a():\n \n                 assert conn_db2.vendor == 'sqlite'\n                 db_name = conn_db2.creation._get_test_db_name()\n-                assert 'test_custom_db_name_gw' in db_name\n+                assert db_name.startswith('test_custom_db_name_gw')\n+        \"\"\"\n+        )\n+\n+        result = django_testdir.runpytest_subprocess(\"--tb=short\", \"-vv\", \"-n1\")\n+        assert result.ret == 0\n+        result.stdout.fnmatch_lines([\"*PASSED*test_a*\"])\n+\n+\n+class TestSqliteWithTox:\n+\n+    db_settings = {\n+        \"default\": {\n+            \"ENGINE\": \"django.db.backends.sqlite3\",\n+            \"NAME\": \"db_name\",\n+            \"TEST\": {\"NAME\": \"test_custom_db_name\"},\n+        }\n+    }\n+\n+    def test_db_with_tox_suffix(self, django_testdir, monkeypatch):\n+        \"A test to check that Tox DB suffix works when running in parallel.\"\n+        monkeypatch.setenv(\"TOX_PARALLEL_ENV\", \"py37-django22\")\n+\n+        django_testdir.create_test_module(\n+            \"\"\"\n+            import pytest\n+            from django.db import connections\n+\n+            @pytest.mark.django_db\n+            def test_inner():\n+\n+                (conn, ) = connections.all()\n+\n+                assert conn.vendor == 'sqlite'\n+                db_name = conn.creation._get_test_db_name()\n+                assert db_name == 'test_custom_db_name_py37-django22'\n+        \"\"\"\n+        )\n+\n+        result = django_testdir.runpytest_subprocess(\"--tb=short\", \"-vv\")\n+        assert result.ret == 0\n+        result.stdout.fnmatch_lines([\"*test_inner*PASSED*\"])\n+\n+    def test_db_with_empty_tox_suffix(self, django_testdir, monkeypatch):\n+        \"A test to check that Tox DB suffix is not used when suffix would be empty.\"\n+        monkeypatch.setenv(\"TOX_PARALLEL_ENV\", \"\")\n+\n+        django_testdir.create_test_module(\n+            \"\"\"\n+            import pytest\n+            from django.db import connections\n+\n+            @pytest.mark.django_db\n+            def test_inner():\n+\n+                (conn,) = connections.all()\n+\n+                assert conn.vendor == 'sqlite'\n+                db_name = conn.creation._get_test_db_name()\n+                assert db_name == 'test_custom_db_name'\n+        \"\"\"\n+        )\n+\n+        result = django_testdir.runpytest_subprocess(\"--tb=short\", \"-vv\")\n+        assert result.ret == 0\n+        result.stdout.fnmatch_lines([\"*test_inner*PASSED*\"])\n+\n+\n+class TestSqliteWithToxAndXdist:\n+\n+    db_settings = {\n+        \"default\": {\n+            \"ENGINE\": \"django.db.backends.sqlite3\",\n+            \"NAME\": \"db_name\",\n+            \"TEST\": {\"NAME\": \"test_custom_db_name\"},\n+        }\n+    }\n+\n+    def test_db_with_tox_suffix(self, django_testdir, monkeypatch):\n+        \"A test to check that both Tox and xdist suffixes work together.\"\n+        pytest.importorskip(\"xdist\")\n+        monkeypatch.setenv(\"TOX_PARALLEL_ENV\", \"py37-django22\")\n+\n+        django_testdir.create_test_module(\n+            \"\"\"\n+            import pytest\n+            from django.db import connections\n+\n+            @pytest.mark.django_db\n+            def test_inner():\n+\n+                (conn, ) = connections.all()\n+\n+                assert conn.vendor == 'sqlite'\n+                db_name = conn.creation._get_test_db_name()\n+                assert db_name.startswith('test_custom_db_name_py37-django22_gw')\n+        \"\"\"\n+        )\n+\n+        result = django_testdir.runpytest_subprocess(\"--tb=short\", \"-vv\", \"-n1\")\n+        assert result.ret == 0\n+        result.stdout.fnmatch_lines([\"*PASSED*test_inner*\"])\n+\n+\n+class TestSqliteInMemoryWithXdist:\n+\n+    db_settings = {\n+        \"default\": {\n+            \"ENGINE\": \"django.db.backends.sqlite3\",\n+            \"NAME\": \":memory:\",\n+            \"TEST\": {\"NAME\": \":memory:\"},\n+        }\n+    }\n+\n+    def test_sqlite_in_memory_used(self, django_testdir):\n+        pytest.importorskip(\"xdist\")\n+\n+        django_testdir.create_test_module(\n+            \"\"\"\n+            import pytest\n+            from django.db import connections\n+\n+            @pytest.mark.django_db\n+            def test_a():\n+                (conn, ) = connections.all()\n+\n+                assert conn.vendor == 'sqlite'\n+                db_name = conn.creation._get_test_db_name()\n+                assert 'file:memorydb' in db_name or db_name == ':memory:'\n         \"\"\"\n         )\n \n", "problem_statement": "Correctly support DB access in parallel Tox testing\nHi!\r\n\r\nRecently, I have migrated some Django projects to run their tests using [Tox](https://tox.readthedocs.io/en/latest/index.html). Because of the number of tests and Tox environments, it was configured to run tests in parallel. This required a similar approach as what's currently handled by `pytest-django` when running tests with `pytest-xdist`: **Database renaming to avoid collisions**.\r\n\r\nA simple fixture like `django_db_modify_db_settings_xdist_suffix`, to add a suffix to database names, was enough to fix database collisions, so I wonder if `pytest-django` should also handle Tox testing in these scenarios. And, now more than ever, with Tox implementing real support for [parallel execution](https://github.com/tox-dev/tox/pull/1102).\r\n\r\nI have the time to work on this, and provide what I've implemented so far, if this request is accepted!\n", "hints_text": "Yes, it makes sense to use something like `django_db_modify_db_settings_tox_suffix` for this.\r\nBut maybe there could be a single `*_suffix` then?\r\nIt should also handle xdist in parallel tox then.\nI think it depends on how Pytest's fixture resolution order works. If it's deterministic (by design, and this contract won't change), I think that separate fixtures make sense. If not, a single `django_db_modify_db_settings_parallel_suffix` could be enough to avoid different DB names with each run.", "created_at": 1545, "language": "python", "label": "Easy"}
{"repo": "rigetti/pyquil", "pull_number": 203, "instance_id": "rigetti__pyquil-203", "issue_numbers": ["138"], "base_commit": "4229a22f98c37967635fbe7b29fcfadde2aea7d8", "patch": "diff --git a/pyquil/quilbase.py b/pyquil/quilbase.py\n--- a/pyquil/quilbase.py\n+++ b/pyquil/quilbase.py\n@@ -261,7 +261,7 @@ def format_matrix_element(element):\n \n             :param element: {int, float, complex, str} The parameterized element to format.\n             \"\"\"\n-            if isinstance(element, integer_types) or isinstance(element, (float, complex)):\n+            if isinstance(element, integer_types) or isinstance(element, (float, complex, np.int_)):\n                 return format_parameter(element)\n             elif isinstance(element, string_types):\n                 return element\n@@ -514,7 +514,7 @@ def format_parameter(element):\n \n     :param element: {int, float, long, complex, Slot} Formats a parameter for Quil output.\n     \"\"\"\n-    if isinstance(element, integer_types):\n+    if isinstance(element, integer_types) or isinstance(element, np.int_):\n         return repr(element)\n     elif isinstance(element, float):\n         return check_for_pi(element)\n", "test_patch": "diff --git a/pyquil/tests/test_quil.py b/pyquil/tests/test_quil.py\n--- a/pyquil/tests/test_quil.py\n+++ b/pyquil/tests/test_quil.py\n@@ -582,3 +582,10 @@ def test_pretty_print_pi():\n     assert p.out() == 'RZ(0) 0\\nRZ(pi) 1\\nRZ(-pi) 2\\nRZ(2*pi/3) 3\\n' \\\n                       'RZ(0.3490658503988659) 4\\n' \\\n                       'RZ(pi/8) 5\\nCPHASE00(-45*pi) 0 1\\n'\n+\n+\n+# https://github.com/rigetticomputing/pyquil/issues/138\n+def test_defgate_integer_input():\n+    dg = DefGate(\"TEST\", np.array([[1, 0],\n+                                   [0, 1]]))\n+    assert dg.out() == \"DEFGATE TEST:\\n    1, 0\\n    0, 1\\n\"\n", "problem_statement": "Creating a gate with all integers throws an error\n```python\r\n>>> DefGate(\"A\", np.array([[1, 0], [0, 1]])).out()\r\n```\r\n\r\nthrows the following error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/steven/workspace/pyquil/pyquil/quilbase.py\", line 208, in out\r\n    fcols = [format_matrix_element(col) for col in row]\r\n  File \"/Users/steven/workspace/pyquil/pyquil/quilbase.py\", line 208, in <listcomp>\r\n    fcols = [format_matrix_element(col) for col in row]\r\n  File \"/Users/steven/workspace/pyquil/pyquil/quilbase.py\", line 68, in format_matrix_element\r\n    assert False, \"Invalid matrix element: %r\" % element\r\nAssertionError: Invalid matrix element: 1\r\n```\r\n\r\nThe type of the integer in a numpy array of all ints is unexpected:\r\n```python\r\n>>> type(np.array([[1, 0], [0, 1]])[0][0])\r\n<class 'numpy.int64'>\r\n```\n", "hints_text": "That is strange, it works for me.\r\n\r\n![screen shot 2017-10-09 at 7 05 08 pm](https://user-images.githubusercontent.com/21032071/31340931-6a86d834-ad25-11e7-8bf3-8b46aee3676a.png)\r\n\nWhat's the different numpy versions?\nMine is 1.13.3\nMight be a Python version thing. I'm on Python 3, numpy 1.13.3\nI'm also affected by this. numpy 1.13.0, python 3.6.1 .", "created_at": 1511, "language": "python", "label": "Hard"}
{"repo": "rigetti/pyquil", "pull_number": 221, "instance_id": "rigetti__pyquil-221", "issue_numbers": ["212"], "base_commit": "6890be97d997a3c3a38ddb36899cfb5677446194", "patch": "diff --git a/pyquil/api/__init__.py b/pyquil/api/__init__.py\n--- a/pyquil/api/__init__.py\n+++ b/pyquil/api/__init__.py\n@@ -18,7 +18,7 @@\n \"\"\"\n import warnings\n \n-__all__ = ['QVMConnection', 'QPUConnection', 'Job', 'get_devices']\n+__all__ = ['QVMConnection', 'QPUConnection', 'Job', 'get_devices', 'errors']\n \n from pyquil.api.job import Job\n from pyquil.api.qvm import QVMConnection\ndiff --git a/pyquil/api/_base_connection.py b/pyquil/api/_base_connection.py\n--- a/pyquil/api/_base_connection.py\n+++ b/pyquil/api/_base_connection.py\n@@ -16,6 +16,8 @@\n \n from __future__ import print_function\n \n+import re\n+\n import requests\n import sys\n \n@@ -24,6 +26,8 @@\n from six import integer_types\n from urllib3 import Retry\n \n+from pyquil.api.errors import QVMError, DeviceOfflineError, DeviceRetuningError, InvalidInputError, InvalidUserError, \\\n+    JobNotFoundError, MissingPermissionsError, error_mapping, UnknownApiError, TooManyQubitsError\n from .job import Job\n from ._config import PyquilConfig\n \n@@ -33,127 +37,102 @@\n TYPE_WAVEFUNCTION = \"wavefunction\"\n \n \n-class BaseConnection(object):\n-    def __init__(self, async_endpoint, api_key, user_id, ping_time, status_time):\n-        self._session = requests.Session()\n-        retry_adapter = HTTPAdapter(max_retries=Retry(total=3,\n-                                                      method_whitelist=['POST'],\n-                                                      status_forcelist=[502, 503, 504, 521, 523],\n-                                                      backoff_factor=0.2,\n-                                                      raise_on_status=False))\n-\n-        # We need this to get binary payload for the wavefunction call.\n-        self._session.headers.update({\"Accept\": \"application/octet-stream\"})\n-\n-        self._session.mount(\"http://\", retry_adapter)\n-        self._session.mount(\"https://\", retry_adapter)\n-\n-        config = PyquilConfig()\n-        self.api_key = api_key if api_key else config.api_key\n-        self.user_id = user_id if user_id else config.user_id\n-\n-        self.async_endpoint = async_endpoint\n-\n-        self.ping_time = ping_time\n-        self.status_time = status_time\n-\n-    def get_job(self, job_id):\n-        \"\"\"\n-        Given a job id, return information about the status of the job\n-\n-        :param str job_id: job id\n-        :return: Job object with the status and potentially results of the job\n-        :rtype: Job\n-        \"\"\"\n-        response = self._get_json(self.async_endpoint + \"/job/\" + job_id)\n-        return Job(response.json())\n-\n-    def wait_for_job(self, job_id, ping_time=None, status_time=None):\n-        \"\"\"\n-        Wait for the results of a job and periodically print status\n-\n-        :param job_id: Job id\n-        :param ping_time: How often to poll the server.\n-                          Defaults to the value specified in the constructor. (0.1 seconds)\n-        :param status_time: How often to print status, set to False to never print status.\n-                            Defaults to the value specified in the constructor (2 seconds)\n-        :return: Completed Job\n-        \"\"\"\n-        if ping_time is None:\n-            ping_time = self.ping_time\n-        if status_time is None:\n-            status_time = self.status_time\n-\n-        count = 0\n-        while True:\n-            job = self.get_job(job_id)\n-            if job.is_done():\n-                break\n-\n-            if status_time and count % int(status_time / ping_time) == 0:\n-                if job.is_queued():\n-                    print(\"job {} is currently queued at position {}\".format(job.job_id, job.position_in_queue()))\n-                elif job.is_running():\n-                    print(\"job {} is currently running\".format(job.job_id))\n-\n-            time.sleep(ping_time)\n-            count += 1\n-\n-        return job\n-\n-    def _post_json(self, url, json):\n-        \"\"\"\n-        Post JSON to the Forest endpoint.\n-\n-        :param str url: The full url to post to\n-        :param dict json: JSON.\n-        :return: A non-error response.\n-        \"\"\"\n-        headers = {\n-            'X-Api-Key': self.api_key,\n-            'X-User-Id': self.user_id,\n-            'Content-Type': 'application/json; charset=utf-8'\n-        }\n-        res = self._session.post(url, json=json, headers=headers)\n-\n-        # Print some nice info for unauthorized/permission errors.\n-        if res.status_code == 401 or res.status_code == 403:\n-            print(\"! ERROR:\\n\"\n-                  \"!   There was an issue validating your forest account.\\n\"\n-                  \"!   Have you run the pyquil-config-setup command yet?\\n\"\n-                  \"! The server came back with the following information:\\n\"\n-                  \"%s\\n%s\\n%s\" % (\"=\" * 80, res.text, \"=\" * 80), file=sys.stderr)\n-            print(\"! If you suspect this to be a bug in pyQuil or Rigetti Forest,\\n\"\n-                  \"! then please describe the problem in a GitHub issue at:\\n!\\n\"\n-                  \"!      https://github.com/rigetticomputing/pyquil/issues\\n\", file=sys.stderr)\n-\n-        # Print some nice info for invalid input or internal server errors.\n-        if res.status_code == 400 or res.status_code >= 500:\n-            print(\"! ERROR:\\n\"\n-                  \"!   Server caught an error. This could be due to a bug in the server\\n\"\n-                  \"!   or a bug in your code. The server came back with the following\\n\"\n-                  \"!   information:\\n\"\n-                  \"%s\\n%s\\n%s\" % (\"=\" * 80, res.text, \"=\" * 80), file=sys.stderr)\n-            print(\"! If you suspect this to be a bug in pyQuil or Rigetti Forest,\\n\"\n-                  \"! then please describe the problem in a GitHub issue at:\\n!\\n\"\n-                  \"!      https://github.com/rigetticomputing/pyquil/issues\\n\", file=sys.stderr)\n-\n-        res.raise_for_status()\n-        return res\n-\n-    def _get_json(self, url):\n-        \"\"\"\n-        Get JSON from a Forest endpoint.\n-\n-        :param str url: The full url to fetch\n-        :return: Response object\n-        \"\"\"\n-        headers = {\n-            'X-Api-Key': self.api_key,\n-            'X-User-Id': self.user_id,\n-            'Content-Type': 'application/json; charset=utf-8'\n-        }\n-        return requests.get(url, headers=headers)\n+def wait_for_job(get_job_fn, ping_time=None, status_time=None):\n+    \"\"\"\n+    Wait for job logic\n+    \"\"\"\n+    count = 0\n+    while True:\n+        job = get_job_fn()\n+        if job.is_done():\n+            break\n+\n+        if status_time and count % int(status_time / ping_time) == 0:\n+            if job.is_queued():\n+                print(\"job {} is currently queued at position {}\".format(job.job_id, job.position_in_queue()))\n+            elif job.is_running():\n+                print(\"job {} is currently running\".format(job.job_id))\n+\n+        time.sleep(ping_time)\n+        count += 1\n+\n+    return job\n+\n+\n+def get_json(session, url):\n+    \"\"\"\n+    Get JSON from a Forest endpoint.\n+    \"\"\"\n+    res = session.get(url)\n+    if res.status_code >= 400:\n+        raise parse_error(res)\n+    return res\n+\n+\n+def post_json(session, url, json):\n+    \"\"\"\n+    Post JSON to the Forest endpoint.\n+    \"\"\"\n+    res = session.post(url, json=json)\n+    if res.status_code >= 400:\n+        raise parse_error(res)\n+    return res\n+\n+\n+def parse_error(res):\n+    \"\"\"\n+    Every server error should contain a \"status\" field with a human readable explanation of what went wrong as well as\n+    a \"error_type\" field indicating the kind of error that can be mappen to a Python type.\n+\n+    There's a fallback error UnknownError for other types of exceptions (network issues, api gateway problems, etc.)\n+    \"\"\"\n+    body = res.json()\n+\n+    if body is None:\n+        raise UnknownApiError(res.text)\n+    elif 'error_type' not in body:\n+        raise UnknownApiError(body)\n+\n+    error_type = body['error_type']\n+    status = body['status']\n+\n+    if re.search(r\"[0-9]+ qubits were requested, but the QVM is limited to [0-9]+ qubits.\", status):\n+        return TooManyQubitsError(status)\n+\n+    error_cls = error_mapping.get(error_type, UnknownApiError)\n+    return error_cls(status)\n+\n+\n+def get_session(api_key, user_id):\n+    \"\"\"\n+    Create a requests session to access the cloud API with the proper authentication\n+\n+    :param str api_key: custom api key, if None will fallback to reading from the config\n+    :param str user_id: custom user id, if None will fallback to reading from the config\n+    :return: requests session\n+    :rtype: Session\n+    \"\"\"\n+    session = requests.Session()\n+    retry_adapter = HTTPAdapter(max_retries=Retry(total=3,\n+                                                  method_whitelist=['POST'],\n+                                                  status_forcelist=[502, 503, 504, 521, 523],\n+                                                  backoff_factor=0.2,\n+                                                  raise_on_status=False))\n+\n+    session.mount(\"http://\", retry_adapter)\n+    session.mount(\"https://\", retry_adapter)\n+\n+    # We need this to get binary payload for the wavefunction call.\n+    session.headers.update({\"Accept\": \"application/octet-stream\"})\n+\n+    config = PyquilConfig()\n+    session.headers.update({\n+        'X-Api-Key': api_key if api_key else config.api_key,\n+        'X-User-Id': user_id if user_id else config.user_id,\n+        'Content-Type': 'application/json; charset=utf-8'\n+    })\n+\n+    return session\n \n \n def validate_noise_probabilities(noise_parameter):\ndiff --git a/pyquil/api/errors.py b/pyquil/api/errors.py\nnew file mode 100644\n--- /dev/null\n+++ b/pyquil/api/errors.py\n@@ -0,0 +1,142 @@\n+\n+class ApiError(Exception):\n+    def __init__(self, server_status, explanation):\n+        super(ApiError, self).__init__(self, server_status)\n+        self.server_status = server_status\n+        self.explanation = explanation\n+\n+    def __repr__(self):\n+        return repr(str(self))\n+\n+    def __str__(self):\n+        return self.server_status + \"\\n\" + self.explanation\n+\n+\n+class CancellationError(ApiError):\n+    def __init__(self, server_status):\n+        explanation = \"Please try resubmitting the job again.\"\n+        super(CancellationError, self).__init__(server_status, explanation)\n+\n+\n+class DeviceOfflineError(ApiError):\n+    def __init__(self, server_status):\n+        explanation = \"\"\"\n+The device you requested is offline. Use the following code to check for the\n+currently available devices:\n+\n+    from pyquil.api import get_devices\n+    print(get_devices())\"\"\"\n+        super(DeviceOfflineError, self).__init__(server_status, explanation)\n+\n+\n+class DeviceRetuningError(ApiError):\n+    def __init__(self, server_status):\n+        explanation = \"\"\"\n+The device you requested is temporarily down for retuning. Use the following\n+code to check for the currently available devices:\n+\n+    from pyquil.api import get_devices\n+    print(get_devices())\"\"\"\n+        super(DeviceRetuningError, self).__init__(server_status, explanation)\n+        ApiError.__init__(self, server_status, explanation)\n+\n+\n+class InvalidInputError(ApiError):\n+    def __init__(self, server_status):\n+        explanation = \"\"\"\n+The server returned the above error because something was wrong with the HTTP\n+request sent to it. This could be due to a bug in the server or a bug in your\n+code. If you suspect this to be a bug in pyQuil or Rigetti Forest, then please\n+describe the problem in a GitHub issue at:\n+    https://github.com/rigetticomputing/pyquil/issues\"\"\"\n+        super(InvalidInputError, self).__init__(server_status, explanation)\n+        ApiError.__init__(self, server_status, explanation)\n+\n+\n+class InvalidUserError(ApiError):\n+    def __init__(self, server_status):\n+        explanation = \"\"\"\n+There was an issue validating your Forest account!\n+Have you run the `pyquil-config-setup` command yet?\n+\n+If you do not yet have a Forest account then sign up for one at:\n+    https://forest.rigetti.com\"\"\"\n+        super(InvalidUserError, self).__init__(server_status, explanation)\n+        ApiError.__init__(self, server_status, explanation)\n+\n+\n+class JobNotFoundError(ApiError):\n+    def __init__(self, server_status):\n+        explanation = \"\"\"\n+The above job may have been deleted manually or due to some bug in the server.\n+If you suspect this to be a bug then please describe the problem in a Github\n+issue at:\n+    https://github.com/rigetticomputing/pyquil/issues\"\"\"\n+        super(JobNotFoundError, self).__init__(server_status, explanation)\n+        ApiError.__init__(self, server_status, explanation)\n+\n+\n+class MissingPermissionsError(ApiError):\n+    def __init__(self, server_status):\n+        explanation = \"\"\"\n+Your account may not be whitelisted for QPU access. To request the appropriate\n+permissions please read the information located at:\n+    https://forest.rigetti.com\"\"\"\n+        super(MissingPermissionsError, self).__init__(server_status, explanation)\n+        ApiError.__init__(self, server_status, explanation)\n+\n+\n+class QPUError(ApiError):\n+    def __init__(self, server_status):\n+        explanation = \"\"\"\n+The QPU returned the above error. This could be due to a bug in the server or a\n+bug in your code. If you suspect this to be a bug in pyQuil or Rigetti Forest,\n+then please describe the problem in a GitHub issue at:\n+    https://github.com/rigetticomputing/pyquil/issues\"\"\"\n+        super(QPUError, self).__init__(server_status, explanation)\n+\n+\n+class QVMError(ApiError):\n+    def __init__(self, server_status):\n+        explanation = \"\"\"\n+The QVM returned the above error. This could be due to a bug in the server or a\n+bug in your code. If you suspect this to be a bug in pyQuil or Rigetti Forest,\n+then please describe the problem in a GitHub issue at:\n+    https://github.com/rigetticomputing/pyquil/issues\"\"\"\n+        super(QVMError, self).__init__(server_status, explanation)\n+\n+\n+class TooManyQubitsError(ApiError):\n+    def __init__(self, server_status):\n+        explanation = \"\"\"\n+You requested too many qubits on the QVM. More qubits are available when you use\n+the queue. Pass the use_queue parameter to QVMConnection to enable additional\n+qubits (however, each program will take longer to run). For example:\n+\n+    qvm = QVMConnection(use_queue=True)\n+    qvm.run(twenty_qubit_program)\n+\n+See https://go.rigetti.com/connections for more info.\"\"\"\n+        super(TooManyQubitsError, self).__init__(server_status, explanation)\n+\n+\n+class UnknownApiError(ApiError):\n+    def __init__(self, server_status):\n+        explanation = \"\"\"\n+The server has failed to return a proper response. Please describe the problem\n+and copy the above message into a GitHub issue at:\n+    https://github.com/rigetticomputing/pyquil/issues\"\"\"\n+        super(UnknownApiError, self).__init__(server_status, explanation)\n+\n+\n+# NB: Some errors are not included here if they are only returned by async endpoints\n+# The source of truth for this mapping is the errors.py file on the server\n+error_mapping = {\n+    'device_offline': DeviceOfflineError,\n+    'device_retuning': DeviceRetuningError,\n+    'invalid_input': InvalidInputError,\n+    'invalid_user': InvalidUserError,\n+    'job_not_found': JobNotFoundError,\n+    'missing_permissions': MissingPermissionsError,\n+    'qvm_error': QVMError,\n+}\ndiff --git a/pyquil/api/job.py b/pyquil/api/job.py\n--- a/pyquil/api/job.py\n+++ b/pyquil/api/job.py\n@@ -17,6 +17,7 @@\n import base64\n import warnings\n \n+from pyquil.api.errors import CancellationError, QVMError, QPUError\n from pyquil.parser import parse_program\n from pyquil.wavefunction import Wavefunction\n \n@@ -29,8 +30,9 @@ class Job(object):\n     They transition to RUNNING when they have been started\n     Finally they are marked as FINISHED, ERROR, or CANCELLED once completed\n     \"\"\"\n-    def __init__(self, raw):\n+    def __init__(self, raw, machine):\n         self._raw = raw\n+        self._machine = machine\n \n     @property\n     def job_id(self):\n@@ -50,16 +52,19 @@ def result(self):\n         \"\"\"\n         The result of the job if available\n         throws ValueError is result is not available yet\n-        throws RuntimeError if server returned an error indicating program execution was not successful\n+        throws ApiError if server returned an error indicating program execution was not successful\n             or if the job was cancelled\n         \"\"\"\n         if not self.is_done():\n             raise ValueError(\"Cannot get a result for a program that isn't completed.\")\n \n         if self._raw['status'] == 'CANCELLED':\n-            raise RuntimeError(\"Job was cancelled: {}\".format(self._raw['result']))\n+            raise CancellationError(self._raw['result'])\n         elif self._raw['status'] == 'ERROR':\n-            raise RuntimeError(\"Server returned an error: {}\".format(self._raw['result']))\n+            if self._machine == 'QVM':\n+                raise QVMError(self._raw['result'])\n+            else:  # self._machine == 'QPU'\n+                raise QPUError(self._raw['result'])\n \n         if self._raw['program']['type'] == 'wavefunction':\n             return Wavefunction.from_bit_packed_string(\ndiff --git a/pyquil/api/qpu.py b/pyquil/api/qpu.py\n--- a/pyquil/api/qpu.py\n+++ b/pyquil/api/qpu.py\n@@ -15,12 +15,12 @@\n ##############################################################################\n import warnings\n \n-import requests\n from six import integer_types\n \n+from pyquil.api import Job\n from pyquil.quil import Program\n-from ._base_connection import validate_run_items, TYPE_MULTISHOT, TYPE_MULTISHOT_MEASURE, get_job_id, BaseConnection\n-from ._config import PyquilConfig\n+from ._base_connection import validate_run_items, TYPE_MULTISHOT, TYPE_MULTISHOT_MEASURE, get_job_id, \\\n+    get_session, wait_for_job, post_json, get_json\n \n \n def get_devices(async_endpoint='https://job.rigetti.com/beta', api_key=None, user_id=None):\n@@ -31,17 +31,8 @@ def get_devices(async_endpoint='https://job.rigetti.com/beta', api_key=None, use\n     :return: set of online and offline devices\n     :rtype: set\n     \"\"\"\n-    config = PyquilConfig()\n-    api_key = api_key if api_key else config.api_key\n-    user_id = user_id if user_id else config.user_id\n-\n-    headers = {\n-        'X-Api-Key': api_key,\n-        'X-User-Id': user_id,\n-        'Content-Type': 'application/json; charset=utf-8'\n-    }\n-\n-    response = requests.get(async_endpoint + '/devices', headers=headers)\n+    session = get_session(api_key, user_id)\n+    response = session.get(async_endpoint + '/devices')\n     return {Device(name, device) for (name, device) in response.json()['devices'].items()}\n \n \n@@ -74,7 +65,7 @@ def __repr__(self):\n         return str(self)\n \n \n-class QPUConnection(BaseConnection):\n+class QPUConnection(object):\n     \"\"\"\n     Represents a connection to the QPU (Quantum Processing Unit)\n     \"\"\"\n@@ -114,9 +105,12 @@ def __init__(self, device_name=None, async_endpoint='https://job.rigetti.com/bet\n \n To suppress this warning, see Python's warning module.\n \"\"\")\n+        self.async_endpoint = async_endpoint\n+        self.session = get_session(api_key, user_id)\n+\n+        self.ping_time = ping_time\n+        self.status_time = status_time\n \n-        super(QPUConnection, self).__init__(async_endpoint=async_endpoint, api_key=api_key, user_id=user_id,\n-                                            ping_time=ping_time, status_time=status_time)\n         self.device_name = device_name\n \n     def run(self, quil_program, classical_addresses, trials=1):\n@@ -130,20 +124,17 @@ def run(self, quil_program, classical_addresses, trials=1):\n                  in `classical_addresses`.\n         :rtype: list\n         \"\"\"\n-        payload = self._run_payload(quil_program, classical_addresses, trials)\n-\n-        response = self._post_json(self.async_endpoint + \"/job\", self._wrap_program(payload))\n-        job = self.wait_for_job(get_job_id(response))\n-        return job.result()\n+        raise DeprecationWarning(\"\"\"\n+The QPU does not currently support arbitrary measure operations. For now, the\n+only supported operation on the QPU is run_and_measure.\"\"\")\n \n     def run_async(self, quil_program, classical_addresses, trials=1):\n         \"\"\"\n         Similar to run except that it returns a job id and doesn't wait for the program to be executed.\n         See https://go.rigetti.com/connections for reasons to use this method.\n         \"\"\"\n-        payload = self._run_payload(quil_program, classical_addresses, trials)\n-        response = self._post_json(self.async_endpoint + \"/job\", self._wrap_program(payload))\n-        return get_job_id(response)\n+        # NB: Throw the same deprecation warning as in run\n+        return self.run(quil_program, classical_addresses, trials)\n \n     def _run_payload(self, quil_program, classical_addresses, trials):\n         if not isinstance(quil_program, Program):\n@@ -172,7 +163,7 @@ def run_and_measure(self, quil_program, qubits, trials=1):\n         \"\"\"\n         payload = self._run_and_measure_payload(quil_program, qubits, trials)\n \n-        response = self._post_json(self.async_endpoint + \"/job\", self._wrap_program(payload))\n+        response = post_json(self.session, self.async_endpoint + \"/job\", self._wrap_program(payload))\n         job = self.wait_for_job(get_job_id(response))\n         return job.result()\n \n@@ -182,7 +173,7 @@ def run_and_measure_async(self, quil_program, qubits, trials):\n         See https://go.rigetti.com/connections for reasons to use this method.\n         \"\"\"\n         payload = self._run_and_measure_payload(quil_program, qubits, trials)\n-        response = self._post_json(self.async_endpoint + \"/job\", self._wrap_program(payload))\n+        response = post_json(self.session, self.async_endpoint + \"/job\", self._wrap_program(payload))\n         return get_job_id(response)\n \n     def _run_and_measure_payload(self, quil_program, qubits, trials):\n@@ -199,6 +190,34 @@ def _run_and_measure_payload(self, quil_program, qubits, trials):\n \n         return payload\n \n+    def get_job(self, job_id):\n+        \"\"\"\n+        Given a job id, return information about the status of the job\n+\n+        :param str job_id: job id\n+        :return: Job object with the status and potentially results of the job\n+        :rtype: Job\n+        \"\"\"\n+        response = get_json(self.session, self.async_endpoint + \"/job/\" + job_id)\n+        return Job(response.json(), 'QPU')\n+\n+    def wait_for_job(self, job_id, ping_time=None, status_time=None):\n+        \"\"\"\n+        Wait for the results of a job and periodically print status\n+\n+        :param job_id: Job id\n+        :param ping_time: How often to poll the server.\n+                          Defaults to the value specified in the constructor. (0.1 seconds)\n+        :param status_time: How often to print status, set to False to never print status.\n+                            Defaults to the value specified in the constructor (2 seconds)\n+        :return: Completed Job\n+        \"\"\"\n+        def get_job_fn():\n+            return self.get_job(job_id)\n+        return wait_for_job(get_job_fn,\n+                            ping_time if ping_time else self.ping_time,\n+                            status_time if status_time else self.status_time)\n+\n     def _wrap_program(self, program):\n         return {\n             \"machine\": \"QPU\",\ndiff --git a/pyquil/api/qvm.py b/pyquil/api/qvm.py\n--- a/pyquil/api/qvm.py\n+++ b/pyquil/api/qvm.py\n@@ -14,17 +14,17 @@\n #    limitations under the License.\n ##############################################################################\n \n-import json\n-\n from six import integer_types\n \n+from pyquil.api import Job\n from pyquil.quil import Program\n from pyquil.wavefunction import Wavefunction\n-from ._base_connection import BaseConnection, validate_noise_probabilities, validate_run_items, TYPE_MULTISHOT, \\\n-    TYPE_MULTISHOT_MEASURE, TYPE_WAVEFUNCTION, TYPE_EXPECTATION, get_job_id\n+from ._base_connection import validate_noise_probabilities, validate_run_items, TYPE_MULTISHOT, \\\n+    TYPE_MULTISHOT_MEASURE, TYPE_WAVEFUNCTION, TYPE_EXPECTATION, get_job_id, get_session, wait_for_job, \\\n+    post_json, get_json\n \n \n-class QVMConnection(BaseConnection):\n+class QVMConnection(object):\n     \"\"\"\n     Represents a connection to the QVM.\n     \"\"\"\n@@ -58,10 +58,13 @@ def __init__(self, sync_endpoint='https://api.rigetti.com', async_endpoint='http\n         :param random_seed: A seed for the QVM's random number generators. Either None (for an\n                             automatically generated seed) or a non-negative integer.\n         \"\"\"\n-        super(QVMConnection, self).__init__(async_endpoint=async_endpoint, api_key=api_key, user_id=user_id,\n-                                            ping_time=ping_time, status_time=status_time)\n+        self.async_endpoint = async_endpoint\n         self.sync_endpoint = sync_endpoint\n+        self.session = get_session(api_key, user_id)\n+\n         self.use_queue = use_queue\n+        self.ping_time = ping_time\n+        self.status_time = status_time\n \n         validate_noise_probabilities(gate_noise)\n         validate_noise_probabilities(measurement_noise)\n@@ -92,12 +95,12 @@ def run(self, quil_program, classical_addresses, trials=1):\n         \"\"\"\n         payload = self._run_payload(quil_program, classical_addresses, trials)\n         if self.use_queue:\n-            response = self._post_json(self.async_endpoint + \"/job\", {\"machine\": \"QVM\", \"program\": payload})\n+            response = post_json(self.session, self.async_endpoint + \"/job\", {\"machine\": \"QVM\", \"program\": payload})\n             job = self.wait_for_job(get_job_id(response))\n             return job.result()\n         else:\n             payload = self._run_payload(quil_program, classical_addresses, trials)\n-            response = self._post_json(self.sync_endpoint + \"/qvm\", payload)\n+            response = post_json(self.session, self.sync_endpoint + \"/qvm\", payload)\n             return response.json()\n \n     def run_async(self, quil_program, classical_addresses, trials=1):\n@@ -106,7 +109,7 @@ def run_async(self, quil_program, classical_addresses, trials=1):\n         See https://go.rigetti.com/connections for reasons to use this method.\n         \"\"\"\n         payload = self._run_payload(quil_program, classical_addresses, trials)\n-        response = self._post_json(self.async_endpoint + \"/job\", {\"machine\": \"QVM\", \"program\": payload})\n+        response = post_json(self.session, self.async_endpoint + \"/job\", {\"machine\": \"QVM\", \"program\": payload})\n         return get_job_id(response)\n \n     def _run_payload(self, quil_program, classical_addresses, trials):\n@@ -144,12 +147,12 @@ def run_and_measure(self, quil_program, qubits, trials=1):\n         \"\"\"\n         payload = self._run_and_measure_payload(quil_program, qubits, trials)\n         if self.use_queue:\n-            response = self._post_json(self.async_endpoint + \"/job\", {\"machine\": \"QVM\", \"program\": payload})\n+            response = post_json(self.session, self.async_endpoint + \"/job\", {\"machine\": \"QVM\", \"program\": payload})\n             job = self.wait_for_job(get_job_id(response))\n             return job.result()\n         else:\n             payload = self._run_and_measure_payload(quil_program, qubits, trials)\n-            response = self._post_json(self.sync_endpoint + \"/qvm\", payload)\n+            response = post_json(self.session, self.sync_endpoint + \"/qvm\", payload)\n             return response.json()\n \n     def run_and_measure_async(self, quil_program, qubits, trials=1):\n@@ -158,7 +161,7 @@ def run_and_measure_async(self, quil_program, qubits, trials=1):\n         See https://go.rigetti.com/connections for reasons to use this method.\n         \"\"\"\n         payload = self._run_and_measure_payload(quil_program, qubits, trials)\n-        response = self._post_json(self.async_endpoint + \"/job\", {\"machine\": \"QVM\", \"program\": payload})\n+        response = post_json(self.session, self.async_endpoint + \"/job\", {\"machine\": \"QVM\", \"program\": payload})\n         return get_job_id(response)\n \n     def _run_and_measure_payload(self, quil_program, qubits, trials):\n@@ -200,12 +203,12 @@ def wavefunction(self, quil_program, classical_addresses=None):\n \n         if self.use_queue:\n             payload = self._wavefunction_payload(quil_program, classical_addresses)\n-            response = self._post_json(self.async_endpoint + \"/job\", {\"machine\": \"QVM\", \"program\": payload})\n+            response = post_json(self.session, self.async_endpoint + \"/job\", {\"machine\": \"QVM\", \"program\": payload})\n             job = self.wait_for_job(get_job_id(response))\n             return job.result()\n         else:\n             payload = self._wavefunction_payload(quil_program, classical_addresses)\n-            response = self._post_json(self.sync_endpoint + \"/qvm\", payload)\n+            response = post_json(self.session, self.sync_endpoint + \"/qvm\", payload)\n             return Wavefunction.from_bit_packed_string(response.content, classical_addresses)\n \n     def wavefunction_async(self, quil_program, classical_addresses=None):\n@@ -217,7 +220,7 @@ def wavefunction_async(self, quil_program, classical_addresses=None):\n             classical_addresses = []\n \n         payload = self._wavefunction_payload(quil_program, classical_addresses)\n-        response = self._post_json(self.async_endpoint + \"/job\", {\"machine\": \"QVM\", \"program\": payload})\n+        response = post_json(self.session, self.async_endpoint + \"/job\", {\"machine\": \"QVM\", \"program\": payload})\n         return get_job_id(response)\n \n     def _wavefunction_payload(self, quil_program, classical_addresses):\n@@ -252,12 +255,12 @@ def expectation(self, prep_prog, operator_programs=None):\n         \"\"\"\n         if self.use_queue:\n             payload = self._expectation_payload(prep_prog, operator_programs)\n-            response = self._post_json(self.async_endpoint + \"/job\", {\"machine\": \"QVM\", \"program\": payload})\n+            response = post_json(self.session, self.async_endpoint + \"/job\", {\"machine\": \"QVM\", \"program\": payload})\n             job = self.wait_for_job(get_job_id(response))\n             return job.result()\n         else:\n             payload = self._expectation_payload(prep_prog, operator_programs)\n-            response = self._post_json(self.sync_endpoint + \"/qvm\", payload)\n+            response = post_json(self.session, self.sync_endpoint + \"/qvm\", payload)\n             return response.json()\n \n     def expectation_async(self, prep_prog, operator_programs=None):\n@@ -266,7 +269,7 @@ def expectation_async(self, prep_prog, operator_programs=None):\n         See https://go.rigetti.com/connections for reasons to use this method.\n         \"\"\"\n         payload = self._expectation_payload(prep_prog, operator_programs)\n-        response = self._post_json(self.async_endpoint + \"/job\", {\"machine\": \"QVM\", \"program\": payload})\n+        response = post_json(self.session, self.async_endpoint + \"/job\", {\"machine\": \"QVM\", \"program\": payload})\n         return get_job_id(response)\n \n     def _expectation_payload(self, prep_prog, operator_programs):\n@@ -284,6 +287,34 @@ def _expectation_payload(self, prep_prog, operator_programs):\n \n         return payload\n \n+    def get_job(self, job_id):\n+        \"\"\"\n+        Given a job id, return information about the status of the job\n+\n+        :param str job_id: job id\n+        :return: Job object with the status and potentially results of the job\n+        :rtype: Job\n+        \"\"\"\n+        response = get_json(self.session, self.async_endpoint + \"/job/\" + job_id)\n+        return Job(response.json(), 'QVM')\n+\n+    def wait_for_job(self, job_id, ping_time=None, status_time=None):\n+        \"\"\"\n+        Wait for the results of a job and periodically print status\n+\n+        :param job_id: Job id\n+        :param ping_time: How often to poll the server.\n+                          Defaults to the value specified in the constructor. (0.1 seconds)\n+        :param status_time: How often to print status, set to False to never print status.\n+                            Defaults to the value specified in the constructor (2 seconds)\n+        :return: Completed Job\n+        \"\"\"\n+        def get_job_fn():\n+            return self.get_job(job_id)\n+        return wait_for_job(get_job_fn,\n+                            ping_time if ping_time else self.ping_time,\n+                            status_time if status_time else self.status_time)\n+\n     def _add_noise_to_payload(self, payload):\n         \"\"\"\n         Set the gate noise and measurement noise of a payload.\ndiff --git a/pyquil/job_results.py b/pyquil/job_results.py\n--- a/pyquil/job_results.py\n+++ b/pyquil/job_results.py\n@@ -1,6 +1,11 @@\n def wait_for_job(res, ping_time=0.5):\n-    raise DeprecationWarning(\n-        \"The wait_for_job function is now deprecated. See https://go.rigetti.com/connections for more info.\")\n+    raise DeprecationWarning(\"\"\"\n+The wait_for_job function has been moved inside the QVMConnection or\n+QPUConnection object. For instance:\n+    job = qvm.wait_for_job(job_id)\n+    print(job.result())\n+\n+See https://go.rigetti.com/connections for more info.\"\"\")\n \n \n class JobResult(object):\n", "test_patch": "diff --git a/pyquil/tests/test_api.py b/pyquil/tests/test_api.py\n--- a/pyquil/tests/test_api.py\n+++ b/pyquil/tests/test_api.py\n@@ -154,8 +154,8 @@ def test_qpu_connection():\n     qpu = QPUConnection(device_name='fake_device')\n \n     program = {\n-        \"type\": \"multishot\",\n-        \"addresses\": [0, 1],\n+        \"type\": \"multishot-measure\",\n+        \"qubits\": [0, 1],\n         \"trials\": 2,\n         \"quil-instructions\": \"H 0\\nCNOT 0 1\\n\"\n     }\n@@ -176,7 +176,7 @@ def mock_queued_response(request, context):\n                                  \"result\": [[0, 0], [1, 1]], \"program\": program})}\n         ])\n \n-        result = qpu.run(BELL_STATE, [0, 1], trials=2)\n+        result = qpu.run_and_measure(BELL_STATE, [0, 1], trials=2)\n         assert result == [[0, 0], [1, 1]]\n \n     with requests_mock.Mocker() as m:\n@@ -192,7 +192,7 @@ def mock_queued_response(request, context):\n                                  }})}\n         ])\n \n-        job = qpu.wait_for_job(qpu.run_async(BELL_STATE, [0, 1], trials=2))\n+        job = qpu.wait_for_job(qpu.run_and_measure_async(BELL_STATE, [0, 1], trials=2))\n         assert job.result() == [[0, 0], [1, 1]]\n         assert job.compiled_quil() == Program(H(0), CNOT(0, 1))\n         assert job.topological_swaps() == 0\n@@ -206,7 +206,7 @@ def mock_queued_response(request, context):\n                                  \"result\": [[0, 0], [1, 1]], \"program\": program})}\n         ])\n \n-        job = qpu.wait_for_job(qpu.run_async(BELL_STATE, [0, 1], trials=2))\n+        job = qpu.wait_for_job(qpu.run_and_measure_async(BELL_STATE, [0, 1], trials=2))\n         assert job.result() == [[0, 0], [1, 1]]\n         assert job.compiled_quil() is None\n         assert job.topological_swaps() is None\n", "problem_statement": "Meta-Issue: User Experience\nWe need to improve user experience in the following areas:\r\n- [ ] jobs can get stuck indefinitely on 'job is currently running' if there were issues with background workers\r\n- [x] errors from the sync QVM are returned as strings, they should throw as exception instead otherwise they could be used as results\r\n- [x] errors from async QVM/QPU are thrown differently than when they come from the sync QVM. (as in, there's no pretty printing of the error like in _base_connection)\r\n- [ ] measure function that takes ranges (ie. `program.measure([0..8], [0..8])`)\n", "hints_text": "Somewhat related to: https://github.com/rigetticomputing/pyquil/issues/193\n- [x] `run_and_measure` and likely other API calls will print periodic status updates that cannot be turned off. It would be nice to either add a flag to `run_and_measure` itself or make this configurable at the `QPUConnection`/`QVMConnection` level. Here is an example within a jupyter notebook that demonstrates this\r\n![image](https://user-images.githubusercontent.com/1573961/33732305-ef50a188-db3a-11e7-8ea8-0c7e664147c4.png)\r\n\n@ntezak  - take a look here: https://github.com/rigetticomputing/pyquil/pull/213\nGot this warning message:\r\n`DeprecationWarning: The wait_for_job function is now deprecated. See https://go.rigetti.com/connections for more info.`\r\nBut in the docs there's this example:\r\n```\r\njob = qvm.wait_for_job(job_id)\r\nprint(job.result())\r\n```\r\nIt'd be more clear if the deprecation warning would have said something like \"job_results.wait_for_job has moved to qvm.wait_for_job\"", "created_at": 1513, "language": "python", "label": "Hard"}
{"repo": "marcelotduarte/cx_Freeze", "pull_number": 2204, "instance_id": "marcelotduarte__cx_Freeze-2204", "issue_numbers": ["2192"], "base_commit": "7bc86a407b93eef77bfba1d3e7d1f3c18de9f97b", "patch": "diff --git a/cx_Freeze/freezer.py b/cx_Freeze/freezer.py\n--- a/cx_Freeze/freezer.py\n+++ b/cx_Freeze/freezer.py\n@@ -88,8 +88,8 @@ def __init__(\n         self.path: list[str] | None = self._validate_path(path)\n         self.include_msvcr: bool = include_msvcr\n         self.target_dir = target_dir\n-        self.bin_includes: list[str] | None = bin_includes\n-        self.bin_excludes: list[str] | None = bin_excludes\n+        self.bin_includes: list[str] = self._validate_bin_file(bin_includes)\n+        self.bin_excludes: list[str] = self._validate_bin_file(bin_excludes)\n         self.bin_path_includes: list[str] = self._validate_bin_path(\n             bin_path_includes\n         )\n@@ -289,7 +289,7 @@ def _freeze_executable(self, exe: Executable) -> None:\n             self._copy_top_dependency(source)\n             # Once copied, it should be deleted from the list to ensure\n             # it will not be copied again.\n-            name = Path(source.name)\n+            name = os.path.normcase(source.name)\n             if name in self.bin_includes:\n                 self.bin_includes.remove(name)\n                 self.bin_excludes.append(name)\n@@ -426,35 +426,36 @@ def _remove_version_numbers(filename: str) -> str:\n             return \".\".join(parts)\n         return filename\n \n-    def _should_copy_file(self, path: Path) -> bool:  # noqa: PLR0911\n+    def _should_copy_file(self, path: Path) -> bool:\n         \"\"\"Return true if the file should be copied to the target machine.\n-        This is done by checking the bin_path_includes, bin_path_excludes,\n-        bin_includes and bin_excludes configuration variables using first\n-        the full file name, then just the base file name, then the file name\n-        without any version numbers.\n+\n+        This is done by checking the bin_includes and bin_excludes\n+        configuration variables using first the full file name, then just the\n+        base file name, then the file name without any version numbers.\n+        Then, bin_path_includes and bin_path_excludes are checked.\n \n         Files are included unless specifically excluded but inclusions take\n         precedence over exclusions.\n         \"\"\"\n         # check the full path\n-        if path in self.bin_includes:\n-            return True\n-        if path in self.bin_excludes:\n-            return False\n-\n         # check the file name by itself (with any included version numbers)\n-        filename = Path(path.name)\n-        if filename in self.bin_includes:\n-            return True\n-        if filename in self.bin_excludes:\n-            return False\n-\n         # check the file name by itself (version numbers removed)\n-        filename = Path(self._remove_version_numbers(path.name))\n-        if filename in self.bin_includes:\n-            return True\n-        if filename in self.bin_excludes:\n-            return False\n+        filename = Path(os.path.normcase(path.name))\n+        filename_noversion = Path(self._remove_version_numbers(filename.name))\n+        for binfile in self.bin_includes:\n+            if (\n+                path.match(binfile)\n+                or filename.match(binfile)\n+                or filename_noversion.match(binfile)\n+            ):\n+                return True\n+        for binfile in self.bin_excludes:\n+            if (\n+                path.match(binfile)\n+                or filename.match(binfile)\n+                or filename_noversion.match(binfile)\n+            ):\n+                return False\n \n         # check the path for inclusion/exclusion\n         dirname = path.parent\n@@ -508,6 +509,15 @@ def _validate_path(path: list[str | Path] | None = None) -> list[str]:\n                 path.insert(index, os.fspath(dynload))\n         return path\n \n+    @staticmethod\n+    def _validate_bin_file(\n+        filenames: Sequence[str | Path] | None,\n+    ) -> list[str]:\n+        \"\"\"Returns valid filenames for bin_includes and bin_excludes.\"\"\"\n+        if filenames is None:\n+            return []\n+        return [os.path.normcase(filename) for filename in filenames]\n+\n     @staticmethod\n     def _validate_bin_path(bin_path: Sequence[str | Path] | None) -> list[str]:\n         \"\"\"Returns valid search path for bin_path_includes and\n@@ -522,15 +532,8 @@ def _validate_bin_path(bin_path: Sequence[str | Path] | None) -> list[str]:\n         return valid\n \n     def _verify_configuration(self) -> None:\n-        \"\"\"Verify and normalize names and paths.\"\"\"\n-        filenames = list(self.bin_includes or [])\n-        filenames += self._default_bin_includes()\n-        self.bin_includes = [Path(name) for name in filenames]\n-\n-        filenames = list(self.bin_excludes or [])\n-        filenames += self._default_bin_excludes()\n-        self.bin_excludes = [Path(name) for name in filenames]\n-\n+        self.bin_includes += self._default_bin_includes()\n+        self.bin_excludes += self._default_bin_excludes()\n         self.bin_path_includes += self._default_bin_path_includes()\n         self.bin_path_excludes += self._default_bin_path_excludes()\n \n@@ -882,9 +885,8 @@ def _pre_copy_hook(self, source: Path, target: Path) -> tuple[Path, Path]:\n         C runtime libraries.\n         \"\"\"\n         # fix the target path for C runtime files\n-        norm_target_name = target.name.lower()\n-        if norm_target_name in self.runtime_files:\n-            target = self.target_dir / norm_target_name\n+        if any(filter(target.match, self.runtime_files)):\n+            target = self.target_dir / target.name\n         return source, target\n \n     def _post_copy_hook(\n@@ -1000,11 +1002,12 @@ def _platform_add_extra_dependencies(\n         search_dirs: set[Path] = set()\n         for filename in dependent_files:\n             search_dirs.add(filename.parent)\n-        for filename in self.runtime_files:\n-            for search_dir in search_dirs:\n-                filepath = search_dir / filename\n-                if filepath.exists():\n-                    dependent_files.add(filepath)\n+        for search_dir in search_dirs:\n+            for pattern in self.runtime_files:\n+                for filename in search_dir.glob(pattern):\n+                    filepath = search_dir / filename\n+                    if filepath.exists():\n+                        dependent_files.add(filepath)\n \n     def _post_freeze_hook(self) -> None:\n         target_lib = self.target_dir / \"lib\"\n@@ -1025,9 +1028,9 @@ def runtime_files(self) -> set[str]:\n         winmsvcr = import_module(\"cx_Freeze.winmsvcr\")\n         if not self.include_msvcr:\n             # just put on the exclusion list\n-            self.bin_excludes.extend(list(map(Path, winmsvcr.FILES)))\n+            self.bin_excludes.extend(winmsvcr.FILES)\n             return set()\n-        return winmsvcr.FILES\n+        return set(winmsvcr.FILES)\n \n \n class DarwinFreezer(Freezer, Parser):\ndiff --git a/cx_Freeze/winmsvcr.py b/cx_Freeze/winmsvcr.py\n--- a/cx_Freeze/winmsvcr.py\n+++ b/cx_Freeze/winmsvcr.py\n@@ -7,47 +7,8 @@\n from __future__ import annotations\n \n FILES = (\n+    \"api-ms-win-*.dll\",\n     # VC 2015 and 2017\n-    \"api-ms-win-core-console-l1-1-0.dll\",\n-    \"api-ms-win-core-datetime-l1-1-0.dll\",\n-    \"api-ms-win-core-debug-l1-1-0.dll\",\n-    \"api-ms-win-core-errorhandling-l1-1-0.dll\",\n-    \"api-ms-win-core-file-l1-1-0.dll\",\n-    \"api-ms-win-core-file-l1-2-0.dll\",\n-    \"api-ms-win-core-file-l2-1-0.dll\",\n-    \"api-ms-win-core-handle-l1-1-0.dll\",\n-    \"api-ms-win-core-heap-l1-1-0.dll\",\n-    \"api-ms-win-core-interlocked-l1-1-0.dll\",\n-    \"api-ms-win-core-libraryloader-l1-1-0.dll\",\n-    \"api-ms-win-core-localization-l1-2-0.dll\",\n-    \"api-ms-win-core-memory-l1-1-0.dll\",\n-    \"api-ms-win-core-namedpipe-l1-1-0.dll\",\n-    \"api-ms-win-core-processenvironment-l1-1-0.dll\",\n-    \"api-ms-win-core-processthreads-l1-1-0.dll\",\n-    \"api-ms-win-core-processthreads-l1-1-1.dll\",\n-    \"api-ms-win-core-profile-l1-1-0.dll\",\n-    \"api-ms-win-core-rtlsupport-l1-1-0.dll\",\n-    \"api-ms-win-core-string-l1-1-0.dll\",\n-    \"api-ms-win-core-synch-l1-1-0.dll\",\n-    \"api-ms-win-core-synch-l1-2-0.dll\",\n-    \"api-ms-win-core-sysinfo-l1-1-0.dll\",\n-    \"api-ms-win-core-timezone-l1-1-0.dll\",\n-    \"api-ms-win-core-util-l1-1-0.dll\",\n-    \"api-ms-win-crt-conio-l1-1-0.dll\",\n-    \"api-ms-win-crt-convert-l1-1-0.dll\",\n-    \"api-ms-win-crt-environment-l1-1-0.dll\",\n-    \"api-ms-win-crt-filesystem-l1-1-0.dll\",\n-    \"api-ms-win-crt-heap-l1-1-0.dll\",\n-    \"api-ms-win-crt-locale-l1-1-0.dll\",\n-    \"api-ms-win-crt-math-l1-1-0.dll\",\n-    \"api-ms-win-crt-multibyte-l1-1-0.dll\",\n-    \"api-ms-win-crt-private-l1-1-0.dll\",\n-    \"api-ms-win-crt-process-l1-1-0.dll\",\n-    \"api-ms-win-crt-runtime-l1-1-0.dll\",\n-    \"api-ms-win-crt-stdio-l1-1-0.dll\",\n-    \"api-ms-win-crt-string-l1-1-0.dll\",\n-    \"api-ms-win-crt-time-l1-1-0.dll\",\n-    \"api-ms-win-crt-utility-l1-1-0.dll\",\n     \"concrt140.dll\",\n     \"msvcp140_1.dll\",\n     \"msvcp140_2.dll\",\n@@ -58,7 +19,9 @@\n     \"vcomp140.dll\",\n     \"vcruntime140.dll\",\n     # VS 2019\n-    \"vcruntime140_1.dll\",\n     \"msvcp140_atomic_wait.dll\",\n     \"msvcp140_codecvt_ids.dll\",\n+    \"vcruntime140_1.dll\",\n+    # VS 2022\n+    \"vcruntime140_threads.dll\",\n )\n", "test_patch": "diff --git a/tests/test_command_build_exe.py b/tests/test_command_build_exe.py\n--- a/tests/test_command_build_exe.py\n+++ b/tests/test_command_build_exe.py\n@@ -97,20 +97,6 @@ def test_build_exe_asmodule(datafiles: Path):\n     assert output.startswith(\"Hello from cx_Freeze\")\n \n \n-@pytest.mark.skipif(sys.platform != \"win32\", reason=\"Windows tests\")\n-@pytest.mark.datafiles(SAMPLES_DIR / \"simple\")\n-def test_build_exe_simple_include_msvcr(datafiles: Path):\n-    \"\"\"Test the simple sample with include_msvcr option.\"\"\"\n-    command = BUILD_EXE_CMD + \" --include-msvcr\"\n-    output = run_command(datafiles, command)\n-\n-    build_exe_dir = datafiles / BUILD_EXE_DIR\n-    executable = build_exe_dir / f\"hello{SUFFIX}\"\n-    assert executable.is_file()\n-    output = run_command(datafiles, executable, timeout=10)\n-    assert output.startswith(\"Hello from cx_Freeze\")\n-\n-\n @pytest.mark.datafiles(SAMPLES_DIR / \"sqlite\")\n def test_build_exe_sqlite(datafiles: Path):\n     \"\"\"Test the sqlite sample.\"\"\"\ndiff --git a/tests/test_winmsvcr.py b/tests/test_winmsvcr.py\n--- a/tests/test_winmsvcr.py\n+++ b/tests/test_winmsvcr.py\n@@ -2,53 +2,17 @@\n from __future__ import annotations\n \n import sys\n+from pathlib import Path\n+from sysconfig import get_platform, get_python_version\n \n import pytest\n+from generate_samples import run_command\n \n from cx_Freeze.winmsvcr import FILES\n \n EXPECTED = (\n+    \"api-ms-win-*.dll\",\n     # VC 2015 and 2017\n-    \"api-ms-win-core-console-l1-1-0.dll\",\n-    \"api-ms-win-core-datetime-l1-1-0.dll\",\n-    \"api-ms-win-core-debug-l1-1-0.dll\",\n-    \"api-ms-win-core-errorhandling-l1-1-0.dll\",\n-    \"api-ms-win-core-file-l1-1-0.dll\",\n-    \"api-ms-win-core-file-l1-2-0.dll\",\n-    \"api-ms-win-core-file-l2-1-0.dll\",\n-    \"api-ms-win-core-handle-l1-1-0.dll\",\n-    \"api-ms-win-core-heap-l1-1-0.dll\",\n-    \"api-ms-win-core-interlocked-l1-1-0.dll\",\n-    \"api-ms-win-core-libraryloader-l1-1-0.dll\",\n-    \"api-ms-win-core-localization-l1-2-0.dll\",\n-    \"api-ms-win-core-memory-l1-1-0.dll\",\n-    \"api-ms-win-core-namedpipe-l1-1-0.dll\",\n-    \"api-ms-win-core-processenvironment-l1-1-0.dll\",\n-    \"api-ms-win-core-processthreads-l1-1-0.dll\",\n-    \"api-ms-win-core-processthreads-l1-1-1.dll\",\n-    \"api-ms-win-core-profile-l1-1-0.dll\",\n-    \"api-ms-win-core-rtlsupport-l1-1-0.dll\",\n-    \"api-ms-win-core-string-l1-1-0.dll\",\n-    \"api-ms-win-core-synch-l1-1-0.dll\",\n-    \"api-ms-win-core-synch-l1-2-0.dll\",\n-    \"api-ms-win-core-sysinfo-l1-1-0.dll\",\n-    \"api-ms-win-core-timezone-l1-1-0.dll\",\n-    \"api-ms-win-core-util-l1-1-0.dll\",\n-    \"api-ms-win-crt-conio-l1-1-0.dll\",\n-    \"api-ms-win-crt-convert-l1-1-0.dll\",\n-    \"api-ms-win-crt-environment-l1-1-0.dll\",\n-    \"api-ms-win-crt-filesystem-l1-1-0.dll\",\n-    \"api-ms-win-crt-heap-l1-1-0.dll\",\n-    \"api-ms-win-crt-locale-l1-1-0.dll\",\n-    \"api-ms-win-crt-math-l1-1-0.dll\",\n-    \"api-ms-win-crt-multibyte-l1-1-0.dll\",\n-    \"api-ms-win-crt-private-l1-1-0.dll\",\n-    \"api-ms-win-crt-process-l1-1-0.dll\",\n-    \"api-ms-win-crt-runtime-l1-1-0.dll\",\n-    \"api-ms-win-crt-stdio-l1-1-0.dll\",\n-    \"api-ms-win-crt-string-l1-1-0.dll\",\n-    \"api-ms-win-crt-time-l1-1-0.dll\",\n-    \"api-ms-win-crt-utility-l1-1-0.dll\",\n     \"concrt140.dll\",\n     \"msvcp140_1.dll\",\n     \"msvcp140_2.dll\",\n@@ -59,13 +23,52 @@\n     \"vcomp140.dll\",\n     \"vcruntime140.dll\",\n     # VS 2019\n-    \"vcruntime140_1.dll\",\n     \"msvcp140_atomic_wait.dll\",\n     \"msvcp140_codecvt_ids.dll\",\n+    \"vcruntime140_1.dll\",\n+    # VS 2022\n+    \"vcruntime140_threads.dll\",\n )\n \n+PLATFORM = get_platform()\n+PYTHON_VERSION = get_python_version()\n+BUILD_EXE_DIR = f\"build/exe.{PLATFORM}-{PYTHON_VERSION}\"\n+\n+SAMPLES_DIR = Path(__file__).resolve().parent.parent / \"samples\"\n+BUILD_EXE_CMD = \"python setup.py build_exe --silent --excludes=tkinter\"\n+IS_WINDOWS = sys.platform == \"win32\"\n+SUFFIX = \".exe\" if IS_WINDOWS else \"\"\n+\n \n @pytest.mark.skipif(sys.platform != \"win32\", reason=\"Windows tests\")\n def test_files():\n     \"\"\"Test winmsvcr.FILES.\"\"\"\n     assert EXPECTED == FILES\n+\n+\n+@pytest.mark.skipif(sys.platform != \"win32\", reason=\"Windows tests\")\n+@pytest.mark.parametrize(\"include_msvcr\", [False, True], ids=[\"no\", \"yes\"])\n+@pytest.mark.datafiles(SAMPLES_DIR / \"sqlite\")\n+def test_build_exe_with_include_msvcr(datafiles: Path, include_msvcr: bool):\n+    \"\"\"Test the simple sample with include_msvcr option.\"\"\"\n+    command = BUILD_EXE_CMD\n+    if include_msvcr:\n+        command += \" --include-msvcr\"\n+    output = run_command(datafiles, command)\n+\n+    build_exe_dir = datafiles / BUILD_EXE_DIR\n+\n+    executable = build_exe_dir / f\"test_sqlite3{SUFFIX}\"\n+    assert executable.is_file()\n+    output = run_command(datafiles, executable, timeout=10)\n+    assert output.startswith(\"dump.sql created\")\n+\n+    names = [\n+        file.name.lower()\n+        for file in build_exe_dir.glob(\"*.dll\")\n+        if any(filter(file.match, EXPECTED))\n+    ]\n+    if include_msvcr:\n+        assert names != []\n+    else:\n+        assert names == []\n", "problem_statement": "api-ms-*.dll are copied regardless of `include_msvcr` value\nMight be related to #367. Asked bout this behavior in discussion #2171.\r\n\r\nI run a build workflow on github, as I do not own a microsoft machine. During the build, various api-ms-*.dll are copied from the PATH. I feel that this behavior is unwarranted.\r\n\r\nSpecific to the build:\r\n\r\n* My [setup.py](https://github.com/BannerlordCE/pyCEStoriesEditor/blob/2f416a502c17de36822befa98a079b2a8952f98c/setup.py).\r\n* The [build workflow](https://github.com/BannerlordCE/pyCEStoriesEditor/blob/2f416a502c17de36822befa98a079b2a8952f98c/.github/workflows/build.yml)\r\n* Last [job](https://github.com/BannerlordCE/pyCEStoriesEditor/actions/runs/7430262647/job/20219746239) (please look at the *build* section)\r\n\r\nVersion of cx_Freeze: 6.15.12\r\n\r\nIt may yet be user error, in which case I apologize.\r\n\n", "hints_text": "I can confirm this issue. With VS 2022 and PowerShell, there are new API-ms DLLs to exclude. I'll make a patch.", "created_at": 1705, "language": "python", "label": "Easy"}
